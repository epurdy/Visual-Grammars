@techreport{grammar-tr,
    abstract = {We formulate a general grammar model motivated by the problem of object detection in computer vision. We focus on four aspects of modeling objects for the purpose of object detection. First, we are interested in modeling objects as having parts which are themselves (recursively) objects. For example a person can be represented as being composed of a face, a trunk, arms, and legs where a face is composed of eyes, a nose and a mouth. Second, we are interested modeling object (and part) categories as being composed of subcategories or subtypes. For example we might distinguish sitting people from standing people and smiling faces from frowning faces. Third, we are interested in modeling the relative positions of the parts that make up an object. For example, in a person, the position of the hand is related to the position of the lower arm which is related to the position of the upper arm which is related to the position of the torso. Fourth, we are interested in modeling the appearance of objects so that we can find them in images. For example, a pattern of edges in a particular location of an image might give evidence for, or against, the presence of a part at that location. These four aspects of models --- parts, subtypes, positions, and appearance --- can be represented in a single grammar formalism that we call an object detection grammar.},
    author = {Felzenszwalb, Pedro F. and McAllester, David},
    citeulike-article-id = {8071303},
    citeulike-linkout-0 = {http://www.cs.uchicago.edu/files/tr\_authentic/TR-2010-02.pdf},
    day = {11},
    institution = {University of Chicago},
    keywords = {candidacyexam, grammar},
    month = {February},
    posted-at = {2010-10-22 20:42:26},
    priority = {2},
    title = {Object Detection Grammars},
    url = {http://www.cs.uchicago.edu/files/tr\_authentic/TR-2010-02.pdf},
    year = {2010}
}

@inproceedings{amit-bernstein,
    abstract = {We propose using simple mixture models to define a set of mid-level binary local features based on binary oriented edge input. The features capture natural local structures in the data and yield very high classification rates when used with a variety of classifiers trained on small training sets, exhibiting robustness to degradation with clutter. Of particular interest is the use of the features as variables in simple statistical models for the objects thus enabling likelihood based classification. Pre-training decision boundaries between classes, a necessary component of non-parametric techniques, are thus avoided. Class models are trained separately with no need to access data of other classes. Experimental results are presented for handwritten character recognition, classification of deformed BTEX symbols involving hundreds of classes, and side view car detection.},
    author = {Bernstein, E. J. and Amit, Y.},
    citeulike-article-id = {1321604},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/CVPR.2005.270},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1467515},
    doi = {10.1109/CVPR.2005.270},
    journal = {Computer Vision and Pattern Recognition, 2005. CVPR 2005. IEEE Computer Society Conference on},
    keywords = {candidacyexam, grammar},
    pages = {734--740 vol. 2},
    posted-at = {2010-10-22 20:39:02},
    priority = {2},
    title = {Part-based statistical models for object classification and detection},
    url = {http://dx.doi.org/10.1109/CVPR.2005.270},
    volume = {2},
    year = {2005}
}

@misc{pictorial,
    abstract = {In this paper we present a statistical framework for modeling the appearance of objects. Our work is motivated by the pictorial structure models introduced by Fischler and Elschlager. The basic idea is to model an object by a collection of parts arranged in a deformable configuration. The appearance of each part is modeled separately, and the deformable configuration is represented by spring-like connections between pairs of parts. These models allow for qualitative descriptions of visual...},
    author = {Felzenszwalb, P. and Huttenlocher, D.},
    citeulike-article-id = {1185937},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.12.6365},
    keywords = {candidacyexam, grammar},
    posted-at = {2010-10-22 20:37:49},
    priority = {2},
    title = {Pictorial structures for object recognition},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.12.6365},
    year = {2003}
}

@incollection{weizmann-horse,
    abstract = {In this paper we present a novel class-based segmentation method, which is guided by a stored representation of the shape of objects within a general class (such as horse images). The approach is different from bottom-up segmentation methods that primarily use the continuity of grey-level, texture, and bounding contours. We show that the method leads to markedly improved segmentation results and can deal with significant variation in shape and varying backgrounds. We discuss the relative merits of class-specific and general image-based segmentation methods and suggest how they can be usefully combined.   Keywords: Grouping and segmentation; Figure-ground; Top-down processing; Object classification},
    author = {Borenstein, E. and Ullman, S.},
    citeulike-article-id = {1638945},
    citeulike-linkout-0 = {http://www.springerlink.com/content/xc6w1hch0b676gm9},
    journal = {Computer Vision - ECCV 2002 : 7th European Conference on Computer Vision, Copenhagen, Denmark, May 28-31, 2002. Proceedings, Part II},
    keywords = {candidacyexam},
    pages = {639--641},
    posted-at = {2010-10-22 10:30:49},
    priority = {2},
    title = {Class-Specific, Top-Down Segmentation},
    url = {http://www.springerlink.com/content/xc6w1hch0b676gm9},
    year = {2002}
}

@book{marr,
    abstract = {A computational investigation into the human representation and processing of
visual information.},
    author = {Marr, David},
    citeulike-article-id = {312794},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0716715678},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0716715678},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0716715678},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0716715678},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0716715678/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0716715678},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0716715678},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0716715678},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0716715678\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0716715678},
    day = {15},
    howpublished = {Paperback},
    isbn = {0716715678},
    keywords = {candidacyexam},
    month = {March},
    posted-at = {2010-10-15 02:46:13},
    priority = {2},
    publisher = {W. H. Freeman},
    title = {Vision: A Computational Investigation into the Human Representation and Processing of Visual Information},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0716715678},
    year = {1983}
}

@article{astar,
    abstract = {We consider the problem of computing a lightest derivation of a global structure using a set of weighted rules. A large variety of inference problems in AI can be formulated in this framework. We generalize A* search and heuristics derived from abstractions to a broad class of lightest derivation problems. We also describe a new algorithm that searches for lightest derivations using a hierarchy of abstractions. Our generalization of A* gives a new algorithm for searching AND/OR graphs in a bottom-up fashion.},
    address = {USA},
    author = {Felzenszwalb, Pedro F. and McAllester, David},
    citeulike-article-id = {8012122},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1622612},
    issn = {1076-9757},
    journal = {J. Artif. Int. Res.},
    keywords = {candidacyexam, grammar},
    number = {1},
    pages = {153--190},
    posted-at = {2010-10-13 21:48:26},
    priority = {2},
    publisher = {AI Access Foundation},
    title = {The generalized A* architecture},
    url = {http://portal.acm.org/citation.cfm?id=1622612},
    volume = {29},
    year = {2007}
}

@article{biederman,
    author = {Biederman, I.},
    citeulike-article-id = {1037940},
    citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/3575582},
    citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=3575582},
    issn = {0033-295X},
    journal = {Psychol Rev},
    keywords = {candidacyexam},
    month = {April},
    number = {2},
    pages = {115--147},
    posted-at = {2010-10-13 21:34:25},
    priority = {2},
    title = {Recognition-by-components: a theory of human image understanding.},
    url = {http://view.ncbi.nlm.nih.gov/pubmed/3575582},
    volume = {94},
    year = {1987}
}

@inproceedings{johnson-naacl,
    author = {Johnson, Mark and Griffiths, Thomas L. and Goldwater, Sharon},
    booktitle = {In Proceedings of the North American Conference on Computational Linguistics},
    citeulike-article-id = {7296749},
    citeulike-linkout-0 = {http://acl.ldc.upenn.edu/N/N07/N07-1018.pdf},
    keywords = {candidacyexam},
    posted-at = {2010-10-13 21:01:39},
    priority = {2},
    title = {Bayesian inference for PCFGs via Markov chain Monte Carlo},
    url = {http://acl.ldc.upenn.edu/N/N07/N07-1018.pdf},
    year = {2007}
}

@inproceedings{bsd,
    abstract = {This paper presents a database containing `ground truth\&\#039; segmentations produced by humans for images of a wide variety of natural scenes. We define an error measure which quantifies the consistency between segmentations of differing granularities and find that different human segmentations of the same image are highly consistent. Use of this dataset is demonstrated in two applications: (1) evaluating the performance of segmentation algorithms and (2) measuring probability distributions associated with Gestalt},
    author = {Martin, David and Fowlkes, Charless and Tal, Doron and Malik, Jitendra},
    booktitle = {in Proc. 8th Int'l Conf. Computer Vision},
    citeulike-article-id = {3878439},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.22.7314},
    keywords = {candidacyexam},
    pages = {416--423},
    posted-at = {2010-10-13 20:19:48},
    priority = {2},
    title = {A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.22.7314},
    volume = {2},
    year = {2001}
}

@article{hausdorff,
    abstract = {The Hausdorff distance measures the extent to which each point of a `model' set lies near some point of an `image' set and vice versa. Thus this distance can be used to determine the degree of resemblance between two objects that are superimposed on one another. In this paper we provide efficient algorithms for computing the Hausdorff distance between all possible relative positions of a binary image and a model. We focus primarily on the case in which the model is only allowed to translate...},
    author = {Huttenlocher, D. and Klanderman, D. and Rucklige, A.},
    citeulike-article-id = {681439},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.57.2238},
    journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
    keywords = {candidacyexam},
    month = {September},
    number = {9},
    pages = {850--863},
    posted-at = {2010-10-13 20:18:02},
    priority = {2},
    title = {Comparing images using the Hausdorff distance},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.57.2238},
    volume = {15},
    year = {1993}
}

@article{canny,
    abstract = {This paper describes a computational approach to edge detection. The success of the approach depends on the definition of a comprehensive set of goals for the computation of edge points. These goals must be precise enough to delimit the desired behavior of the detector while making minimal assumptions about the form of the solution. We define detection and localization criteria for a class of edges, and present mathematical forms for these criteria as functionals on the operator impulse response. A third criterion is then added to ensure that the detector has only one response to a single edge. We use the criteria in numerical optimization to derive detectors for several common image features, including step edges. On specializing the analysis to step edges, we find that there is a natural uncertainty principle between detection and localization performance, which are the two main goals. With this principle we derive a single operator shape which is optimal at any scale. The optimal detector has a simple approximate implementation in which edges are marked at maxima in gradient magnitude of a Gaussian-smoothed image. We extend this simple detector using operators of several widths to cope with different signal-to-noise ratios in the image. We present a general method, called feature synthesis, for the fine-to-coarse integration of information from operators at different scales. Finally we show that step edge detector performance improves considerably as the operator point spread function is extended along the edge.},
    address = {Washington, DC, USA},
    author = {Canny, J.},
    citeulike-article-id = {504152},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=11275},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/TPAMI.1986.4767851},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4767851},
    doi = {10.1109/TPAMI.1986.4767851},
    issn = {0162-8828},
    journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
    keywords = {candidacyexam},
    month = {November},
    number = {6},
    pages = {679--698},
    posted-at = {2010-10-13 20:16:37},
    priority = {2},
    publisher = {IEEE Computer Society},
    title = {A Computational Approach to Edge Detection},
    url = {http://dx.doi.org/10.1109/TPAMI.1986.4767851},
    volume = {PAMI-8},
    year = {1986}
}

@phdthesis{potter,
    address = {Providence, RI, USA},
    author = {Potter, Daniel F.},
    citeulike-article-id = {8011600},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=929684},
    isbn = {0-599-32810-X},
    keywords = {candidacyexam, grammar},
    posted-at = {2010-10-13 19:28:36},
    priority = {2},
    publisher = {Brown University},
    title = {Compositional pattern recognition},
    url = {http://portal.acm.org/citation.cfm?id=929684},
    year = {1999}
}

@article{lda,
    abstract = {We describe  latent Dirichlet allocation  (LDA), a generative probabilistic model for collections of discrete data such as text corpora. LDA is a three-level hierarchical Bayesian model, in which each item of a collection is modeled as a finite mixture over an underlying set of topics. Each topic is, in turn, modeled as an infinite mixture over an underlying set of topic probabilities. In the context of text modeling, the topic probabilities provide an explicit representation of a document. We present efficient approximate inference techniques based on variational methods and an EM algorithm for empirical Bayes parameter estimation. We report results in document modeling, text classification, and collaborative filtering, comparing to a mixture of unigrams model and the probabilistic LSI model.},
    address = {Cambridge, MA, USA},
    author = {Blei, David M. and Ng, Andrew Y. and Jordan, Michael I.},
    citeulike-article-id = {378143},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=944919.944937},
    issn = {1533-7928},
    journal = {J. Mach. Learn. Res.},
    keywords = {candidacyexam},
    pages = {993--1022},
    posted-at = {2010-10-13 07:20:57},
    priority = {2},
    publisher = {MIT Press},
    title = {Latent dirichlet allocation},
    url = {http://portal.acm.org/citation.cfm?id=944919.944937},
    volume = {3},
    year = {2003}
}

@book{grenander,
    abstract = {Pattern Theory provides a comprehensive and accessible overview of the modern challenges in signal, data, and pattern analysis in speech recognition, computational linguistics, image analysis and computer vision. Aimed at graduate students in biomedical engineering, mathematics, computer science, and electrical engineering with a good background in mathematics and probability, the text include numerous exercises and an extensive bibliography. Additional resources including extended proofs, selected solutions and examples are available on a companion website. The book commences with a short overview of pattern theory and the basics of statistics and estimation theory. Chapters 3-6 discuss the role of representation of patterns via condition structure. Chapters 7 and 8 examine the second central component of pattern theory: groups of geometric transformation applied to the representation of geometric objects. Chapter 9 moves into probabilistic structures in the continuum, studying random processes and random fields indexed over subsets of Rn. Chapters 10 and 11 continue with transformations and patterns indexed over the continuum. Chapters 12-14 extend from the pure representations of shapes to the Bayes estimation of shapes and their parametric representation. Chapters 15 and 16 study the estimation of infinite dimensional shape in the newly emergent field of Computational Anatomy. Finally, Chapters 17 and 18 look at inference, exploring random sampling approaches for estimation of model order and parametric representing of shapes.},
    address = {New York, NY, USA},
    author = {Grenander, Ulf and Miller, Michael},
    citeulike-article-id = {7470549},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1512854},
    isbn = {0199297061, 9780199297061},
    keywords = {candidacyexam, grammar},
    posted-at = {2010-10-12 23:23:35},
    priority = {2},
    publisher = {Oxford University Press, Inc.},
    title = {Pattern Theory: From Representation to Inference},
    url = {http://portal.acm.org/citation.cfm?id=1512854},
    year = {2007}
}

@article{pop,
    abstract = {Abstract\&nbsp;\&nbsp;We formulate a deformable template model for objects with an efficient mechanism for computation and parameter estimation. The data consists of binary oriented edge features, robust to photometric variation and small local deformations. The template is defined in terms of probability arrays for each edge type. A primary contribution of this paper is the definition of the instantiation of an object in terms of shifts of a moderate number local submodels—parts—which are subsequently recombined using a patchwork operation, to define a coherent statistical model of the data. Object classes are modeled as mixtures of patchwork of parts POP models that are discovered sequentially as more class data is observed. We define the notion of the support associated to an instantiation, and use this to formulate statistical models for multi-object configurations including possible occlusions. All decisions on the labeling of the objects in the image are based on comparing likelihoods. The combination of a deformable model with an efficient estimation procedure yields competitive results in a variety of applications with very small training sets, without need to train decision boundaries—only data from the class being trained is used. Experiments are presented on the MNIST database, reading zipcodes, and face detection.},
    author = {Amit, Yali and Trouv\'{e}, Alain},
    citeulike-article-id = {6419237},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/s11263-006-0033-9},
    day = {1},
    doi = {10.1007/s11263-006-0033-9},
    issn = {0920-5691},
    journal = {International Journal of Computer Vision},
    keywords = {candidacyexam},
    month = {November},
    number = {2},
    pages = {267--282},
    posted-at = {2010-09-29 18:22:45},
    priority = {2},
    title = {POP: Patchwork of Parts Models for Object Recognition},
    url = {http://dx.doi.org/10.1007/s11263-006-0033-9},
    volume = {75},
    year = {2007}
}

@article{em,
    abstract = {A broadly applicable algorithm for computing maximum likelihood estimates from incomplete data is presented at various levels of generality. Theory showing the monotone behaviour of the likelihood and convergence of the algorithm is derived. Many examples are sketched, including missing value situations, applications to grouped, censored or truncated data, finite mixture models, variance component estimation, hyperparameter estimation, iteratively reweighted least squares and factor analysis.},
    author = {Dempster, A. P. and Laird, N. M. and Rubin, D. B.},
    citeulike-article-id = {117535},
    citeulike-linkout-0 = {http://dx.doi.org/10.2307/2984875},
    citeulike-linkout-1 = {http://www.jstor.org/stable/2984875},
    doi = {10.2307/2984875},
    issn = {00359246},
    journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
    keywords = {candidacyexam},
    number = {1},
    pages = {1--38},
    posted-at = {2010-09-28 08:56:07},
    priority = {2},
    publisher = {Blackwell Publishing for the Royal Statistical Society},
    title = {Maximum Likelihood from Incomplete Data via the EM Algorithm},
    url = {http://dx.doi.org/10.2307/2984875},
    volume = {39},
    year = {1977}
}

@article{basri-jacobs,
    abstract = {Determining the similarity of two shapes is a significant task in both machine and human vision systems that must recognize or classify objects. The exact properties of human shape similarity judgements are not well understood yet, and this task is particularly difficult in domains where the shapes are not related by rigid transformations. In this paper we identify a number of possibly desirable properties of a shape similarity method, and determine the extent to which these properties can be captured by approaches that compare local properties of the contours of the shapes, through elastic matching. Special attention is devoted to objects that possess articulations, i.e. articulated parts. Elastic matching evaluates the similarity of two shapes as the sum of local deformations needed to change one shape into another. We show that similarities of part structure can be captured by such an approach, without the explicit computation of part structure. This may be of importance, since although parts appear to play a significant role in visual recognition, it is difficult to stably determine part structure. We also show novel results about how one can evaluate smooth and polyhedral shapes with the same method. Finally, we describe shape similarity effects that cannot be handled by current approaches.},
    author = {Basri, R. and Costa, L. and Geiger, D. and Jacobs, D.},
    citeulike-article-id = {2764539},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/S0042-6989(98)00043-1},
    citeulike-linkout-1 = {http://www.sciencedirect.com/science/article/B6T0W-3WBFMK9-B/1/19f3d3cd84b96e1336a1be37b58dc075},
    doi = {10.1016/S0042-6989(98)00043-1},
    journal = {Vision Research},
    keywords = {candidacyexam},
    month = {August},
    number = {15-16},
    pages = {2365--2385},
    posted-at = {2010-09-28 06:33:15},
    priority = {2},
    title = {Determining the similarity of deformable shapes},
    url = {http://dx.doi.org/10.1016/S0042-6989(98)00043-1},
    volume = {38},
    year = {1998}
}

@book{wordnet,
    abstract = {with a preface by George Miller <P>WordNet, an electronic lexical database, is considered to be the most important resource available to researchers in computational linguistics, text analysis, and many related areas. Its design is inspired by current psycholinguistic and computational theories of human lexical memory. English nouns, verbs, adjectives, and adverbs are organized into synonym sets, each representing one underlying lexicalized concept. Different relations link the synonym sets. <P>The purpose of this volume is twofold. First, it discusses the design of WordNet and the theoretical motivations behind it. Second, it provides a survey of representative applications, including word sense identification, information retrieval, selectional preferences of verbs, and lexical chains. <P>Contributors: Reem Al-Halimi, Robert C. Berwick, J. F. M. Burg, Martin Chodorow, Christiane Fellbaum, Joachim Grabowski, Sanda Harabagiu, Marti A. Hearst, Graeme Hirst, Douglas A. Jones, Rick Kazman, Karen T. Kohl, Shari Landes, Claudia Leacock, George A. Miller, Katherine J. Miller, Dan Moldovan, Naoyuki Nomura, Uta Priss, Philip Resnik, David St-Onge, Randee Tengi, Reind P. van de Riet, Ellen Voorhees.},
    author = {Fellbaum},
    citeulike-article-id = {113955},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/026206197X},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/026206197X},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/026206197X},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/026206197X},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/026206197X/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/026206197X},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/026206197X},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN026206197X},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=026206197X\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/026206197X},
    day = {15},
    edition = {illustrated edition},
    howpublished = {Hardcover},
    isbn = {026206197X},
    keywords = {candidacyexam, grammar},
    month = {May},
    posted-at = {2010-09-28 06:05:26},
    priority = {2},
    publisher = {The MIT Press},
    title = {WordNet: An Electronic Lexical Database (Language, Speech, and Communication)},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/026206197X},
    year = {1998}
}

@article{parzen,
    abstract = {A new multivariate density estimator suitable for pattern classifier design is proposed. The data are first transformed so that the pattern vector components with the most non-Gaussian structure are separated from the Gaussian components. Nonparametric density estimation is then used to capture the non-Gaussian structure of the data while parametric Gaussian conditional density estimation is applied to the rest of the components. Both simulated and real data sets are used to demonstrate the...},
    author = {Parzen, E.},
    citeulike-article-id = {1118827},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.57.8666},
    journal = {Annals of Mathematical Statistics},
    keywords = {candidacyexam, nonparametric},
    pages = {1065--1076},
    posted-at = {2010-09-28 05:56:00},
    priority = {2},
    title = {On the estimation of a probability density function and mode},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.57.8666},
    volume = {33},
    year = {1962}
}

@article{ks-fu,
    abstract = {The problem of pattern recognition is discussed in terms of single-entity representation versus multiple-entity representation. A combined syntactic-semantic approach based on attributed grammars is suggested. Syntax-semantics tradeoff in pattern representation is demonstrated. This approach is intended to be an initial step toward unification of syntactic and statistical approaches to pattern recognition.},
    author = {Fu, K. S.},
    citeulike-article-id = {7914272},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/TPAMI.1986.4767800},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4767800},
    doi = {10.1109/TPAMI.1986.4767800},
    issn = {0162-8828},
    journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
    keywords = {candidacyexam, grammar},
    month = {May},
    number = {3},
    pages = {398--404},
    posted-at = {2010-09-28 05:54:02},
    priority = {2},
    title = {A Step Towards Unification of Syntactic and Statistical Pattern Recognition},
    url = {http://dx.doi.org/10.1109/TPAMI.1986.4767800},
    volume = {PAMI-8},
    year = {1986}
}

@article{Muller2004Nonparametric,
    abstract = {We review the current state of nonparametric Bayesian inference. The discussion follows a list of important statistical inference problems, including density estimation, regression, survival analysis, hierarchical models and model validation. For each inference problem we review relevant nonparametric Bayesian models and approaches including Dirichlet process (DP) models and variations, P\'{o}lya trees, wavelet based models, neural network models, spline regression, CART, dependent DP models and model validation with DP and P\'{o}lya tree extensions of parametric models.},
    author = {M\"{u}ller, Peter and Quintana, Fernando A.},
    citeulike-article-id = {3136980},
    citeulike-linkout-0 = {http://dx.doi.org/10.2307/4144375},
    citeulike-linkout-1 = {http://www.jstor.org/stable/4144375},
    doi = {10.2307/4144375},
    issn = {08834237},
    journal = {Statistical Science},
    keywords = {candidacyexam, nonparametric},
    number = {1},
    pages = {95--110},
    posted-at = {2010-09-27 22:06:16},
    priority = {2},
    publisher = {Institute of Mathematical Statistics},
    title = {Nonparametric Bayesian Data Analysis},
    url = {http://dx.doi.org/10.2307/4144375},
    volume = {19},
    year = {2004}
}

@article{labelme,
    abstract = {Abstract\&nbsp;\&nbsp; We seek to build a large collection of images with ground truth labels to be used for object detection and recognition research. Such data is useful for supervised learning and quantitative evaluation. To achieve this, we developed a web-based tool that allows easy image annotation and instant sharing of such annotations. Using this annotation tool, we have collected a large dataset that spans many object categories, often containing multiple instances over a wide variety of images. We quantify the contents of the dataset and compare against existing state of the art datasets used for object recognition and detection. Also, we show how to extend the dataset to automatically enhance object labels with WordNet, discover object parts, recover a depth ordering of objects in a scene, and increase the number of labels using minimal user supervision and images from the web.},
    address = {Hingham, MA, USA},
    author = {Russell, Bryan C. and Torralba, Antonio and Murphy, Kevin P. and Freeman, William T.},
    citeulike-article-id = {2857997},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1345995.1345999},
    citeulike-linkout-1 = {http://dx.doi.org/10.1007/s11263-007-0090-8},
    citeulike-linkout-2 = {http://www.springerlink.com/content/76x9j562653k0378},
    day = {1},
    doi = {10.1007/s11263-007-0090-8},
    issn = {0920-5691},
    journal = {International Journal of Computer Vision},
    keywords = {candidacyexam, grammar},
    month = {May},
    number = {1},
    pages = {157--173},
    posted-at = {2010-09-10 10:37:52},
    priority = {2},
    publisher = {Kluwer Academic Publishers},
    title = {{LabelMe}: A Database and Web-Based Tool for Image Annotation},
    url = {http://dx.doi.org/10.1007/s11263-007-0090-8},
    volume = {77},
    year = {2008}
}

@book{zhu-mumford-book,
    abstract = {A Stochastic Grammar of Images is the first book to provide a foundational review and perspective of grammatical approaches to computer vision. In its quest for a stochastic and context sensitive grammar of images, it is intended to serve as a unified frame-work of representation, learning, and recognition for a large number of object categories. It starts out by addressing the historic trends in the area and overviewing the main concepts: such as the and-or graph, the parse graph, the dictionary and goes on to learning issues, semantic gaps between symbols and pixels, dataset for learning and algorithms. The proposal grammar presented integrates three prominent representations in the literature: stochastic grammars for composition, Markov (or graphical) models for contexts, and sparse coding with primitives (wavelets). It also combines the structure-based and appearance based methods in the vision literature. At the end of the review, three case studies are presented to illustrate the proposed grammar. A Stochastic Grammar of Images is an important contribution to the literature on structured statistical models in computer vision.},
    address = {Hanover, MA, USA},
    author = {Zhu, Song C. and Mumford, David},
    citeulike-article-id = {5710885},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1537078},
    isbn = {1601980604, 9781601980601},
    keywords = {candidacyexam, grammar},
    posted-at = {2010-09-10 10:35:02},
    priority = {2},
    publisher = {Now Publishers Inc.},
    title = {A Stochastic Grammar of Images},
    url = {http://portal.acm.org/citation.cfm?id=1537078},
    year = {2007}
}

@article{visual-context,
    abstract = {We see the world in scenes, where visual objects occur in rich surroundings, often embedded in a typical context with other related objects. How does the human brain analyse and use these common associations? This article reviews the knowledge that is available, proposes specific mechanisms for the contextual facilitation of object recognition, and highlights important open questions. Although much has already been revealed about the cognitive and cortical mechanisms that subserve recognition of individual objects, surprisingly little is known about the neural underpinnings of contextual analysis and scene perception. Building on previous findings, we now have the means to address the question of how the brain integrates individual elements to construct the visual experience.},
    author = {Bar, Moshe},
    citeulike-article-id = {1282371},
    citeulike-linkout-0 = {http://dx.doi.org/10.1038/nrn1476},
    citeulike-linkout-1 = {http://dx.doi.org/10.1038/nrn1476},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/15263892},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=15263892},
    day = {01},
    doi = {10.1038/nrn1476},
    issn = {1471-003X},
    journal = {Nature Reviews Neuroscience},
    keywords = {candidacyexam},
    month = {August},
    number = {8},
    pages = {617--629},
    posted-at = {2010-09-10 09:53:17},
    priority = {2},
    publisher = {Nature Publishing Group},
    title = {Visual objects in context},
    url = {http://dx.doi.org/10.1038/nrn1476},
    volume = {5},
    year = {2004}
}

@techreport{Aycinena2008Learning,
    abstract = {Many object recognition systems are limited by their inability to share common parts or structure among related object classes. This capability is desirable because it allows information about parts and relationships in one object class to be generalized to other classes for which it is relevant. With this goal in mind, we have designed a representation and recognition framework that captures structural variability and shared part structure within and among object classes. The framework uses probabilistic geometric grammars (PGGs) to represent object classes recursively in terms of their parts, thereby exploiting the hierarchical and substitutive structure inherent to many types of objects. To incorporate geometric and appearance information, we extend traditional probabilistic context-free grammars to represent distributions over the relative geometric characteristics of object parts as well as the appearance of primitive parts. We describe an efficient dynamic programming algorithm for object categorization and localization in images given a PGG model. We also develop an EM algorithm to estimate the parameters of a grammar structure from training data, and a search-based structure learning approach that finds a compact grammar to explain the image data while sharing substructure among classes. Finally, we describe a set of experiments that demonstrate empirically that the system provides a performance benefit.},
    author = {Aycinena, Meg and Kaelbling, Leslie P. and Lozano-Perez, Tomas},
    citeulike-article-id = {7805459},
    citeulike-linkout-0 = {http://people.csail.mit.edu/aycinena/papers/MIT-CSAIL-TR-2008-011.pdf},
    day = {25},
    institution = {MIT},
    keywords = {candidacyexam, grammar},
    month = {February},
    number = {MIT-CSAIL-TR-2008-011},
    posted-at = {2010-09-09 22:34:26},
    priority = {2},
    title = {Learning Grammatical Models for Object Recognition},
    url = {http://people.csail.mit.edu/aycinena/papers/MIT-CSAIL-TR-2008-011.pdf},
    year = {2008}
}

@techreport{lee-induction,
    abstract = {We survey methods for learning context-free languages (CFL's) in the theoretical computer science literature. We first present some important negative results. Then, we consider five types of methods: those that take text as input, those that take structural information as input, those that rely on CFL formalisms that are not based on context-free grammars, those which learn subclasses of CFL's, and stochastic methods. A description of the subclasses of CFL's considered is provided, as is an...},
    author = {Lee, Lillian},
    citeulike-article-id = {3431},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.40.7989},
    institution = {Harvard University},
    keywords = {candidacyexam, grammar},
    number = {TR-12-96},
    posted-at = {2010-09-09 17:38:40},
    priority = {2},
    title = {Learning of Context-Free Languages: A Survey of the Literature},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.40.7989},
    year = {\# 1996}
}

@article{Guy1995CoinWeighing,
    author = {Guy, Richard K. and Nowakowski, Richard J.},
    citeulike-article-id = {6707322},
    citeulike-linkout-0 = {http://dx.doi.org/10.2307/2975353},
    citeulike-linkout-1 = {http://www.jstor.org/stable/2975353},
    doi = {10.2307/2975353},
    issn = {00029890},
    journal = {The American Mathematical Monthly},
    keywords = {coins},
    number = {2},
    pages = {164--167},
    posted-at = {2010-02-21 03:45:15},
    priority = {2},
    publisher = {Mathematical Association of America},
    title = {Coin-Weighing Problems},
    url = {http://dx.doi.org/10.2307/2975353},
    volume = {102},
    year = {1995}
}

@article{Aigner1997Searching,
    abstract = {The well-known counterfeit problem asks for the minimum number of weighings necessary to determine all fake coins in a given set ofn coins. We derive a new upper bound when we know that at mostd coins are defective, improving a previous result of L. Pyber.},
    author = {Aigner, Martin and Li, Anping},
    citeulike-article-id = {6707319},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/BF01202233},
    citeulike-linkout-1 = {http://www.springerlink.com/content/uk3ml0616812n602},
    day = {1},
    doi = {10.1007/BF01202233},
    issn = {0911-0119},
    journal = {Graphs and Combinatorics},
    keywords = {coins},
    month = {March},
    number = {1},
    pages = {9--20},
    posted-at = {2010-02-21 03:44:19},
    priority = {2},
    title = {Searching for counterfeit coins},
    url = {http://dx.doi.org/10.1007/BF01202233},
    volume = {13},
    year = {1997}
}

@phdthesis{Yuret:98,
    abstract = {This work has been motivated by two long term goals: to understand how humans learn language and to build programs that can understand language. Using a representation that makes the relevant features explicit is a prerequisite for successful learning and understanding. Therefore, I chose to represent relations between individual words explicitly in my model. Lexical attraction is defined as the likelihood of such relations. I introduce a new class of probabilistic language models named lexical ...},
    author = {Yuret, D.},
    citeulike-article-id = {899509},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.39.1353},
    month = {May},
    posted-at = {2010-02-16 17:20:35},
    priority = {2},
    school = {Department of Computer Science and Electrical Engineering, MIT},
    title = {Discovery of linguistic relations using lexical attraction},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.39.1353},
    year = {1998}
}

@inproceedings{Haghighi2007Unsupervised,
    address = {Prague, Czech Republic},
    author = {Haghighi, Aria and Klein, Dan},
    booktitle = {Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics},
    citeulike-article-id = {1433175},
    citeulike-linkout-0 = {http://www.aclweb.org/anthology/P/P07/P07-1107},
    month = {June},
    pages = {848--855},
    posted-at = {2010-02-05 07:04:35},
    priority = {2},
    publisher = {Association for Computational Linguistics},
    title = {Unsupervised Coreference Resolution in a Nonparametric Bayesian Model},
    url = {http://www.aclweb.org/anthology/P/P07/P07-1107},
    year = {2007}
}

@inproceedings{Zhang2006SVMKNN,
    abstract = {We consider visual category recognition in the framework of measuring similarities, or equivalently perceptual distances, to prototype examples of categories. This approach is quite flexible, and permits recognition based on color, texture, and particularly shape, in a homogeneous framework. While nearest neighbor classifiers are natural in this setting, they suffer from the problem of high variance (in bias-variance decomposition) in the case of limited sampling. Alternatively, one could use support vector machines but they involve time-consuming optimization and computation of pairwise distances. We propose a hybrid of these two methods which deals naturally with the multiclass setting, has reasonable computational complexity both in training and at run time, and yields excellent results in practice. The basic idea is to find close neighbors to a query sample and train a local support vector machine that preserves the distance function on the collection of neighbors. Our method can be applied to large, multiclass data sets for which it outperforms nearest neighbor and support vector machines, and remains efficient when the problem becomes intractable for support vector machines. A wide variety of distance functions can be used and our experiments show state-of-the-art performance on a number of benchmark data sets for shape and texture classification (MNIST, USPS, CUReT) and object recognition (Caltech- 101). On Caltech-101 we achieved a correct classification rate of 59.05\%(±0.56\%) at 15 training images per class, and 66.23\%(±0.48\%) at 30 training images.},
    address = {Washington, DC, USA},
    author = {Zhang, Hao and Berg, A. C. and Maire, M. and Malik, J.},
    booktitle = {CVPR '06: Proceedings of the 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
    citeulike-article-id = {2552946},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1153171.1153559},
    citeulike-linkout-1 = {http://doi.ieeecomputersociety.org/10.1109/CVPR.2006.301},
    citeulike-linkout-2 = {http://dblp.uni-trier.de/rec/bibtex/conf/cvpr/ZhangBMM06},
    citeulike-linkout-3 = {http://dx.doi.org/10.1109/CVPR.2006.301},
    citeulike-linkout-4 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1641014},
    doi = {10.1109/CVPR.2006.301},
    location = {New York, NY, USA},
    pages = {2126--2136},
    posted-at = {2010-02-05 05:36:43},
    priority = {2},
    publisher = {IEEE Computer Society},
    title = {SVM-KNN: Discriminative Nearest Neighbor Classification for Visual Category Recognition},
    url = {http://dx.doi.org/10.1109/CVPR.2006.301},
    year = {2006}
}

@inproceedings{Belongie2000Shape,
    abstract = {We introduce a new shape descriptor, the shape context, for correspondence recovery and shape-based object recognition. The shape context at a point captures the distribution over relative positions of other shape points and thus summarizes global shape in a rich, local descriptor. Shape contexts greatly simplify recovery of correspondences between points of two given shapes. Moreover, the shape context leads to a robust score for measuring shape similarity, once shapes are aligned. The shape context descriptor is tolerant to all common shape deformations. As a key advantage no special landmarks or key-points are necessary. It is thus a generic method with applications in object recognition, image registration and point set matching. Using examples involving both handwritten digits and 3D objects, we illustrate its power for object recognition.},
    author = {Belongie, Serge and Malik, Jitendra and Puzicha, Jan},
    booktitle = {In NIPS},
    citeulike-article-id = {3504719},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.27.8567},
    pages = {831--837},
    posted-at = {2010-02-05 05:35:47},
    priority = {2},
    title = {Shape Context: A new descriptor for shape matching and object recognition},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.27.8567},
    year = {2000}
}

@electronic{Wilson2000Reduction,
    abstract = { Exemplar-based learning algorithms are often faced with the problem of deciding which instances or other exemplars to store for use during generalization. Storing too many exemplars can result in large memory requirements and slow execution speed, and can cause an oversensitivity to noise. This paper has two main purposes. First, it provides a survey of existing algorithms used to reduce the number of exemplars retained in exemplar-based learning models. Second, it proposes six new reduction algorithms called DROP1-5 and DEL that can be used to prune instances from the concept description. These algorithms and 10 algorithms from the survey are compared on 31 datasets. Of those algorithms that provide substantial storage reduction, the DROP algorithms have the highest generalization accuracy in these experiments, especially in the presence of noise.},
    author = {Wilson, D. Randall and Martinez, Tony R.},
    citeulike-article-id = {6629066},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.50.6544},
    pages = {257--286},
    posted-at = {2010-02-05 05:34:23},
    priority = {2},
    title = {Reduction Techniques for Exemplar-Based Learning Algorithms},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.50.6544},
    volume = {38},
    year = {2000}
}

@article{Wolff1977Discovery,
    author = {Wolff, J. G.},
    citeulike-article-id = {3787370},
    journal = {British Journal of Psychology},
    pages = {97--106},
    posted-at = {2010-02-04 23:28:44},
    priority = {2},
    title = {The discovery of segments in natural language},
    volume = {68},
    year = {1977}
}

@article{Wolff1980Language,
    author = {Wolff, J. G.},
    citeulike-article-id = {3786946},
    citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/7432051},
    citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=7432051},
    issn = {0023-8309},
    journal = {Language and speech},
    number = {Pt 3},
    pages = {255--269},
    posted-at = {2010-02-04 23:28:12},
    priority = {2},
    title = {Language acquisition and the discovery of phrase structure.},
    url = {http://view.ncbi.nlm.nih.gov/pubmed/7432051},
    volume = {23},
    year = {1980}
}

@article{Wolff1982Language,
    author = {Wolff, J. G.},
    citeulike-article-id = {3787374},
    journal = {Language and Communication},
    pages = {57--89},
    posted-at = {2010-02-04 23:27:18},
    priority = {2},
    title = {Language acquisition, data compression and generalization},
    volume = {2},
    year = {1982}
}

@article{Cohen2007Voting,
    abstract = {We describe a statistical signature of chunks and an algorithm for finding chunks. While there is no formal definition of chunks, they may be reliably identified as configurations with low internal entropy or unpredictability and high entropy at their boundaries. We show that the log frequency of a chunk is a measure of its internal entropy. The Voting-Experts exploits the signature of chunks to find word boundaries in text from four languages and episode boundaries in the activities of a mobile robot.},
    address = {Amsterdam, The Netherlands, The Netherlands},
    author = {Cohen, Paul and Adams, Niall and Heeringa, Brent},
    citeulike-article-id = {6628581},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1368021},
    issn = {1088-467X},
    journal = {Intell. Data Anal.},
    number = {6},
    pages = {607--625},
    posted-at = {2010-02-04 23:25:59},
    priority = {2},
    publisher = {IOS Press},
    title = {Voting experts: An unsupervised algorithm for segmenting sequences},
    url = {http://portal.acm.org/citation.cfm?id=1368021},
    volume = {11},
    year = {2007}
}

@misc{EisnerNotes,
    author = {Eisner, Jason},
    citeulike-article-id = {6628579},
    citeulike-linkout-0 = {http://www.cs.jhu.edu/\~{}jason/465/iobasics.pdf},
    posted-at = {2010-02-04 23:23:07},
    priority = {2},
    title = {Notes on the Inside-Outside Algorithm},
    url = {http://www.cs.jhu.edu/\~{}jason/465/iobasics.pdf}
}

@unpublished{FelzenszwalbHierarchical,
    author = {Felzenszwalb, Pedro},
    citeulike-article-id = {6628577},
    posted-at = {2010-02-04 23:21:54},
    priority = {2},
    title = {Hierarchical Curve Models}
}

@article{Goldsmith2006Algorithm,
    abstract = {This paper describes in detail an algorithm for the unsupervised learning of natural language morphology, with emphasis on challenges that are encountered in languages typologically similar to European languages. It utilizes the Minimum Description Length analysis described in Goldsmith (2001), and has been implemented in software that is available for downloading and testing.},
    address = {New York, NY, USA},
    author = {Goldsmith, John},
    citeulike-article-id = {6628575},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1181162},
    citeulike-linkout-1 = {http://dx.doi.org/10.1017/S1351324905004055},
    doi = {10.1017/S1351324905004055},
    issn = {1351-3249},
    journal = {Nat. Lang. Eng.},
    number = {4},
    pages = {353--371},
    posted-at = {2010-02-04 23:18:59},
    priority = {2},
    publisher = {Cambridge University Press},
    title = {An algorithm for the unsupervised learning of morphology},
    url = {http://dx.doi.org/10.1017/S1351324905004055},
    volume = {12},
    year = {2006}
}

@electronic{nevill-manning,
    abstract = {SEQUITUR is an algorithm that infers a hierarchical structure from a sequence of discrete symbols by replacing repeated phrases with a grammatical rule that generates the phrase, and continuing this process recursively. The result is a hierarchical representation of the original sequence, which offers insights into its lexical structure. The algorithm is driven by two constraints that reduce the size of the grammar, and produce structure as a by-product. SEQUITUR breaks new ground by operating incrementally. Moreover, the method's simple structure permits a proof that it operates in space and time that is linear in the size of the input. Our implementation can process 50,000 symbols per second and has been applied to an extensive range of real world sequences. 1. Introduction Many sequences of discrete symbols exhibit natural hierarchical structure. Text is made up of paragraphs, sentences, phrases, and words. Music is composed from major sections, motifs, bars, and notes. Records of ...},
    author = {Nevill-Manning, Craig G. and Witten, Ian H.},
    citeulike-article-id = {6628573},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.51.3846},
    posted-at = {2010-02-04 23:16:36},
    priority = {2},
    title = {Identifying Hierarchical Structure in Sequences: A linear-time algorithm},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.51.3846},
    year = {1997}
}

@book{Dryden1998Statistical,
    author = {Dryden, I. L. and Mardia, Kanti V.},
    citeulike-article-id = {5636224},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0471958166},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0471958166},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0471958166},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0471958166},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0471958166/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0471958166},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0471958166},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0471958166},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0471958166\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0471958166},
    day = {02},
    edition = {1},
    howpublished = {Hardcover},
    isbn = {0471958166},
    month = {September},
    posted-at = {2010-02-04 23:15:46},
    priority = {2},
    publisher = {Wiley},
    title = {Statistical Shape Analysis},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0471958166},
    year = {1998}
}

@inproceedings{Schutze1995Distributional,
    abstract = {This paper presents an algorithm for tagging words whose part-of-speech properties are unknown. Unlike previous work, the algorithm categorizes  word tokens in context  instead of  word types . The algorithm is evaluated on the Brown Corpus.},
    address = {San Francisco, CA, USA},
    author = {Sch\"{u}tze, Hinrich},
    booktitle = {Proceedings of the seventh conference on European chapter of the Association for Computational Linguistics},
    citeulike-article-id = {165339},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=976994},
    citeulike-linkout-1 = {http://dx.doi.org/10.3115/976973.976994},
    doi = {10.3115/976973.976994},
    location = {Dublin, Ireland},
    pages = {141--148},
    posted-at = {2010-02-04 23:15:07},
    priority = {2},
    publisher = {Morgan Kaufmann Publishers Inc.},
    title = {Distributional part-of-speech tagging},
    url = {http://dx.doi.org/10.3115/976973.976994},
    year = {1995}
}

@inproceedings{Clark2001Unsupervised,
    abstract = {An algorithm is presented for learning a phrase-structure grammar from tagged text. It clusters sequences of tags together based on local distributional information, and selects clusters that satisfy a novel mutual information criterion. This criterion is shown to be related to the entropy of a random variable associated with the tree structures, and it is demonstrated that it selects linguistically plausible constituents. This is incorporated in a Minimum Description Length algorithm. The evaluation of unsupervised models is discussed, and results are presented when the algorithm has been trained on 12 million words of the British National Corpus.},
    address = {Morristown, NJ, USA},
    author = {Clark, Alexander},
    booktitle = {ConLL '01: Proceedings of the 2001 workshop on Computational Natural Language Learning},
    citeulike-article-id = {2873598},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1117831},
    citeulike-linkout-1 = {http://dx.doi.org/10.3115/1117822.1117831},
    doi = {10.3115/1117822.1117831},
    location = {Toulouse, France},
    pages = {1--8},
    posted-at = {2010-02-04 23:13:56},
    priority = {2},
    publisher = {Association for Computational Linguistics},
    title = {Unsupervised induction of stochastic context-free grammars using distributional clustering},
    url = {http://dx.doi.org/10.3115/1117822.1117831},
    year = {2001}
}

@electronic{KomodakisImage,
    abstract = {In this paper, a new exemplar-based framework is presented, which treats image completion, texture synthesis and image inpainting in a unified manner. In order to be able to avoid the occurrence of visually inconsistent results, we pose all of the above image-editing tasks in the form of a discrete global optimization problem. The objective function of this problem is always well-defined, and corresponds to the energy of a discrete Markov Random Field (MRF). For efficiently optimizing this MRF, a novel opti-mization scheme, called Priority-BP, is then proposed, which carries two very important extensions over the standard Belief Propagation (BP) algorithm:  ” priority-based message scheduling ” and  ” dynamic label pruning”. These two extensions work in cooperation to deal with the intolerable computational cost of BP, which is caused by the huge number of labels associated with our MRF. Moreover, both of our extensions are generic, since they do not rely on the use of domain-specific prior knowledge. They can therefore be applied to any MRF, i.e to a very wide class of problems in image processing and computer vision, thus managing to resolve what is currently considered as one major limitation of the Belief Propagation algorithm: its inefficiency in handling MRFs with very large discrete state-spaces. Experimental results on a wide variety of input images are presented, which demonstrate the effectiveness of our image-completion framework for tasks such as object removal, texture synthesis, text removal and image inpainting.},
    author = {Komodakis, Nikos and Tziritas, Georgios},
    citeulike-article-id = {6628571},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.109.1572},
    posted-at = {2010-02-04 23:12:52},
    priority = {2},
    title = {Image Completion Using Efficient Belief Propagation via Priority Scheduling and Dynamic Pruning},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.109.1572}
}

@techreport{Chanda2004Grammatical,
    author = {Chanda, Gaurav and Dellaert, Frank},
    citeulike-article-id = {6628570},
    citeulike-linkout-0 = {http://smartech.gatech.edu/handle/1853/3738},
    day = {29},
    institution = {Georgia Tech},
    month = {November},
    posted-at = {2010-02-04 23:12:03},
    priority = {2},
    title = {Grammatical Methods in Computer Vision: An Overview},
    url = {http://smartech.gatech.edu/handle/1853/3738},
    year = {2004}
}

@electronic{Bunke1996Recognition,
    abstract = {This paper provides a compelling illustration of the complexity of the mathematics-recognition task, of the many symbol configurations that must be considered. The authors state that syntactic approaches, using parsing, are untenable because the great variety of possible expressions makes it impossible to provide an a priori syntax definition for all possible expressions. This, combined with the computational complexity of parsing, motivates them to instead use a large collection of procedurally-coded recognition rules. Their comment about a priori syntax definition requires some clarification: any recognition method, including procedurally-coded rules, implicitly or explicitly defines the syntax of recognizable expressions. Apparently Okamoto et al. find it easier and more practical to provide an implicit syntax definition, coded as procedural rules, rather than an explicit syntax definition, coded as grammar rules.},
    author = {Bunke, H. and Blostein, Dorothea and Grbavec, Ann},
    citeulike-article-id = {6628568},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.52.67},
    posted-at = {2010-02-04 23:09:22},
    priority = {2},
    title = {Recognition Of Mathematical Notation},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.52.67},
    year = {1996}
}

@inproceedings{Lavirotte1998Mathematical,
    abstract = {This paper describes current results of OFR (Optical Formula Recognition), a system for extracting and understanding mathematical expressions in documents. Such a tool could be really useful to be able to re-use knowledge in scientific books which are not available in electronic form. We currently also study use of this system for direct input of formulas with a graphical tablet for computer algebra system softwares. Existing solutions for mathematical recognition have problems to analyze two dimensional expressions like vectors and matrices... This is because they often try to use extended classical grammar to analyze formulas, relatively to baseline. But a lot of mathematical notations do not respect rules for such a parsing and that is the reason why they fail to extend text parsing technic. We investigate graph grammar and graph rewriting as a solution to recognize two dimensional mathematical notations. Graph grammar provide a powerful formalism to describe structural manipulations...},
    author = {Lavirotte, St\'{e}phane and Pottier, Lo\"{i}c and Pottier, Lo\#c},
    booktitle = {In Proceedings of the SPIE},
    citeulike-article-id = {6628566},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.40.5752},
    pages = {44--52},
    posted-at = {2010-02-04 23:08:07},
    priority = {2},
    title = {Mathematical Formula Recognition Using Graph Grammar},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.40.5752},
    volume = {3305},
    year = {1998}
}

@incollection{Bolle1997Toward,
    abstract = {We are interested in processing video data for the purpose of solving a variety of problems in video search, analysis, indexing, browsing and compression. Instead of concentrating on a particular problem, in this paper we present a framework for developing video applications. Our basic thesis is that video data can be represented at a higher level of abstraction as a string generated by a grammar, termed motion picture grammar. The rules of that grammar relate different spatiotemporal representations of the video content and, in particular, representations of action.},
    address = {Berlin, Heidelberg},
    author = {Bolle, Ruud and Aloimonos, Yiannis and Ferm\"{u}ller, Cornelia},
    booktitle = {Computer Vision — ACCV'98 },
    chapter = {38},
    citeulike-article-id = {6628563},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/3-540-63931-4\_228},
    citeulike-linkout-1 = {http://www.springerlink.com/content/mg41245228833173},
    doi = {10.1007/3-540-63931-4\_228},
    editor = {Chin, Roland and Pong, Ting-Chuen},
    isbn = {978-3-540-63931-2},
    pages = {283--290},
    posted-at = {2010-02-04 23:06:58},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    series = {Lecture Notes in Computer Science},
    title = {Toward motion picture grammars},
    url = {http://dx.doi.org/10.1007/3-540-63931-4\_228},
    volume = {1352},
    year = {1997}
}

@article{Lee1992Character,
    abstract = {The recognition of Korean characters by a syntactic method is considered. Korean characters are composed of phonetic symbols in two dimensions and contain very little redundancy. In addition, the phonetic symbols in each character are different in shape and number depending on how they are composed. Thus, attribute information is important. A Korean character recognition algorithm based on an attribute-dependent programmed grammar is presented. The preprocessing and primitive extraction algorithm is also described. The algorithm was implemented and tested with more than 9600 Korean characters in pages randomly selected from children's story books. The algorithm based on the attribute-dependent programmed grammar recognized characters reasonably quickly, with more than 95.1\% accuracy.},
    address = {Washington, DC, USA},
    author = {Lee, Kyoon H. and Eom, Kie B. and Kashyap, R. L.},
    citeulike-article-id = {6628562},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=141786},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/34.166629},
    doi = {10.1109/34.166629},
    issn = {0162-8828},
    journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
    number = {11},
    pages = {1122--1128},
    posted-at = {2010-02-04 23:05:44},
    priority = {2},
    publisher = {IEEE Computer Society},
    title = {Character Recognition Based on Attribute-Dependent Programmed Grammar},
    url = {http://dx.doi.org/10.1109/34.166629},
    volume = {14},
    year = {1992}
}

@inproceedings{Richards1985Codon,
    abstract = {Codons are simple primitives for describing plane curves. They thus are primarily image-based descriptors. Yet they have the power to capture important information about the 3D world, such as making part boundaries explicit, The codon description is highly redundant (useful for error-correction). This redundancy can be viewed as a constraint on tile number of possible codon strings, For smooth closed strings that represent the bounding contour (silhouette) of many smooth 3D objects, tile constraints are so strong that sequences containing 6 elements yield only 33 generic shapes as compared with possible number of 15,625 combinations.},
    author = {Richards, Whitman and Hoffman, Donald D. and Richards, Codon C.},
    booktitle = {Computer Vision, Graphics, and Image Processing},
    citeulike-article-id = {6628560},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.18.5639},
    pages = {265--281},
    posted-at = {2010-02-04 23:05:01},
    priority = {2},
    title = {Codon constraints on closed 2D shapes},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.18.5639},
    volume = {31},
    year = {1985}
}

@inproceedings{Dreyer2009Graphical,
    address = {Singapore},
    author = {Dreyer, Markus and Eisner, Jason},
    booktitle = {Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing},
    citeulike-article-id = {5427355},
    citeulike-linkout-0 = {http://www.aclweb.org/anthology-new/D/D09/D09-1011.bib},
    citeulike-linkout-1 = {http://www.aclweb.org/anthology-new/D/D09/D09-1011.pdf},
    month = {August},
    pages = {101--110},
    posted-at = {2010-02-04 23:04:14},
    priority = {2},
    publisher = {Association for Computational Linguistics},
    title = {Graphical Models over Multiple Strings},
    url = {http://www.aclweb.org/anthology-new/D/D09/D09-1011.bib},
    year = {2009}
}

@inproceedings{Kumar2008What,
    abstract = {Many computer vision algorithms require searching a set of images for similar patches, which is a very expensive operation. In this work, we compare and evaluate a number of nearest neighbors algorithms for speeding up this task. Since image patches follow very different distributions from the uniform and Gaussian distributions that are typically used to evaluate nearest neighbors methods, we determine the method with the best performance via extensive experimentation on real images. Furthermore, we take advantage of the inherent structure and properties of images to achieve highly efficient implementations of these algorithms. Our results indicate that vantage point trees, which are not well known in the vision community, generally offer the best performance.},
    address = {Berlin, Heidelberg},
    author = {Kumar, Neeraj and Zhang, Li and Nayar, Shree},
    booktitle = {ECCV '08: Proceedings of the 10th European Conference on Computer Vision},
    citeulike-article-id = {6628557},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1479280},
    citeulike-linkout-1 = {http://dx.doi.org/10.1007/978-3-540-88688-4\_27},
    doi = {10.1007/978-3-540-88688-4\_27},
    isbn = {978-3-540-88685-3},
    location = {Marseille, France},
    pages = {364--378},
    posted-at = {2010-02-04 23:02:00},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {What Is a Good Nearest Neighbors Algorithm for Finding Similar Patches in Images?},
    url = {http://dx.doi.org/10.1007/978-3-540-88688-4\_27},
    year = {2008}
}

@article{Charniak1997Statistical,
    author = {Charniak, E.},
    citeulike-article-id = {931311},
    journal = {The AI Magazine},
    posted-at = {2010-02-04 23:00:39},
    priority = {2},
    title = {Statistical techniques for natural language parsing},
    year = {1997}
}

@article{Parikh2009Unsupervised,
    abstract = {A successful representation of objects in literature is as a collection of patches, or parts, with a certain appearance and position. The relative locations of the different parts of an object are constrained by the geometry of the object. Going beyond a single object, consider a collection of images of a particular scene category containing multiple (recurring) objects. The parts belonging to different objects are not constrained by such a geometry. However, the objects themselves, arguably due to their semantic relationships, demonstrate a pattern in their relative locations. Hence, analyzing the interactions among the parts across the collection of images can allow for extraction of the foreground objects, and analyzing the interactions among these objects can allow for a semantically meaningful grouping of these objects, which characterizes the entire scene. These groupings are typically hierarchical. We introduce hierarchical semantics of objects (hSO) that captures this hierarchical grouping. We propose an approach for the unsupervised learning of the hSO from a collection of images of a particular scene. We also demonstrate the use of the hSO in providing context for enhanced object localization in the presence of significant occlusions, and show its superior performance over a fully connected graphical model for the same task.},
    address = {New York, NY, United States},
    author = {Parikh, Devi and Chen, Tsuhan},
    citeulike-article-id = {6628555},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1608907},
    citeulike-linkout-1 = {http://dx.doi.org/10.1155/2009/184618},
    doi = {10.1155/2009/184618},
    issn = {1687-5176},
    journal = {J. Image Video Process.},
    pages = {1--16},
    posted-at = {2010-02-04 22:59:15},
    priority = {2},
    publisher = {Hindawi Publishing Corp.},
    title = {Unsupervised modeling of objects and their hierarchical contextual interactions},
    url = {http://dx.doi.org/10.1155/2009/184618},
    volume = {2009},
    year = {2009}
}

@inproceedings{Parikh09,
    abstract = {The visual world demonstrates organized spatial pat-
terns, among objects or regions in a scene, object-parts
in an object, and low-level features in object-parts. These
classes of spatial structures are inherently hierarchical in
nature. Although seemingly quite different these spatial pat-
terns are simply manifestations of different levels in a hier-
archy. In this work, we present a unified approach to un-
supervised learning of hierarchical spatial structures from
a collection of images. Ours is a hierarchical rule-based
model capturing spatial patterns, where each rule is repre-
sented by a star-graph. We propose an unsupervised EM-
style algorithm to learn our model from a collection of im-
ages. We show that the inference problem of determining
the set of learnt rules instantiated in an image is equiva-
lent to finding the minimum-cost Steiner tree in a directed
acyclic graph. We evaluate our approach on a diverse set
of data sets of object categories, natural outdoor scenes and
images from complex street scenes with multiple objects.},
    author = {Parikh, Devi and Zitnick, C. Lawrence and Chen, Tsuhan},
    booktitle = {IEEE Conference on Computer Vision and Pattern Recognition},
    citeulike-article-id = {5013745},
    citeulike-linkout-0 = {http://amp.ece.cmu.edu/Publication/Devi/ParikhZitnickChen\_CVPR\_2009\_steiner.pdf},
    posted-at = {2010-02-04 22:57:57},
    priority = {2},
    title = {Unsupervised Learning of Hierarchical Spatial Structures In Images},
    url = {http://amp.ece.cmu.edu/Publication/Devi/ParikhZitnickChen\_CVPR\_2009\_steiner.pdf},
    year = {2009}
}

@article{Qi2005Eigenvalues,
    abstract = {In this paper, we define the symmetric hyperdeterminant, eigenvalues and E-eigenvalues of a real supersymmetric tensor. We show that eigenvalues are roots of a one-dimensional polynomial, and when the order of the tensor is even, E-eigenvalues are roots of another one-dimensional polynomial. These two one-dimensional polynomials are associated with the symmetric hyperdeterminant. We call them the characteristic polynomial and the E-characteristic polynomial of that supersymmetric tensor. Real eigenvalues (E-eigenvalues) with real eigenvectors (E-eigenvectors) are called H-eigenvalues (Z-eigenvalues). When the order of the supersymmetric tensor is even, H-eigenvalues (Z-eigenvalues) exist and the supersymmetric tensor is positive definite if and only if all of its H-eigenvalues (Z-eigenvalues) are positive. An  inlMMLBox -order  n -dimensional supersymmetric tensor where  m  is even has exactly  n ( m −1) n −1  eigenvalues, and the number of its E-eigenvalues is strictly less than  n ( m −1) n −1  when  m ≥4 . We show that the product of all the eigenvalues is equal to the value of the symmetric hyperdeterminant, while the sum of all the eigenvalues is equal to the sum of the diagonal elements of that supersymmetric tensor, multiplied by  ( m −1) n −1 . The  n ( m −1) n −1  eigenvalues are distributed in  n  disks in  inlMMLBox . The centers and radii of these  n  disks are the diagonal elements, and the sums of the absolute values of the corresponding off-diagonal elements, of that supersymmetric tensor. On the other hand, E-eigenvalues are invariant under orthogonal transformations.},
    author = {Qi, L.},
    citeulike-article-id = {6628551},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.jsc.2005.05.007},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0747717105000817},
    doi = {10.1016/j.jsc.2005.05.007},
    issn = {07477171},
    journal = {Journal of Symbolic Computation},
    month = {December},
    number = {6},
    pages = {1302--1324},
    posted-at = {2010-02-04 22:56:48},
    priority = {2},
    title = {Eigenvalues of a real supersymmetric tensor},
    url = {http://dx.doi.org/10.1016/j.jsc.2005.05.007},
    volume = {40},
    year = {2005}
}

@article{Lim2006Singular,
    abstract = {We propose a theory of eigenvalues, eigenvectors, singular values, and
singular vectors for tensors based on a constrained variational approach much
like the Rayleigh quotient for symmetric matrix eigenvalues. These notions are
particularly useful in generalizing certain areas where the spectral theory of
matrices has traditionally played an important role. For illustration, we will
discuss a multilinear generalization of the Perron-Frobenius theorem.},
    archivePrefix = {arXiv},
    author = {Lim, Lek-Heng},
    citeulike-article-id = {780719},
    citeulike-linkout-0 = {http://arxiv.org/abs/math.SP/0607648},
    citeulike-linkout-1 = {http://arxiv.org/pdf/math.SP/0607648},
    day = {26},
    eprint = {math.SP/0607648},
    month = {Jul},
    posted-at = {2010-02-04 22:52:58},
    priority = {2},
    title = {Singular Values and Eigenvalues of Tensors: A Variational Approach},
    url = {http://arxiv.org/abs/math.SP/0607648},
    year = {2006}
}

@article{Shi2000Normalized,
    abstract = {We propose a novel approach for solving the perceptual
grouping problem in vision. Rather than focusing
on local features and their consistencies in the
image data, our approach aims at extracting the global
impression of an image. We treat image segmentation
as a graph partitioning problem and propose a
novel global criterion, the normalized cut, for segmenting
the graph. The normalized cut criterion measures
both the total dissimilarity between the different groups
as well as the total...},
    author = {Shi, Jianbo and Malik, Jitendra},
    citeulike-article-id = {801014},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.42.7500},
    journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
    number = {8},
    pages = {888--905},
    posted-at = {2010-02-04 22:52:06},
    priority = {2},
    title = {Normalized Cuts and Image Segmentation},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.42.7500},
    volume = {22},
    year = {2000}
}

@phdthesis{Jin2006Probabilistic,
    author = {Jin, Ya},
    citeulike-article-id = {6628548},
    month = {May},
    posted-at = {2010-02-04 22:51:31},
    priority = {2},
    school = {Brown},
    title = {Probabilistic Hierarchical Image Models},
    year = {2006}
}

@inbook{gestalt,
    author = {Wertheimer, M.},
    booktitle = {A Sourcebook of Gestalt Psychology},
    citeulike-article-id = {6628541},
    citeulike-linkout-0 = {http://psychclassics.asu.edu/Wertheimer/Forms/forms.htm},
    editor = {Ellis, W. B.},
    pages = {71--88},
    posted-at = {2010-02-04 22:46:30},
    priority = {2},
    publisher = {Harcourt, Brace},
    title = {Laws of Organization in Perceptual Forms (partial translation)},
    url = {http://psychclassics.asu.edu/Wertheimer/Forms/forms.htm},
    year = {1938}
}

@inproceedings{Mcdonald2005Nonprojective,
    abstract = {We formalize weighted dependency parsing as searching for maximum spanning trees (MSTs) in directed graphs. Using this representation, the parsing algorithm of Eisner (1996) is sufficient for searching over all projective trees in O(n 3) time. More surprisingly, the representation is extended naturally to non-projective parsing using Chu-Liu-Edmonds (Chu and Liu, 1965; Edmonds, 1967) MST algorithm, yielding an O(n 2) parsing algorithm. We evaluate these methods on the Prague Dependency Treebank using online large-margin learning techniques (Crammer et al., 2003; McDonald et al., 2005) and show that MST parsing increases efficiency and accuracy for languages with non-projective dependencies. 1},
    author = {Mcdonald, Ryan and Pereira, Fernando and Ribarov, Kiril and Haji\v{c}, Jan},
    booktitle = {In Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing},
    citeulike-article-id = {6628540},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.84.2066},
    pages = {523--530},
    posted-at = {2010-02-04 22:43:05},
    priority = {2},
    title = {Non-projective dependency parsing using spanning tree algorithms},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.84.2066},
    year = {2005}
}

@article{Tarjan1977Finding,
    abstract = {Chu and Liu, Edmonds, and Bock have independently devised an efficient algorithm to find an optimum branching in a directed graph. We give an implementation of the algorithm which runs in 0(m logn) time if the problem graph has n vertices and m edges. A modification for dense graphs gives a running time of 0(n2). We also show that the unmodified algorithm runs in 0(n(log n)2 +m) time on an average graph, assuming a uniform probability distribution.},
    address = {Stanford University Stanford, California},
    author = {Tarjan, R. E.},
    citeulike-article-id = {6628539},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/net.3230070103},
    citeulike-linkout-1 = {http://www3.interscience.wiley.com/cgi-bin/abstract/113393863/ABSTRACT},
    doi = {10.1002/net.3230070103},
    issn = {1097-0037},
    journal = {Networks},
    number = {1},
    pages = {25--35},
    posted-at = {2010-02-04 22:41:45},
    priority = {2},
    title = {Finding optimum branchings},
    url = {http://dx.doi.org/10.1002/net.3230070103},
    volume = {7},
    year = {1977}
}

@inproceedings{Koo2007Structured,
    abstract = {This paper provides an algorithmic framework for learning statistical models involving directed spanning trees, or equivalently non-projective dependency structures. We show how partition functions and marginals for directed spanning trees can be computed by an adaptation of Kirchhoff's Matrix-Tree Theorem. To demonstrate an application of the method, we perform experiments which use the algorithm in training both log-linear and max-margin dependency parsers. The new training methods give improvements in accuracy over perceptron-trained models. 1},
    author = {Koo, Terry and Globerson, Amir and Carreras, Xavier and Collins, Michael},
    booktitle = {In EMNLP-CoNLL},
    citeulike-article-id = {6628533},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.64.2843},
    posted-at = {2010-02-04 22:40:29},
    priority = {2},
    title = {Structured prediction models via the matrix-tree theorem},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.64.2843},
    year = {2007}
}

@inproceedings{Johnson1999Estimators,
    address = {Morristown, NJ, USA},
    author = {Johnson, Mark and Geman, Stuart and Canon, Stephen and Chi, Zhiyi and Riezler, Stefan},
    booktitle = {Proceedings of the 37th annual meeting of the Association for Computational Linguistics on Computational Linguistics},
    citeulike-article-id = {912421},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1034758},
    isbn = {1558606093},
    pages = {535--541},
    posted-at = {2010-02-04 22:39:09},
    priority = {2},
    publisher = {Association for Computational Linguistics},
    title = {Estimators for stochastic "Unification-Based" grammars},
    url = {http://portal.acm.org/citation.cfm?id=1034758},
    year = {1999}
}

@article{KleinMultiplesource,
    author = {Klein, Philip N.},
    citeulike-article-id = {6628526},
    posted-at = {2010-02-04 22:34:52},
    priority = {2},
    title = {Multiple-source shortest paths in planar graphs}
}

@inproceedings{hcm,
    abstract = {We describe a new hierarchical representation for two-dimensional objects that captures shape information at multiple levels of resolution. This representation is based on a hierarchical description of an object's boundary and can be used in an elastic matching framework, both for comparing pairs of objects and for detecting objects in cluttered images. In contrast to classical elastic models, our representation explicitly captures global shape information. This leads to richer geometric models and more accurate recognition results. Our experiments demonstrate classification results that are significantly better than the current state-of-the-art in several shape datasets. We also show initial experiments in matching shapes to cluttered images.},
    author = {Felzenszwalb, P. and Schwartz, J.},
    booktitle = {Computer Vision and Pattern Recognition, 2007. CVPR '07. IEEE Conference on},
    citeulike-article-id = {4245508},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/CVPR.2007.383018},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4270043},
    doi = {10.1109/CVPR.2007.383018},
    journal = {Computer Vision and Pattern Recognition, 2007. CVPR '07. IEEE Conference on},
    pages = {1--8},
    posted-at = {2010-02-04 22:29:26},
    priority = {2},
    title = {Hierarchical Matching of Deformable Shapes},
    url = {http://dx.doi.org/10.1109/CVPR.2007.383018},
    year = {2007}
}

@inproceedings{Mcallester1999Complexity,
    address = {London, UK},
    author = {Mcallester, David A.},
    booktitle = {SAS '99: Proceedings of the 6th International Symposium on Static Analysis},
    citeulike-article-id = {1813098},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=647168.718136},
    isbn = {3540664599},
    pages = {312--329},
    posted-at = {2010-02-04 22:27:11},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {On the Complexity Analysis of Static Analyses},
    url = {http://portal.acm.org/citation.cfm?id=647168.718136},
    year = {1999}
}

@misc{FakcharoenpholPlanar,
    abstract = {for finding shortest paths in a planar graph with real
weights.},
    author = {Fakcharoenphol, Jittat and Rao, Satish},
    citeulike-article-id = {504347},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.3.7229},
    posted-at = {2010-02-04 22:25:01},
    priority = {2},
    title = {Planar Graphs, Negative Weight Edges, Shortest Paths, and Near Linear Time},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.3.7229}
}

@inproceedings{Ren2005ScaleInvariant,
    address = {Washington, DC, USA},
    author = {Ren, Xiaofeng and Fowlkes, Charless C. and Malik, Jitendra},
    booktitle = {ICCV '05: Proceedings of the Tenth IEEE International Conference on Computer Vision},
    citeulike-article-id = {1232052},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1097115.1097782},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/ICCV.2005.213},
    doi = {10.1109/ICCV.2005.213},
    pages = {1214--1221},
    posted-at = {2010-02-04 22:24:37},
    priority = {2},
    publisher = {IEEE Computer Society},
    title = {Scale-Invariant Contour Completion Using Conditional Random Fields},
    url = {http://dx.doi.org/10.1109/ICCV.2005.213},
    year = {2005}
}

@article{Olson1997Automatic,
    abstract = {Abstract--- This paper describes techniques to perform efficient and accurate target recognition in difficult domains. In order to accurately model small, irregularly shaped targets, the target objects and images are represented by their edge maps, with a local orientation associated with each edge pixel. Threedimensional objects are modeled by a set of two-dimensional views of the object. Translation, rotation, and scaling of the views are allowed to approximate full three-dimensional motion of the object. A version of the Hausdorff measure that incorporates both location and orientation information is used to determine which positions of each object model are reported as possible target locations. These positions are determined efficiently through the examination of a hierarchical cell decomposition of the transformation space. This allows large volumes of the space to be pruned quickly. Additional techniques are used to decrease the computation time required by the method when matching is performed against a catalog of object models. The probability that this measure will yield a false alarm and efficient methods for estimating this probability at run-time are considered in detail. This information can be used to maintain a low false alarm rate or to rank competing hypotheses based on their likelihood of being a false alarm. Finally, results of the system recognizing objects in infrared and intensity images are given. I.},
    author = {Olson, Clark F. and Huttenlocher, Daniel P.},
    citeulike-article-id = {4123055},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.56.7573},
    journal = {IEEE Transactions on Image Processing},
    pages = {103--113},
    posted-at = {2010-02-04 22:23:48},
    priority = {2},
    title = {Automatic target recognition by matching oriented edge pixels},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.56.7573},
    volume = {6},
    year = {1997}
}

@article{Lafferty1996GibbsMarkov,
    author = {Lafferty, John D.},
    citeulike-article-id = {6628506},
    journal = {Computing Science and Statistics},
    pages = {370--377},
    posted-at = {2010-02-04 22:22:47},
    priority = {2},
    title = {Gibbs-Markov Models},
    volume = {27},
    year = {1996}
}

@book{grune-jacobs-90,
    abstract = {This 320-page book treats parsing in its own right, in greater depth than is found in most computer science and linguistics books. It offers a clear, accessible, and thorough discussion of many different parsing techniques with their interrelations and applicabilities, including error recovery techniques. Unlike most books, it treats (almost) all parsing methods, not just the popular ones. See Preface + Introduction and/or Table of Contents for a quick impression. The book features a 48 page...},
    address = {Chichester, England},
    author = {Grune, D. and Jacobs, C. J. H.},
    citeulike-article-id = {2570368},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.55.6774},
    keywords = {candidacyexam},
    posted-at = {2010-02-04 22:20:24},
    priority = {2},
    publisher = {Ellis Horwood Limited},
    title = {Parsing techniques: a practical guide},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.55.6774},
    year = {1990}
}

@phdthesis{Huang2001Compositional,
    author = {Huang, Shih-Hsiu},
    citeulike-article-id = {6628501},
    keywords = {candidacyexam},
    month = {May},
    posted-at = {2010-02-04 22:19:14},
    priority = {2},
    school = {Brown},
    title = {Compositional Approach to Recognition Using Multi-Scale Computations},
    year = {2001}
}

@book{Hofstadter1996Metamagical,
    abstract = {{A bestselling collection of brilliant and quirky essays, on subjects ranging from biology to grammar to artificial intelligence, that are unified by one primary concern: the way people perceive and think. }},
    author = {Hofstadter, Douglas R.},
    citeulike-article-id = {567103},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0465045669},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0465045669},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0465045669},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0465045669},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0465045669/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0465045669},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0465045669},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0465045669},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0465045669\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0465045669},
    day = {14},
    howpublished = {Paperback},
    isbn = {0465045669},
    keywords = {candidacyexam},
    month = {May},
    posted-at = {2010-02-04 22:06:42},
    priority = {2},
    publisher = {{HarperCollins Publishers}},
    title = {Metamagical Themas: Questing for the Essence of Mind and Pattern},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0465045669},
    year = {1996}
}

@article{Bod2009From,
    author = {Bod, Rens},
    citeulike-article-id = {6628476},
    issn = {0364-0213 / 1551-6709},
    journal = {Cognitive Science},
    keywords = {candidacyexam},
    pages = {752--793},
    posted-at = {2010-02-04 22:05:26},
    priority = {2},
    title = {From Exemplar to Grammar: A Probabilistic Analogy-Based MOdel of Language Learning},
    volume = {33},
    year = {2009}
}

@phdthesis{NevillManning1996Inferring,
    author = {Nevill-Manning, Craig G.},
    citeulike-article-id = {6628470},
    keywords = {candidacyexam},
    month = {May},
    posted-at = {2010-02-04 22:01:51},
    priority = {2},
    title = {Inferring Sequential Structure},
    year = {1996}
}

@article{deMarcken1995Unsupervised,
    author = {de Marcken, Carl},
    citeulike-article-id = {6596595},
    citeulike-linkout-0 = {http://www.demarcken.org/carl/papers/sigdat.pdf},
    keywords = {candidacyexam, grammar},
    posted-at = {2010-01-27 20:07:26},
    priority = {2},
    title = {On the Unsupervised Induction of Phrase Structure Grammars},
    url = {http://www.demarcken.org/carl/papers/sigdat.pdf},
    year = {1995}
}

@article{deMarcken1996Linguistic,
    author = {de Marcken, Carl},
    citeulike-article-id = {6596593},
    citeulike-linkout-0 = {http://www.demarcken.org/carl/papers/acl96.pdf},
    keywords = {candidacyexam, grammar},
    posted-at = {2010-01-27 20:06:13},
    priority = {2},
    title = {Linguistic Structure as Composition and Perturbation},
    url = {http://www.demarcken.org/carl/papers/acl96.pdf},
    year = {1996}
}

@phdthesis{deMarcken1996Unsupervised,
    author = {de Marcken, Carl},
    citeulike-article-id = {6596590},
    citeulike-linkout-0 = {http://www.demarcken.org/carl/papers/PhD.pdf},
    keywords = {candidacyexam, grammar},
    posted-at = {2010-01-27 20:03:06},
    priority = {2},
    title = {Unsupervised Language Acquisition},
    url = {http://www.demarcken.org/carl/papers/PhD.pdf},
    year = {1996}
}

@book{charniak,
    abstract = {{Eugene Charniak breaks new ground in artificial intelligence research by presenting statistical language processing from an artificial intelligence point of view in a text for researchers and scientists with a traditional computer science background.<br /> <br /> New, exacting empirical methods are needed to break the deadlock in such areas of artificial intelligence as robotics, knowledge representation, machine learning, machine translation, and natural language processing (NLP). It is time, Charniak observes, to switch paradigms. This text introduces statistical language processing techniques -- word tagging, parsing with probabilistic context free grammars, grammar induction, syntactic disambiguation, semantic word classes, word-sense disambiguation -- along with the underlying mathematics and chapter exercises.<br /> <br /> Charniak points out that as a method of attacking NLP problems, the statistical approach has several advantages. It is grounded in real text and therefore promises to produce usable results, and it offers an obvious way to approach learning: "one simply gathers statistics."<br /> <br /> <I>Language, Speech, and Communication</I>}},
    author = {Charniak, Eugene},
    citeulike-article-id = {1718353},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0262531410},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0262531410},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0262531410},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0262531410},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0262531410/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0262531410},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0262531410},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0262531410},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0262531410\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0262531410},
    day = {01},
    howpublished = {Paperback},
    isbn = {0262531410},
    keywords = {candidacyexam, grammar},
    month = {September},
    posted-at = {2010-01-27 19:51:32},
    priority = {2},
    publisher = {The MIT Press},
    title = {Statistical Language Learning (Language, Speech, and Communication)},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0262531410},
    year = {1996}
}

@book{manning-schutze,
    abstract = {"Statistical natural-language processing is, in my estimation, one of the most fast-moving and exciting areas of computer science these days. Anyone who wants to learn this field would be well advised to get this book. For that matter, the same goes for anyone who is already in the field. I know that it is going to be one of the most well-thumbed books on my bookshelf." -- Eugene Charniak, Department of Computer Science, Brown University <P>Statistical approaches to processing natural language text have become dominant in recent years. This foundational text is the first comprehensive introduction to statistical natural language processing (NLP) to appear. The book contains all the theory and algorithms needed for building NLP tools. It provides broad but rigorous coverage of mathematical and linguistic foundations, as well as detailed discussion of statistical methods, allowing students and researchers to construct their own implementations. The book covers collocation finding, word sense disambiguation, probabilistic parsing, information retrieval, and other applications. <P>More on this book},
    author = {Manning, Christopher D. and Sch\"{u}tze, Hinrich},
    citeulike-article-id = {105906},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0262133601},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0262133601},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0262133601},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0262133601},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0262133601/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0262133601},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0262133601},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0262133601},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0262133601\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0262133601},
    day = {18},
    edition = {1},
    howpublished = {Hardcover},
    isbn = {0262133601},
    keywords = {candidacyexam, grammar},
    month = {June},
    posted-at = {2010-01-27 19:51:04},
    priority = {2},
    publisher = {The MIT Press},
    title = {Foundations of Statistical Natural Language Processing},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0262133601},
    year = {1999}
}

@book{Bod2003Probabilistic,
    abstract = {For the past forty years, linguistics has been dominated by the idea that language is categorical and linguistic competence discrete. It has become increasingly clear, however, that many levels of representation, from phonemes to sentence structure, show probabilistic properties, as does the language faculty. Probabilistic linguistics conceptualizes categories as distributions and views knowledge of language not as a minimal set of categorical constraints but as a set of gradient rules that may be characterized by a statistical distribution. Whereas categorical approaches focus on the endpoints of distributions of linguistic phenomena, probabilistic approaches focus on the gradient middle ground. Probabilistic linguistics integrates all the progress made by linguistics thus far with a probabilistic perspective.<br /> <br /> This book presents a comprehensive introduction to probabilistic approaches to linguistic inquiry. It covers the application of probabilistic techniques to phonology, morphology, semantics, syntax, language acquisition, psycholinguistics, historical linguistics, and sociolinguistics. It also includes a tutorial on elementary probability theory and probabilistic grammars.},
    author = {Bod, Rens},
    citeulike-article-id = {238798},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0262523388},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0262523388},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0262523388},
    citeulike-linkout-3 = {http://www.amazon.co.uk/exec/obidos/ASIN/0262523388/citeulike00-21},
    citeulike-linkout-4 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0262523388},
    citeulike-linkout-5 = {http://www.worldcat.org/isbn/0262523388},
    citeulike-linkout-6 = {http://books.google.com/books?vid=ISBN0262523388},
    citeulike-linkout-7 = {http://www.amazon.com/gp/search?keywords=0262523388\&index=books\&linkCode=qs},
    citeulike-linkout-8 = {http://www.librarything.com/isbn/0262523388},
    day = {01},
    howpublished = {Paperback},
    isbn = {0262523388},
    keywords = {candidacyexam, grammar},
    month = {April},
    posted-at = {2010-01-27 19:50:19},
    priority = {2},
    publisher = {The MIT Press},
    title = {Probabilistic Linguistics},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0262523388},
    year = {2003}
}

@book{Jurafsky2008Speech,
    abstract = {An explosion of Web-based language techniques, merging of distinct fields,
availability of phone-based dialogue systems, and much more make this an
exciting time in speech and language processing. The first of its kind to
thoroughly cover language technology – at all levels and with all modern
technologies – this book takes an empirical approach to the subject, based on
applying statistical and other machine-learning algorithms to large
corporations. Builds each chapter around one or more worked examples
demonstrating the main idea of the chapter, usingthe examples to illustrate
the relative strengths and weaknesses of various approaches. Adds coverage of
statistical sequence labeling, information extraction, question answering and
summarization, advanced topics in speech recognition, speech synthesis.
Revises coverage of language modeling, formal grammars, statistical parsing,
machine translation, and dialog processing. A useful reference for
professionals in any of the areas of speech and language processing.},
    author = {Jurafsky, Daniel and Martin, James H.},
    citeulike-article-id = {3153746},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0131873210},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0131873210},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0131873210},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0131873210},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0131873210/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0131873210},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0131873210},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0131873210},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0131873210\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0131873210},
    day = {26},
    edition = {2},
    howpublished = {Hardcover},
    isbn = {0131873210},
    keywords = {candidacyexam, grammar},
    month = {May},
    posted-at = {2010-01-27 19:49:25},
    priority = {2},
    publisher = {Prentice Hall},
    title = {Speech and Language Processing (2nd Edition)},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0131873210},
    year = {2008}
}

@book{Schutze1997Ambiguity,
    author = {Schutze, Hinrich},
    citeulike-article-id = {6596556},
    citeulike-linkout-0 = {http://standish.stanford.edu/bin/object?00000066},
    isbn = {1575860740},
    keywords = {candidacyexam, grammar},
    posted-at = {2010-01-27 19:47:51},
    priority = {2},
    title = {Ambiguity Resolution in Language Learning},
    url = {http://standish.stanford.edu/bin/object?00000066},
    year = {1997}
}

@article{Liu2009Nonparametric,
    abstract = {In this paper we propose a novel nonparametric approach for object recognition and scene parsing using dense scene alignment. Given an input image, we retrieve its best matches from a large database with annotated images using our modified, coarse-to-fine SIFT flow algorithm that aligns the structures within two images. Based on the dense scene correspondence obtained from the SIFT flow, our system warps the existing annotations, and integrates multiple cues in a Markov random field framework to segment and recognize the query image. Promising experimental results have been achieved by our nonparametric scene parsing system on a challenging database. Compared to existing object recognition approaches that require training for each object category, our system is easy to implement, has few parameters, and embeds contextual information naturally in the retrieval/alignment procedure.},
    address = {Los Alamitos, CA, USA},
    author = {Liu, Ce and Yuen, J. and Torralba, A.},
    citeulike-article-id = {6478953},
    citeulike-linkout-0 = {http://doi.ieeecomputersociety.org/10.1109/CVPRW.2009.5206536},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/CVPRW.2009.5206536},
    doi = {10.1109/CVPRW.2009.5206536},
    isbn = {978-1-4244-3992-8},
    journal = {Computer Vision and Pattern Recognition, IEEE Computer Society Conference on},
    pages = {1972--1979},
    posted-at = {2010-01-04 19:29:29},
    priority = {2},
    publisher = {IEEE Computer Society},
    title = {Nonparametric scene parsing: Label transfer via dense scene alignment},
    url = {http://dx.doi.org/10.1109/CVPRW.2009.5206536},
    volume = {0},
    year = {2009}
}

@article{Kent2004Simulation,
    abstract = {The complex Bingham distribution is relevant for the shape analysis of landmark data in two dimensions. In this paper it is shown that the problem of simulating from this distribution reduces to simulation from a truncated multivariate exponential distribution. Several simulation methods are described and their efficiencies are compared.},
    author = {Kent, John T. and Constable, Patrick D. L. and Er, Fikret},
    citeulike-article-id = {6201864},
    citeulike-linkout-0 = {http://dx.doi.org/10.1023/B:STCO.0000009414.14099.03},
    citeulike-linkout-1 = {http://www.springerlink.com/content/gjj8701924l94t54},
    day = {1},
    doi = {10.1023/B:STCO.0000009414.14099.03},
    journal = {Statistics and Computing},
    keywords = {monte\_carlo, sampling, watson},
    month = {January},
    number = {1},
    pages = {53--57},
    posted-at = {2009-11-24 05:44:22},
    priority = {2},
    title = {Simulation for the complex Bingham distribution},
    url = {http://dx.doi.org/10.1023/B:STCO.0000009414.14099.03},
    volume = {14},
    year = {2004}
}

@article{Mardia1999Complex,
    abstract = {The complex Watson distribution is an important simple distribution on the complex sphere which is used in statistical shape analysis. We describe the density, obtain the integrating constant and provide large sample approximations. Maximum likelihood estimation and hypothesis testing procedures for one and two samples are described. The particular connection with shape analysis is discussed and we consider an application examining shape differences between normal and schizophrenic brains. We make some observations about Bayesian shape inference and finally we describe a more general rotationally symmetric family of distributions.},
    author = {Mardia, K. V. and Dryden, I. L.},
    citeulike-article-id = {6200344},
    citeulike-linkout-0 = {http://dx.doi.org/10.2307/2680713},
    citeulike-linkout-1 = {http://www.jstor.org/stable/2680713},
    doi = {10.2307/2680713},
    issn = {13697412},
    journal = {Journal of the Royal Statistical Society. Series B (Statistical Methodology)},
    keywords = {candidacyexam, grammar, watson},
    number = {4},
    pages = {913--926},
    posted-at = {2009-11-23 23:40:52},
    priority = {2},
    publisher = {Blackwell Publishing for the Royal Statistical Society},
    title = {The Complex Watson Distribution and Shape Analysis},
    url = {http://dx.doi.org/10.2307/2680713},
    volume = {61},
    year = {1999}
}

@inproceedings{Bijral2007Mixture,
    abstract = {Machine learning applications often involve data that can be analyzed as unit vectors on a d-dimensional hypersphere, or equivalently are directional in nature. Spectral clustering techniques generate embeddings that constitute an example of directional data and can result in different shapes on a hypersphere (depending on the original structure). Other examples of directional data include text and some sub-domains of bioinformatics. The Watson distribution for directional data presents a tractable form and has more modeling capability than the simple von Mises-Fisher distribution. In this paper, we present a generative model of mixtures of Watson distributions on a hypersphere and derive numerical approximations of the parameters in an Expectation Maximization (EM) setting. This model also allows us to present an explanation for choosing the right embedding dimension for spectral clustering. We analyze the algorithm on a generated example and demonstrate its superiority over the existing algorithms through results on real datasets. 1},
    author = {Bijral, Avleen S. and Breitenbach, Markus and Grudic, Greg},
    booktitle = {In AI and Statistics},
    citeulike-article-id = {6199070},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.62.9059},
    keywords = {candidacyexam, grammar, watson},
    posted-at = {2009-11-23 20:16:05},
    priority = {2},
    title = {Mixture of watson distributions: A generative model for hyperspherical embeddings},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.62.9059},
    year = {2007}
}

@article{Green1995Reversible,
    abstract = {10.1093/biomet/82.4.711 Markov chain Monte Carlo methods for Bayesian computation have until recently been restricted to problems where the joint distribution of all variables has a density with respect to some fixed standard underlying measure. They have therefore not been available for application to Bayesian model determination, where the dimensionality of the parameter vector is typically not fixed. This paper proposes a new framework for the construction of reversible Markov chain samplers that jump between parameter subspaces of differing dimensionality, which is flexible and entirely constructive. It should therefore have wide applicability in model determination problems. The methodology is illustrated with applications to multiple change-point analysis in one and two dimensions, and to a Bayesian comparison of binomial experiments.},
    author = {Green, Peter J.},
    citeulike-article-id = {2529750},
    citeulike-linkout-0 = {http://dx.doi.org/10.1093/biomet/82.4.711},
    citeulike-linkout-1 = {http://biomet.oxfordjournals.org/content/82/4/711.abstract},
    citeulike-linkout-2 = {http://biomet.oxfordjournals.org/content/82/4/711.full.pdf},
    citeulike-linkout-3 = {http://biomet.oxfordjournals.org/cgi/content/abstract/82/4/711},
    day = {1},
    doi = {10.1093/biomet/82.4.711},
    journal = {Biometrika},
    keywords = {monte\_carlo},
    month = {December},
    number = {4},
    pages = {711--732},
    posted-at = {2009-10-20 16:16:08},
    priority = {2},
    title = {Reversible jump Markov chain Monte Carlo computation and Bayesian model determination},
    url = {http://dx.doi.org/10.1093/biomet/82.4.711},
    volume = {82},
    year = {1995}
}

@article{Kimia2003Euler,
    abstract = {In this paper we address the curve completion problem, e.g., the geometric continuation of boundaries of objects which are temporarily interrupted by occlusion. Also known as the gap completion or shape completion problem, this problem is a significant element of perceptual grouping of edge elements and has been approached by using cubic splines or biarcs which minimize total curvature squared (elastica), as motivated by a physical analogy. Our approach is motivated by railroad design methods of the early 1900's which connect two rail segments by  ” transition curves”, and by the work of Knuth on mathematical typography. We propose that in using an energy minimizing solution completion curves should not penalize curvature as in elastica but curvature variation. The minimization of total curvature variation leads to an Euler Spiral solution, a curve whose curvature varies linearly with arclength. We reduce the construction of this curve from a pair of points and tangents at these points to solving a nonlinear system of equations involving Fresnel Integrals, whose solution relies on optimization from a suitable initial condition constrained to satisfy given boundary conditions. Since the choice of an appropriate initial curve is critical in this optimization, we analytically derive an optimal solution in the class of biarc curves, which is then used as the initial curve. The resulting interpolations yield intuitive interpolation across gaps and occlusions, and are extensible, in contrast to the scale-invariant version of elastica. In addition, Euler Spiral segments can be used in other applications of curve completions, e.g., modeling boundary segments between curvature extrema or modeling skeletal branch geometry.},
    author = {Kimia, Benjamin and Frankel, Ilana and Popescu, Ana-Maria},
    citeulike-article-id = {5941554},
    citeulike-linkout-0 = {http://dx.doi.org/10.1023/A:1023713602895},
    citeulike-linkout-1 = {http://www.springerlink.com/content/m05l328421n82428},
    day = {21},
    doi = {10.1023/A:1023713602895},
    journal = {International Journal of Computer Vision},
    month = {August},
    number = {1},
    pages = {159--182},
    posted-at = {2009-10-14 23:04:35},
    priority = {2},
    title = {Euler Spiral for Shape Completion},
    url = {http://dx.doi.org/10.1023/A:1023713602895},
    volume = {54},
    year = {2003}
}

@misc{Klein2002Natural,
    abstract = {This paper presents a novel approach to the unsupervised learning of syntactic

analyses of natural language text. Most previous work has focused

on maximizing likelihood according to generative PCFG models. In contrast,

we employ a simpler probabilistic model over trees based directly

on constituent identity and linear context, and use an EM-like iterative

procedure to induce structure. This method produces much higher quality

analyses, giving the best published results on the ATIS...},
    author = {Klein, D. and Manning, C.},
    citeulike-article-id = {2924347},
    citeulike-linkout-0 = {http://citeseer.ist.psu.edu/klein01natural.html},
    citeulike-linkout-1 = {http://citeseer.lcs.mit.edu/klein01natural.html},
    citeulike-linkout-2 = {http://citeseer.ifi.unizh.ch/klein01natural.html},
    citeulike-linkout-3 = {http://citeseer.comp.nus.edu.sg/klein01natural.html},
    posted-at = {2009-08-31 18:52:58},
    priority = {2},
    title = {Natural language grammar induction using a constituent-context model},
    url = {http://citeseer.ist.psu.edu/klein01natural.html},
    year = {2002}
}

@article{zhu-chen-yuille,
    abstract = {We introduce a Probabilistic Grammar-Markov Model (PGMM) which couples probabilistic context free grammars and Markov Random Fields. These PGMMs are generative models defined over attributed features and are used to detect and classify objects in natural images. PGMMs are designed so that they can perform rapid inference, parameter learning, and the more difficult task of structure induction. PGMMs can deal with unknown 2D pose (position, orientation, and scale) in both inference and learning, different appearances, or aspects, of the model. The PGMMs can be learnt in an unsupervised manner where the image can contain one of an unknown number of objects of different categories or even be pure background. We first study the weakly supervised case, where each image contains an example of the (single) object of interest, and then generalize to less supervised cases. The goal of this paper is theoretical but, to provide proof of concept, we demonstrate results from this approach on a subset of the Caltech dataset (learning on a training set and evaluating on a testing set). Our results are generally comparable with the current state of the art, and our inference is performed in less than five seconds.},
    address = {Washington, DC, USA},
    author = {Zhu, Long and Chen, Yuanhao and Yuille, Alan},
    citeulike-article-id = {5666971},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1477526},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/TPAMI.2008.67},
    doi = {10.1109/TPAMI.2008.67},
    issn = {0162-8828},
    journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
    keywords = {candidacyexam, grammar},
    number = {1},
    pages = {114--128},
    posted-at = {2009-08-29 19:04:34},
    priority = {2},
    publisher = {IEEE Computer Society},
    title = {Unsupervised Learning of Probabilistic Grammar-Markov Models for Object Categories},
    url = {http://dx.doi.org/10.1109/TPAMI.2008.67},
    volume = {31},
    year = {2009}
}

@article{Caraballo1997New,
    abstract = {Best-first parsing methods for natural language try to parse efficiently by considering the most likely constituents first. Some figure of merit is needed by which to compare the likelihood of constituents, and the choice of this figure has a substantial impact on the efficiency of the parser. While several parsers described in the literature have used such techniques, there is little published data on their efficacy, much less attempts to judge their relative merits. We propose and evaluate several figures of merit for best-first parsing, and we identify an easily-computable figure of merit which provides excellent performance on various measures and two different grammars. 1 Introduction  Chart parsing is a commonly-used algorithm for parsing natural language texts. The chart is a data structure which contains all of the constituents for which subtrees have been found, that is, constituents for which a derivation has been found and which may therefore appear in some complete parse of...},
    author = {Caraballo, Sharon A. and Charniak, Eugene},
    citeulike-article-id = {5651192},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.52.6651},
    journal = {Computational Linguistics},
    keywords = {candidacyexam, grammar},
    pages = {275--298},
    posted-at = {2009-08-26 18:53:06},
    priority = {2},
    title = {New Figures of Merit for Best-First Probabilistic Chart Parsing},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.52.6651},
    volume = {24},
    year = {1997}
}

@article{zhu-han,
    abstract = {This paper presents a simple attribute graph grammar as a generative representation for made-made scenes, such as buildings, hallways, kitchens, and living rooms, and studies an effective top-down/bottom-up inference algorithm for parsing images in the process of maximizing a Bayesian posterior probability or equivalently minimizing a description length (MDL). Given an input image, the inference algorithm computes (or constructs) a parse graph, which includes a parse tree for the hierarchical decomposition and a number of spatial constraints. In the inference algorithm, the bottom-up step detects an excessive number of rectangles as weighted candidates, which are sorted in certain order and activate top-down predictions of occluded or missing components through the grammar rules. In the experiment, we show that the grammar and top-down inference can largely improve the performance of bottom-up detection.},
    address = {Washington, DC, USA},
    author = {Han, Feng and Zhu, Song C.},
    booktitle = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
    citeulike-article-id = {4719290},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1477072.1477522},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/TPAMI.2008.65},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4479470},
    doi = {10.1109/TPAMI.2008.65},
    issn = {0162-8828},
    journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
    keywords = {candidacyexam, grammar},
    number = {1},
    pages = {59--73},
    posted-at = {2009-08-26 18:30:27},
    priority = {2},
    publisher = {IEEE Computer Society},
    title = {Bottom-Up/Top-Down Image Parsing with Attribute Grammar},
    url = {http://dx.doi.org/10.1109/TPAMI.2008.65},
    volume = {31},
    year = {2009}
}

@article{zhu-tu-chen-yuille,
    author = {Tu, Zhuowen and Chen, Xiangrong and Yuille, Alan and Zhu, Song-Chun},
    citeulike-article-id = {156940},
    citeulike-linkout-0 = {http://dblp.uni-trier.de/rec/bibtex/journals/ijcv/TuCYZ05},
    citeulike-linkout-1 = {http://dx.doi.org/10.1007/s11263-005-6642-x},
    citeulike-linkout-2 = {http://www.ingentaconnect.com/content/klu/visi/2005/00000063/00000002/00006642},
    citeulike-linkout-3 = {http://www.springerlink.com/content/g1886t6163340314},
    doi = {10.1007/s11263-005-6642-x},
    issn = {0920-5691},
    journal = {International Journal of Computer Vision},
    keywords = {candidacyexam, grammar},
    month = {July},
    number = {2},
    pages = {113--140},
    posted-at = {2009-08-26 18:29:07},
    priority = {2},
    publisher = {Kluwer Academic Publishers},
    title = {Image Parsing: Unifying Segmentation, Detection, and Recognition},
    url = {http://dx.doi.org/10.1007/s11263-005-6642-x},
    volume = {63},
    year = {2005}
}

@article{zhu-mumford,
    abstract = {This exploratory paper quests for a stochastic and context sensitive grammar of images. The grammar should achieve the following four objectives and thus serves as a unified framework of representation, learning, and recognition for a large number of object categories. (i) The grammar represents both the hierarchical decompositions from scenes, to objects, parts, primitives and pixels by terminal and nonterminal nodes and the contexts for spatial and functional relations by horizontal links between the nodes. It formulates each object category as the set of all possible valid configurations produced by the grammar. (ii) The grammar is embodied in a simple And-Or graph representation where each Or-node points to alternative sub-configurations and an And-node is decomposed into a number of components. This representation supports recursive top-down/bottom-up procedures for image parsing under the Bayesian framework and make it convenient to scale up in complexity. Given an input image, the image parsing task constructs a most probable parse graph on-the-fly as the output interpretation and this parse graph is a subgraph of the And-Or graph after making choice on the Or-nodes. (iii) A probabilistic model is defined on this And-Or graph representation to account for the natural occurrence frequency of objects and parts as well as their relations. This model is learned from a relatively small training set per category and then sampled to synthesize a large number of configurations to cover novel object instances in the test set. This generalization capability is mostly missing in discriminative machine learning methods and can largely improve recognition performance in experiments. (iv) To fill the well-known semantic gap between symbols and raw signals, the grammar includes a series of visual dictionaries and organizes them through graph composition. At the bottom-level the dictionary is a set of image primitives each having a number of anchor points with open bonds to link with other primitives. These primitives can be combined to form larger and larger graph structures for parts and objects. The ambiguities in inferring local primitives shall be resolved through top-down computation using larger structures. Finally these primitives forms a primal sketch representation which will generate the input image with every pixels explained. The proposal grammar integrates three prominent representations in the literature: stochastic grammars for composition, Markov (or graphical) models for contexts, and sparse coding with primitives (wavelets). It also combines the structure-based and appearance based methods in the vision literature. Finally the paper presents three case studies to illustrate the proposed grammar.},
    address = {Hanover, MA, USA},
    author = {Zhu, Song C. and Mumford, David},
    citeulike-article-id = {3874677},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1315337},
    citeulike-linkout-1 = {http://dx.doi.org/10.1561/0600000018},
    doi = {10.1561/0600000018},
    issn = {1572-2740},
    journal = {Found. Trends. Comput. Graph. Vis.},
    number = {4},
    pages = {259--362},
    posted-at = {2009-08-26 18:27:56},
    priority = {2},
    publisher = {Now Publishers Inc.},
    title = {A stochastic grammar of images},
    url = {http://dx.doi.org/10.1561/0600000018},
    volume = {2},
    year = {2006}
}

@inproceedings{jin-geman,
    abstract = {It is widely conjectured that the excellent ROC performance of biological vision systems is due in large part to the exploitation of context at each of many levels in a part/whole hierarchy. We propose a mathematical framework (a "composition machine") for constructing probabilistic hierarchical image models, designed to accommodate arbitrary contextual relationships, and we build a demonstration system for reading Massachusetts license plates in an image set collected at Logan Airport. The demonstration system detects and correctly reads more than 98\% of the plates, with a negligible rate of false detection. Unlike a formal grammar, the architecture of a composition machine does not exclude the sharing of sub-parts among multiple entities, and does not limit interpretations to single trees (e.g. a scene can have multiple license plates, or no plates at all). In this sense, the architecture is more like a general Bayesian network than a formal grammar. On the other hand, unlike a Bayesian network, the distribution is non-Markovian, and therefore more like a probabilistic context-sensitive grammar. The conceptualization and construction of a composition machine is facilitated by its formulation as the result of a series of non-Markovian perturbations of a "Markov backbone."},
    author = {Jin, Ya and Geman, S.},
    booktitle = {Computer Vision and Pattern Recognition, 2006 IEEE Computer Society Conference on},
    citeulike-article-id = {2404441},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/CVPR.2006.86},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1641016},
    doi = {10.1109/CVPR.2006.86},
    journal = {Computer Vision and Pattern Recognition, 2006 IEEE Computer Society Conference on},
    keywords = {candidacyexam, grammar},
    pages = {2145--2152},
    posted-at = {2009-08-26 18:26:49},
    priority = {2},
    title = {Context and Hierarchy in a Probabilistic Image Model},
    url = {http://dx.doi.org/10.1109/CVPR.2006.86},
    volume = {2},
    year = {2006}
}

@article{potter-geman-bienenstock,
    author = {Bienenstock, Elie and Geman, Stuart and Potter, Daniel},
    citeulike-article-id = {5651122},
    citeulike-linkout-0 = {http://citeseer.ist.psu.edu/old/bienenstock97compositionality.html},
    keywords = {candidacyexam, grammar},
    posted-at = {2009-08-26 18:26:16},
    priority = {2},
    title = {Compositionality, MDL Priors, and Object Recognition},
    url = {http://citeseer.ist.psu.edu/old/bienenstock97compositionality.html}
}

@techreport{potter-geman-chi,
    author = {Geman, Stuart and Potter, Daniel F. and Chi, Zhiyi},
    citeulike-article-id = {5651119},
    citeulike-linkout-0 = {http://www.cs.umd.edu/\~{}djacobs/CMSC828/Composition\%2520Systems.pdf},
    institution = {Brown University},
    keywords = {candidacyexam, grammar},
    posted-at = {2009-08-26 18:24:20},
    priority = {2},
    title = {Composition Systems},
    url = {http://www.cs.umd.edu/\~{}djacobs/CMSC828/Composition\%2520Systems.pdf}
}

@inproceedings{Liu2008SIFT,
    abstract = {While image registration has been studied in different areas of computer vision, aligning images depicting different scenes remains a challenging problem, closer to recognition than to image matching. Analogous to optical flow, where an image is aligned to its temporally adjacent frame, we propose  SIFT flow , a method to align an image to its neighbors in a large image collection consisting of a variety of scenes. For a query image, histogram intersection on a bag-of-visual-words representation is used to find the set of nearest neighbors in the database. The SIFT flow algorithm then consists of matching densely sampled SIFT features between the two images, while preserving spatial discontinuities. The use of SIFT features allows robust matching across different scene/object appearances and the discontinuity-preserving spatial model allows matching of objects located at different parts of the scene. Experiments show that the proposed approach is able to robustly align complicated scenes with large spatial distortions. We collect a large database of videos and apply the SIFT flow algorithm to two applications: (i) motion field prediction from a single static image and (ii) motion synthesis via transfer of moving objects.},
    address = {Berlin, Heidelberg},
    author = {Liu, Ce and Yuen, Jenny and Torralba, Antonio and Sivic, Josef and Freeman, William T.},
    booktitle = {ECCV '08: Proceedings of the 10th European Conference on Computer Vision},
    citeulike-article-id = {4143297},
    citeulike-linkout-0 = {http://web.missouri.edu/\~{}hantx/ECE8001/notes/StudentPresentation/SIFT\_flow.pdf},
    citeulike-linkout-1 = {http://portal.acm.org/citation.cfm?id=1478176},
    citeulike-linkout-2 = {http://dx.doi.org/10.1007/978-3-540-88690-7\_3},
    doi = {10.1007/978-3-540-88690-7\_3},
    isbn = {978-3-540-88689-1},
    keywords = {keypoint},
    location = {Marseille, France},
    pages = {28--42},
    posted-at = {2009-08-25 19:57:43},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {SIFT Flow: Dense Correspondence across Different Scenes},
    url = {http://web.missouri.edu/\~{}hantx/ECE8001/notes/StudentPresentation/SIFT\_flow.pdf},
    year = {2008}
}

@phdthesis{stolcke,
    address = {Berkeley, CA, USA},
    author = {Stolcke, Andreas},
    citeulike-article-id = {165434},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=221997},
    keywords = {candidacyexam, grammar},
    posted-at = {2009-08-25 19:56:19},
    priority = {2},
    publisher = {University of California at Berkeley},
    title = {Bayesian learning of probabilistic language models},
    url = {http://portal.acm.org/citation.cfm?id=221997},
    year = {1994}
}

@article{cook,
    abstract = {A cost function is developed, based on information-theoretic concepts, that measures the complexity of a stochastic context-free grammar, as well as the discrepancy between its language and a given stochastic language sample. This function is used to guide a search procedure that finds simple grammars whose languages are good fits to a sample. Reasonable results have been obtained in a variety of cases, including parenthesis and addition strings, Basic English (the first 25 sentences in  English Through Pictures ) and chain-encoded chromosome boundaries.},
    author = {Cook, C.},
    citeulike-article-id = {5645610},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/0020-0255(76)90061-X},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/0020-0255(76)90061-X},
    doi = {10.1016/0020-0255(76)90061-X},
    issn = {00200255},
    journal = {Information Sciences},
    keywords = {candidacyexam, grammar},
    number = {1},
    pages = {59--80},
    posted-at = {2009-08-25 19:55:28},
    priority = {2},
    title = {Grammatical inference by hill climbing},
    url = {http://dx.doi.org/10.1016/0020-0255(76)90061-X},
    volume = {10},
    year = {1976}
}

@article{Mikolajczyk2005Performance,
    abstract = {In this paper, we compare the performance of descriptors computed for local interest regions, as, for example, extracted by the Harris-Affine detector [Mikolajczyk, K and Schmid, C, 2004]. Many different descriptors have been proposed in the literature. It is unclear which descriptors are more appropriate and how their performance depends on the interest region detector. The descriptors should be distinctive and at the same time robust to changes in viewing conditions as well as to errors of the detector. Our evaluation uses as criterion recall with respect to precision and is carried out for different image transformations. We compare shape context [Belongie, S, et al., April 2002], steerable filters [Freeman, W and Adelson, E, Setp. 1991], PCA-SIFT [Ke, Y and Sukthankar, R, 2004], differential invariants [Koenderink, J and van Doorn, A, 1987], spin images [Lazebnik, S, et al., 2003], SIFT [Lowe, D. G., 1999], complex filters [Schaffalitzky, F and Zisserman, A, 2002], moment invariants [Van Gool, L, et al., 1996], and cross-correlation for different types of interest regions. We also propose an extension of the SIFT descriptor and show that it outperforms the original method. Furthermore, we observe that the ranking of the descriptors is mostly independent of the interest region detector and that the SIFT-based descriptors perform best. Moments and steerable filters show the best performance among the low dimensional descriptors.},
    author = {Mikolajczyk, K. and Schmid, C.},
    citeulike-article-id = {828985},
    citeulike-linkout-0 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1498756},
    journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
    keywords = {keypoint},
    number = {10},
    pages = {1615--1630},
    posted-at = {2009-08-13 23:29:41},
    priority = {2},
    title = {A performance evaluation of local descriptors},
    url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1498756},
    volume = {27},
    year = {2005}
}

@article{Kofidis2002Best,
    abstract = {Abstract. Recently the problem of determining the best, in the least-squares sense, rank-1 approximation to a higher-order tensor was studied and an iterative method that extends the wellknown power method for matriceswasproposed for itssolution. Thishigher-order power method is also proposed for the special but important class of supersymmetric tensors, with no change. A simplified version, adapted to the special structure of the supersymmetric problem, is deemed unreliable, asitsconvergence isnot guaranteed. The aim of thispaper isto show that a symmetric version of the above method converges under assumptions of convexity (or concavity) for the functional induced by the tensor in question, assumptions that are very often satisfied in practical applications. The use of this version entails significant savings in computational complexity as compared to the unconstrained higher-order power method. Furthermore, a novel method for initializing the iterative processisdeveloped which hasbeen observed to yield an estimate that liescloser to the global optimum than the initialization suggested before. Moreover, its proximity to the global optimum is a priori quantifiable. In the course of the analysis, some important properties that the supersymmetry of a tensor implies for its square matrix unfolding are also studied.},
    author = {Kofidis, Eleftherios and Phillip and Regalia, A.},
    citeulike-article-id = {5430690},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.101.6035},
    journal = {SIAM J. Matrix Anal. Appl},
    keywords = {tensor},
    pages = {863--884},
    posted-at = {2009-08-13 07:06:00},
    priority = {2},
    title = {On the best rank-1 approximation of higher-order supersymmetric tensors},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.101.6035},
    volume = {23},
    year = {2002}
}

@proceedings{Parikh2007Hierarchical,
    abstract = {We introduce hSOs: hierarchical semantics of objects. An hSO is learnt from a collection of images taken from a particular scene category. The hSO captures the interactions between the objects that tend to co-occur in the scene, and hence are potentially semantically related. Such relationships are typically hierarchical. For example, in a collection of images taken in a living room scene, the TV, DVD player and coffee-table co-occur frequently. The TV and the DVD player are more closely related to each other than the coffee table, and this can be learnt from the fact that the two are located at similar relative locations across images, while the coffee table is somewhat arbitrarily placed. The goal of this paper is to learn this hierarchy that characterizes the scene. The proposed approach, being entirely unsupervised, can detect the parts of the images that belong to the foreground objects, cluster these parts to represent objects, and provide an understanding of the scene by hierarchically clustering these objects in a semantically meaningful way - all from a collection of unlabeled images of a particular scene category. In addition to providing the semantic layout of the scene, learnt hSOs can have several useful applications such as compact scene representation for scene category classification and providing context for enhanced object detection.},
    author = {Parikh, D. and Chen, Tsuhan},
    booktitle = {Computer Vision, 2007. ICCV 2007. IEEE 11th International Conference on},
    citeulike-article-id = {4446213},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/ICCV.2007.4408960},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4408960},
    doi = {10.1109/ICCV.2007.4408960},
    journal = {Computer Vision, 2007. ICCV 2007. IEEE 11th International Conference on},
    keywords = {candidacyexam, grammar},
    pages = {1--8},
    posted-at = {2009-08-10 16:28:25},
    priority = {2},
    title = {Hierarchical Semantics of Objects (hSOs)},
    url = {http://dx.doi.org/10.1109/ICCV.2007.4408960},
    year = {2007}
}

@inproceedings{Finley2008Training,
    abstract = {While discriminative training (e.g., CRF, structural SVM) holds much promise for machine translation, image segmentation, and clustering, the complex inference these applications require make exact training intractable. This leads to a need for approximate training methods. Unfortunately, knowledge about how to perform efficient and effective approximate training is limited. Focusing on structural SVMs, we provide and explore algorithms for two different classes of approximate training algorithms, which we call undergenerating (e.g., greedy) and overgenerating (e.g., relaxations) algorithms. We provide a theoretical and empirical analysis of both types of approximate trained structural SVMs, focusing on fully connected pairwise Markov random fields. We find that models trained with overgenerating methods have theoretic advantages over undergenerating methods, are empirically robust relative to their undergenerating brethren, and relaxed trained models favor non-fractional predictions from relaxed predictors.},
    address = {New York, NY, USA},
    author = {Finley, Thomas and Joachims, Thorsten},
    booktitle = {ICML '08: Proceedings of the 25th international conference on Machine learning},
    citeulike-article-id = {5375475},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1390195},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1390156.1390195},
    doi = {10.1145/1390156.1390195},
    isbn = {978-1-60558-205-4},
    keywords = {structured},
    location = {Helsinki, Finland},
    pages = {304--311},
    posted-at = {2009-08-06 00:00:39},
    priority = {2},
    publisher = {ACM},
    title = {Training structural SVMs when exact inference is intractable},
    url = {http://dx.doi.org/10.1145/1390156.1390195},
    year = {2008}
}

@article{Leordeanu2007Beyond,
    abstract = {We present a discriminative shape-based algorithm for object category localization and recognition. Our method learns object models in a weakly-supervised fashion, without requiring the specification of object locations nor pixel masks in the training data. We represent object models as cliques of fully-interconnected parts, exploiting only the pairwise geometric relationships between them. The use of pairwise relationships enables our algorithm to successfully overcome several problems that are common to previously-published methods. Even though our algorithm can easily incorporate local appearance information from richer features, we purposefully do not use them in order to demonstrate that simple geometric relationships can match (or exceed) the performance of state-of-the-art object recognition algorithms.},
    address = {Los Alamitos, CA, USA},
    author = {Leordeanu, Marius and Hebert, Martial and Sukthankar, Rahul},
    booktitle = {Computer Vision and Pattern Recognition, 2007. CVPR '07. IEEE Conference on},
    citeulike-article-id = {3496533},
    citeulike-linkout-0 = {http://doi.ieeecomputersociety.org/10.1109/CVPR.2007.383091},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/CVPR.2007.383091},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4270116},
    day = {22},
    doi = {10.1109/CVPR.2007.383091},
    isbn = {1-4244-1179-3},
    journal = {Computer Vision and Pattern Recognition, IEEE Computer Society Conference on},
    keywords = {tensor},
    month = {June},
    pages = {1--8},
    posted-at = {2009-08-05 23:56:44},
    priority = {2},
    publisher = {IEEE Computer Society},
    title = {Beyond Local Appearance: Category Recognition from Pairwise Interactions of Simple Features},
    url = {http://dx.doi.org/10.1109/CVPR.2007.383091},
    volume = {0},
    year = {2007}
}

@article{Hinton2006Fast,
    abstract = {We show how to use "complementary priors" to eliminate the explaining-away effects that make inference difficult in densely connected belief nets that have many hidden layers. Using complementary priors, we derive a fast, greedy algorithm that can learn deep, directed belief networks one layer at a time, provided the top two layers form an undirected associative memory. The fast, greedy algorithm is used to initialize a slower learning procedure that fine-tunes the weights using a contrastive version of the wake-sleep algorithm. After fine-tuning, a network with three hidden layers forms a very good generative model of the joint distribution of handwritten digit images and their labels. This generative model gives better digit classification than the best discriminative learning algorithms. The low-dimensional manifolds on which the digits lie are modeled by long ravines in the free-energy landscape of the top-level associative memory, and it is easy to explore these ravines by using the directed connections to display what the associative memory has in mind.},
    author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee-Whye},
    citeulike-article-id = {921697},
    citeulike-linkout-0 = {http://www.informatics.sussex.ac.uk/users/chrisla/papers/hinton06.pdf},
    citeulike-linkout-1 = {http://neco.mitpress.org/cgi/content/abstract/18/7/1527},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/16764513},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=16764513},
    day = {1},
    journal = {Neural Comp.},
    month = {July},
    number = {7},
    pages = {1527--1554},
    posted-at = {2009-08-05 23:53:59},
    priority = {2},
    title = {A Fast Learning Algorithm for Deep Belief Nets},
    url = {http://www.informatics.sussex.ac.uk/users/chrisla/papers/hinton06.pdf},
    volume = {18},
    year = {2006}
}

@article{Lazebnik2005Sparse,
    abstract = {This paper introduces a texture representation suitable for recognizing images of textured surfaces under a wide range of transformations, including viewpoint changes and nonrigid deformations. At the feature extraction stage, a sparse set of affine Harris and Laplacian regions is found in the image. Each of these regions can be thought of as a texture element having a characteristic elliptic shape and a distinctive appearance pattern. This pattern is captured in an affine-invariant fashion via a process of shape normalization followed by the computation of two novel descriptors, the spin image and the RIFT descriptor. When affine invariance is not required, the original elliptical shape serves as an additional discriminative feature for texture recognition. The proposed approach is evaluated in retrieval and classification tasks using the entire Brodatz database and a publicly available collection of 1,000 photographs of textured surfaces taken from different viewpoints.},
    author = {Lazebnik, S. and Schmid, C. and Ponce, J.},
    booktitle = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
    citeulike-article-id = {1647377},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/TPAMI.2005.151},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1453514},
    doi = {10.1109/TPAMI.2005.151},
    journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
    number = {8},
    pages = {1265--1278},
    posted-at = {2009-07-21 01:24:55},
    priority = {2},
    title = {A sparse texture representation using local affine regions},
    url = {http://dx.doi.org/10.1109/TPAMI.2005.151},
    volume = {27},
    year = {2005}
}

@inproceedings{Lazebnik2006Beyond,
    abstract = {This paper presents a method for recognizing scene categories based on approximate global geometric correspondence. This technique works by partitioning the image into increasingly fine sub-regions and computing histograms of local features found inside each sub-region. The resulting "spatial pyramid" is a simple and computationally efficient extension of an orderless bag-of-features image representation, and it shows significantly improved performance on challenging scene categorization tasks. Specifically, our proposed method exceeds the state of the art on the Caltech-101 database and achieves high accuracy on a large database of fifteen natural scene categories. The spatial pyramid framework also offers insights into the success of several recently proposed image descriptions, including Torralba's "gist" and Lowe's SIFT descriptors.},
    address = {Los Alamitos, CA, USA},
    author = {Lazebnik, S. and Schmid, C. and Ponce, J.},
    booktitle = {CVPR '06: Proceedings of the 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
    citeulike-article-id = {1720832},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1153549},
    citeulike-linkout-1 = {http://doi.ieeecomputersociety.org/10.1109/CVPR.2006.68},
    citeulike-linkout-2 = {http://dblp.uni-trier.de/rec/bibtex/conf/cvpr/LazebnikSP06},
    citeulike-linkout-3 = {http://dx.doi.org/10.1109/CVPR.2006.68},
    citeulike-linkout-4 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1641019},
    day = {09},
    doi = {10.1109/CVPR.2006.68},
    issn = {1063-6919},
    journal = {Computer Vision and Pattern Recognition, 2006 IEEE Computer Society Conference on},
    keywords = {bagofwords},
    location = {New York, NY, USA},
    month = {October},
    pages = {2169--2178},
    posted-at = {2009-07-21 01:24:51},
    priority = {2},
    publisher = {IEEE Computer Society},
    title = {Beyond Bags of Features: Spatial Pyramid Matching for Recognizing Natural Scene Categories},
    url = {http://dx.doi.org/10.1109/CVPR.2006.68},
    volume = {2},
    year = {2006}
}

@inproceedings{Csurka2004Visual,
    abstract = {Abstract. We present a novel method for generic visual categorization: the problem of identifying the object content of natural images while generalizing across variations inherent to the object class. This bag of keypoints method is based on vector quantization of affine invariant descriptors of image patches. We propose and compare two alternative implementations using different classifiers: Na\"{i}ve Bayes and SVM. The main advantages of the method are that it is simple, computationally efficient and intrinsically invariant. We present results for simultaneously classifying seven semantic visual categories. These results clearly demonstrate that the method is robust to background clutter and produces good categorization accuracy even without exploiting geometric information. 1.},
    author = {Csurka, Gabriella and Dance, Christopher R. and Fan, Lixin and Willamowski, Jutta and Bray, C\'{e}dric},
    booktitle = {In Workshop on Statistical Learning in Computer Vision, ECCV},
    citeulike-article-id = {4007958},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.72.604},
    keywords = {bagofwords},
    pages = {1--22},
    posted-at = {2009-07-21 01:23:32},
    priority = {2},
    title = {Visual categorization with bags of keypoints},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.72.604},
    year = {2004}
}

@inproceedings{Sun2008Least,
    abstract = {Canonical Correlation Analysis (CCA) is a well-known technique for finding the correlations between two sets of multi-dimensional variables. It projects both sets of variables into a lower-dimensional space in which they are maximally correlated. CCA is commonly applied for supervised dimensionality reduction, in which one of the multi-dimensional variables is derived from the class label. It has been shown that CCA can be formulated as a least squares problem in the binaryclass case. However, their relationship in the more general setting remains unclear. In this paper, we show that, under a mild condition which tends to hold for high-dimensional data, CCA in multi-label classifications can be formulated as a least squares problem. Based on this equivalence relationship, we propose several CCA extensions including sparse CCA using 1-norm regularization. Experiments on multi-label data sets confirm the established equivalence relationship. Results also demonstrate the effectiveness of the proposed CCA extensions.},
    address = {New York, NY, USA},
    author = {Sun, Liang and Ji, Shuiwang and Ye, Jieping},
    booktitle = {ICML '08: Proceedings of the 25th international conference on Machine learning},
    citeulike-article-id = {3781597},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1390156.1390285},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1390156.1390285},
    doi = {10.1145/1390156.1390285},
    isbn = {978-1-60558-205-4},
    location = {Helsinki, Finland},
    pages = {1024--1031},
    posted-at = {2009-07-21 01:16:50},
    priority = {2},
    publisher = {ACM},
    title = {A least squares formulation for canonical correlation analysis},
    url = {http://dx.doi.org/10.1145/1390156.1390285},
    year = {2008}
}

@inproceedings{Mikolajczyk2002Affine,
    abstract = {  This paper presents a novel approach for detecting affine invariant interest points. Our method can deal with significant affine transformations including large scale changes. Such transformations introduce significant changes in the point location as well as in the scale and the shape of the neighbourhood of an interest point. Our approach allows to solve for these problems simultaneously. It is based on three key ideas: 1) The second moment matrix computed in a point can be used to normalize a region in an affine invariant way (skew and stretch). 2) The scale of the local structure is indicated by local extrema of normalized derivatives over scale. 3) An affine-adapted Harris detector determines the location of interest points. Amulti-scale version of this detector is used for initialization. An iterative algorithm then modifies location, scale and neighbourhood of each point and converges to affine invariant points. For matching and recognition, the image is characterized by a set of affine invariant points; the affine transformation associated with each point allows the computation of an affine invariant descriptor which is also invariant to affine illumination changes. A quantitative comparison of our detector with existing ones shows a significant improvement in the presence of large affine deformations. Experimental results for wide baseline matching show an excellent performance in the presence of large perspective transformations including significant scale changes. Results for recognition are very good for a database with more than 5000 images.},
    author = {Mikolajczyk, Krystian and Schmid, Cordelia},
    booktitle = { Proc. European Conf. Computer Vision},
    citeulike-article-id = {4889589},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.19.4779},
    keywords = {keypoint},
    pages = {128--142},
    posted-at = {2009-07-21 01:14:16},
    priority = {2},
    title = {An affine invariant interest point detector},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.19.4779},
    volume = {2350},
    year = {2002}
}

