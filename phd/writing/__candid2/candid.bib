@article{Wolff1977Discovery,
    author = {Wolff, J. G.},
    citeulike-article-id = {3787370},
    journal = {British Journal of Psychology},
    pages = {97--106},
    posted-at = {2010-02-04 23:28:44},
    priority = {2},
    title = {The discovery of segments in natural language},
    volume = {68},
    year = {1977}
}



@article{Wolff1980Language,
    author = {Wolff, J. G.},
    citeulike-article-id = {3786946},
    citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/7432051},
    citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=7432051},
    issn = {0023-8309},
    journal = {Language and speech},
    number = {Pt 3},
    pages = {255--269},
    posted-at = {2010-02-04 23:28:12},
    priority = {2},
    title = {Language acquisition and the discovery of phrase structure.},
    url = {http://view.ncbi.nlm.nih.gov/pubmed/7432051},
    volume = {23},
    year = {1980}
}



@article{Wolff1982Language,
    author = {Wolff, J. G.},
    citeulike-article-id = {3787374},
    journal = {Language and Communication},
    pages = {57--89},
    posted-at = {2010-02-04 23:27:18},
    priority = {2},
    title = {Language acquisition, data compression and generalization},
    volume = {2},
    year = {1982}
}



@article{Cohen2007Voting,
    abstract = {We describe a statistical signature of chunks and an algorithm for finding chunks. While there is no formal definition of chunks, they may be reliably identified as configurations with low internal entropy or unpredictability and high entropy at their boundaries. We show that the log frequency of a chunk is a measure of its internal entropy. The Voting-Experts exploits the signature of chunks to find word boundaries in text from four languages and episode boundaries in the activities of a mobile robot.},
    address = {Amsterdam, The Netherlands, The Netherlands},
    author = {Cohen, Paul and Adams, Niall and Heeringa, Brent},
    citeulike-article-id = {6628581},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1368021},
    issn = {1088-467X},
    journal = {Intell. Data Anal.},
    number = {6},
    pages = {607--625},
    posted-at = {2010-02-04 23:25:59},
    priority = {2},
    publisher = {IOS Press},
    title = {Voting experts: An unsupervised algorithm for segmenting sequences},
    url = {http://portal.acm.org/citation.cfm?id=1368021},
    volume = {11},
    year = {2007}
}



@misc{EisnerNotes,
    author = {Eisner, Jason},
    citeulike-article-id = {6628579},
    citeulike-linkout-0 = {http://www.cs.jhu.edu/\~{}jason/465/iobasics.pdf},
    posted-at = {2010-02-04 23:23:07},
    priority = {2},
    title = {Notes on the Inside-Outside Algorithm},
    url = {http://www.cs.jhu.edu/\~{}jason/465/iobasics.pdf}
}



@unpublished{FelzenszwalbHierarchical,
    author = {Felzenszwalb, Pedro},
    citeulike-article-id = {6628577},
    posted-at = {2010-02-04 23:21:54},
    priority = {2},
    title = {Hierarchical Curve Models}
}



@article{Goldsmith2006Algorithm,
    abstract = {This paper describes in detail an algorithm for the unsupervised learning of natural language morphology, with emphasis on challenges that are encountered in languages typologically similar to European languages. It utilizes the Minimum Description Length analysis described in Goldsmith (2001), and has been implemented in software that is available for downloading and testing.},
    address = {New York, NY, USA},
    author = {Goldsmith, John},
    citeulike-article-id = {6628575},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1181162},
    citeulike-linkout-1 = {http://dx.doi.org/10.1017/S1351324905004055},
    doi = {10.1017/S1351324905004055},
    issn = {1351-3249},
    journal = {Nat. Lang. Eng.},
    number = {4},
    pages = {353--371},
    posted-at = {2010-02-04 23:18:59},
    priority = {2},
    publisher = {Cambridge University Press},
    title = {An algorithm for the unsupervised learning of morphology},
    url = {http://dx.doi.org/10.1017/S1351324905004055},
    volume = {12},
    year = {2006}
}



@electronic{NevillManning1997Identifying,
    abstract = {SEQUITUR is an algorithm that infers a hierarchical structure from a sequence of discrete symbols by replacing repeated phrases with a grammatical rule that generates the phrase, and continuing this process recursively. The result is a hierarchical representation of the original sequence, which offers insights into its lexical structure. The algorithm is driven by two constraints that reduce the size of the grammar, and produce structure as a by-product. SEQUITUR breaks new ground by operating incrementally. Moreover, the method's simple structure permits a proof that it operates in space and time that is linear in the size of the input. Our implementation can process 50,000 symbols per second and has been applied to an extensive range of real world sequences. 1. Introduction Many sequences of discrete symbols exhibit natural hierarchical structure. Text is made up of paragraphs, sentences, phrases, and words. Music is composed from major sections, motifs, bars, and notes. Records of ...},
    author = {Nevill-Manning, Craig G. and Witten, Ian H.},
    citeulike-article-id = {6628573},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.51.3846},
    posted-at = {2010-02-04 23:16:36},
    priority = {2},
    title = {Identifying Hierarchical Structure in Sequences: A linear-time algorithm},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.51.3846},
    year = {1997}
}



@book{Dryden1998Statistical,
    author = {Dryden, I. L. and Mardia, Kanti V.},
    citeulike-article-id = {5636224},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0471958166},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0471958166},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0471958166},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0471958166},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0471958166/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0471958166},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0471958166},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0471958166},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0471958166\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0471958166},
    day = {02},
    edition = {1},
    howpublished = {Hardcover},
    isbn = {0471958166},
    month = {September},
    posted-at = {2010-02-04 23:15:46},
    priority = {2},
    publisher = {Wiley},
    title = {Statistical Shape Analysis},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0471958166},
    year = {1998}
}



@inproceedings{Schutze1995Distributional,
    abstract = {This paper presents an algorithm for tagging words whose part-of-speech properties are unknown. Unlike previous work, the algorithm categorizes  word tokens in context  instead of  word types . The algorithm is evaluated on the Brown Corpus.},
    address = {San Francisco, CA, USA},
    author = {Sch\"{u}tze, Hinrich},
    booktitle = {Proceedings of the seventh conference on European chapter of the Association for Computational Linguistics},
    citeulike-article-id = {165339},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=976994},
    citeulike-linkout-1 = {http://dx.doi.org/10.3115/976973.976994},
    doi = {10.3115/976973.976994},
    location = {Dublin, Ireland},
    pages = {141--148},
    posted-at = {2010-02-04 23:15:07},
    priority = {2},
    publisher = {Morgan Kaufmann Publishers Inc.},
    title = {Distributional part-of-speech tagging},
    url = {http://dx.doi.org/10.3115/976973.976994},
    year = {1995}
}



@inproceedings{Clark2001Unsupervised,
    abstract = {An algorithm is presented for learning a phrase-structure grammar from tagged text. It clusters sequences of tags together based on local distributional information, and selects clusters that satisfy a novel mutual information criterion. This criterion is shown to be related to the entropy of a random variable associated with the tree structures, and it is demonstrated that it selects linguistically plausible constituents. This is incorporated in a Minimum Description Length algorithm. The evaluation of unsupervised models is discussed, and results are presented when the algorithm has been trained on 12 million words of the British National Corpus.},
    address = {Morristown, NJ, USA},
    author = {Clark, Alexander},
    booktitle = {ConLL '01: Proceedings of the 2001 workshop on Computational Natural Language Learning},
    citeulike-article-id = {2873598},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1117831},
    citeulike-linkout-1 = {http://dx.doi.org/10.3115/1117822.1117831},
    doi = {10.3115/1117822.1117831},
    location = {Toulouse, France},
    pages = {1--8},
    posted-at = {2010-02-04 23:13:56},
    priority = {2},
    publisher = {Association for Computational Linguistics},
    title = {Unsupervised induction of stochastic context-free grammars using distributional clustering},
    url = {http://dx.doi.org/10.3115/1117822.1117831},
    year = {2001}
}



@electronic{KomodakisImage,
    abstract = {In this paper, a new exemplar-based framework is presented, which treats image completion, texture synthesis and image inpainting in a unified manner. In order to be able to avoid the occurrence of visually inconsistent results, we pose all of the above image-editing tasks in the form of a discrete global optimization problem. The objective function of this problem is always well-defined, and corresponds to the energy of a discrete Markov Random Field (MRF). For efficiently optimizing this MRF, a novel opti-mization scheme, called Priority-BP, is then proposed, which carries two very important extensions over the standard Belief Propagation (BP) algorithm:  ” priority-based message scheduling ” and  ” dynamic label pruning”. These two extensions work in cooperation to deal with the intolerable computational cost of BP, which is caused by the huge number of labels associated with our MRF. Moreover, both of our extensions are generic, since they do not rely on the use of domain-specific prior knowledge. They can therefore be applied to any MRF, i.e to a very wide class of problems in image processing and computer vision, thus managing to resolve what is currently considered as one major limitation of the Belief Propagation algorithm: its inefficiency in handling MRFs with very large discrete state-spaces. Experimental results on a wide variety of input images are presented, which demonstrate the effectiveness of our image-completion framework for tasks such as object removal, texture synthesis, text removal and image inpainting.},
    author = {Komodakis, Nikos and Tziritas, Georgios},
    citeulike-article-id = {6628571},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.109.1572},
    posted-at = {2010-02-04 23:12:52},
    priority = {2},
    title = {Image Completion Using Efficient Belief Propagation via Priority Scheduling and Dynamic Pruning},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.109.1572}
}



@techreport{Chanda2004Grammatical,
    author = {Chanda, Gaurav and Dellaert, Frank},
    citeulike-article-id = {6628570},
    citeulike-linkout-0 = {http://smartech.gatech.edu/handle/1853/3738},
    day = {29},
    institution = {Georgia Tech},
    month = {November},
    posted-at = {2010-02-04 23:12:03},
    priority = {2},
    title = {Grammatical Methods in Computer Vision: An Overview},
    url = {http://smartech.gatech.edu/handle/1853/3738},
    year = {2004}
}



@electronic{Bunke1996Recognition,
    abstract = {This paper provides a compelling illustration of the complexity of the mathematics-recognition task, of the many symbol configurations that must be considered. The authors state that syntactic approaches, using parsing, are untenable because the great variety of possible expressions makes it impossible to provide an a priori syntax definition for all possible expressions. This, combined with the computational complexity of parsing, motivates them to instead use a large collection of procedurally-coded recognition rules. Their comment about a priori syntax definition requires some clarification: any recognition method, including procedurally-coded rules, implicitly or explicitly defines the syntax of recognizable expressions. Apparently Okamoto et al. find it easier and more practical to provide an implicit syntax definition, coded as procedural rules, rather than an explicit syntax definition, coded as grammar rules.},
    author = {Bunke, H. and Blostein, Dorothea and Grbavec, Ann},
    citeulike-article-id = {6628568},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.52.67},
    posted-at = {2010-02-04 23:09:22},
    priority = {2},
    title = {Recognition Of Mathematical Notation},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.52.67},
    year = {1996}
}



@inproceedings{Lavirotte1998Mathematical,
    abstract = {This paper describes current results of OFR (Optical Formula Recognition), a system for extracting and understanding mathematical expressions in documents. Such a tool could be really useful to be able to re-use knowledge in scientific books which are not available in electronic form. We currently also study use of this system for direct input of formulas with a graphical tablet for computer algebra system softwares. Existing solutions for mathematical recognition have problems to analyze two dimensional expressions like vectors and matrices... This is because they often try to use extended classical grammar to analyze formulas, relatively to baseline. But a lot of mathematical notations do not respect rules for such a parsing and that is the reason why they fail to extend text parsing technic. We investigate graph grammar and graph rewriting as a solution to recognize two dimensional mathematical notations. Graph grammar provide a powerful formalism to describe structural manipulations...},
    author = {Lavirotte, St\'{e}phane and Pottier, Lo\"{i}c and Pottier, Lo\#c},
    booktitle = {In Proceedings of the SPIE},
    citeulike-article-id = {6628566},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.40.5752},
    pages = {44--52},
    posted-at = {2010-02-04 23:08:07},
    priority = {2},
    title = {Mathematical Formula Recognition Using Graph Grammar},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.40.5752},
    volume = {3305},
    year = {1998}
}



@incollection{Bolle1997Toward,
    abstract = {We are interested in processing video data for the purpose of solving a variety of problems in video search, analysis, indexing, browsing and compression. Instead of concentrating on a particular problem, in this paper we present a framework for developing video applications. Our basic thesis is that video data can be represented at a higher level of abstraction as a string generated by a grammar, termed motion picture grammar. The rules of that grammar relate different spatiotemporal representations of the video content and, in particular, representations of action.},
    address = {Berlin, Heidelberg},
    author = {Bolle, Ruud and Aloimonos, Yiannis and Ferm\"{u}ller, Cornelia},
    booktitle = {Computer Vision — ACCV'98 },
    chapter = {38},
    citeulike-article-id = {6628563},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/3-540-63931-4\_228},
    citeulike-linkout-1 = {http://www.springerlink.com/content/mg41245228833173},
    doi = {10.1007/3-540-63931-4\_228},
    editor = {Chin, Roland and Pong, Ting-Chuen},
    isbn = {978-3-540-63931-2},
    pages = {283--290},
    posted-at = {2010-02-04 23:06:58},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    series = {Lecture Notes in Computer Science},
    title = {Toward motion picture grammars},
    url = {http://dx.doi.org/10.1007/3-540-63931-4\_228},
    volume = {1352},
    year = {1997}
}



@article{Lee1992Character,
    abstract = {The recognition of Korean characters by a syntactic method is considered. Korean characters are composed of phonetic symbols in two dimensions and contain very little redundancy. In addition, the phonetic symbols in each character are different in shape and number depending on how they are composed. Thus, attribute information is important. A Korean character recognition algorithm based on an attribute-dependent programmed grammar is presented. The preprocessing and primitive extraction algorithm is also described. The algorithm was implemented and tested with more than 9600 Korean characters in pages randomly selected from children's story books. The algorithm based on the attribute-dependent programmed grammar recognized characters reasonably quickly, with more than 95.1\% accuracy.},
    address = {Washington, DC, USA},
    author = {Lee, Kyoon H. and Eom, Kie B. and Kashyap, R. L.},
    citeulike-article-id = {6628562},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=141786},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/34.166629},
    doi = {10.1109/34.166629},
    issn = {0162-8828},
    journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
    number = {11},
    pages = {1122--1128},
    posted-at = {2010-02-04 23:05:44},
    priority = {2},
    publisher = {IEEE Computer Society},
    title = {Character Recognition Based on Attribute-Dependent Programmed Grammar},
    url = {http://dx.doi.org/10.1109/34.166629},
    volume = {14},
    year = {1992}
}



@inproceedings{Richards1985Codon,
    abstract = {Codons are simple primitives for describing plane curves. They thus are primarily image-based descriptors. Yet they have the power to capture important information about the 3D world, such as making part boundaries explicit, The codon description is highly redundant (useful for error-correction). This redundancy can be viewed as a constraint on tile number of possible codon strings, For smooth closed strings that represent the bounding contour (silhouette) of many smooth 3D objects, tile constraints are so strong that sequences containing 6 elements yield only 33 generic shapes as compared with possible number of 15,625 combinations.},
    author = {Richards, Whitman and Hoffman, Donald D. and Richards, Codon C.},
    booktitle = {Computer Vision, Graphics, and Image Processing},
    citeulike-article-id = {6628560},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.18.5639},
    pages = {265--281},
    posted-at = {2010-02-04 23:05:01},
    priority = {2},
    title = {Codon constraints on closed 2D shapes},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.18.5639},
    volume = {31},
    year = {1985}
}



@inproceedings{Dreyer2009Graphical,
    address = {Singapore},
    author = {Dreyer, Markus and Eisner, Jason},
    booktitle = {Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing},
    citeulike-article-id = {5427355},
    citeulike-linkout-0 = {http://www.aclweb.org/anthology-new/D/D09/D09-1011.bib},
    citeulike-linkout-1 = {http://www.aclweb.org/anthology-new/D/D09/D09-1011.pdf},
    month = {August},
    pages = {101--110},
    posted-at = {2010-02-04 23:04:14},
    priority = {2},
    publisher = {Association for Computational Linguistics},
    title = {Graphical Models over Multiple Strings},
    url = {http://www.aclweb.org/anthology-new/D/D09/D09-1011.bib},
    year = {2009}
}



@inproceedings{Kumar2008What,
    abstract = {Many computer vision algorithms require searching a set of images for similar patches, which is a very expensive operation. In this work, we compare and evaluate a number of nearest neighbors algorithms for speeding up this task. Since image patches follow very different distributions from the uniform and Gaussian distributions that are typically used to evaluate nearest neighbors methods, we determine the method with the best performance via extensive experimentation on real images. Furthermore, we take advantage of the inherent structure and properties of images to achieve highly efficient implementations of these algorithms. Our results indicate that vantage point trees, which are not well known in the vision community, generally offer the best performance.},
    address = {Berlin, Heidelberg},
    author = {Kumar, Neeraj and Zhang, Li and Nayar, Shree},
    booktitle = {ECCV '08: Proceedings of the 10th European Conference on Computer Vision},
    citeulike-article-id = {6628557},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1479280},
    citeulike-linkout-1 = {http://dx.doi.org/10.1007/978-3-540-88688-4\_27},
    doi = {10.1007/978-3-540-88688-4\_27},
    isbn = {978-3-540-88685-3},
    location = {Marseille, France},
    pages = {364--378},
    posted-at = {2010-02-04 23:02:00},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {What Is a Good Nearest Neighbors Algorithm for Finding Similar Patches in Images?},
    url = {http://dx.doi.org/10.1007/978-3-540-88688-4\_27},
    year = {2008}
}



@article{Charniak97a,
    author = {Charniak, E.},
    citeulike-article-id = {931311},
    journal = {The AI Magazine},
    posted-at = {2010-02-04 23:00:39},
    priority = {2},
    title = {Statistical techniques for natural language parsing},
    year = {1997}
}



@article{Parikh2009Unsupervised,
    abstract = {A successful representation of objects in literature is as a collection of patches, or parts, with a certain appearance and position. The relative locations of the different parts of an object are constrained by the geometry of the object. Going beyond a single object, consider a collection of images of a particular scene category containing multiple (recurring) objects. The parts belonging to different objects are not constrained by such a geometry. However, the objects themselves, arguably due to their semantic relationships, demonstrate a pattern in their relative locations. Hence, analyzing the interactions among the parts across the collection of images can allow for extraction of the foreground objects, and analyzing the interactions among these objects can allow for a semantically meaningful grouping of these objects, which characterizes the entire scene. These groupings are typically hierarchical. We introduce hierarchical semantics of objects (hSO) that captures this hierarchical grouping. We propose an approach for the unsupervised learning of the hSO from a collection of images of a particular scene. We also demonstrate the use of the hSO in providing context for enhanced object localization in the presence of significant occlusions, and show its superior performance over a fully connected graphical model for the same task.},
    address = {New York, NY, United States},
    author = {Parikh, Devi and Chen, Tsuhan},
    citeulike-article-id = {6628555},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1608907},
    citeulike-linkout-1 = {http://dx.doi.org/10.1155/2009/184618},
    doi = {10.1155/2009/184618},
    issn = {1687-5176},
    journal = {J. Image Video Process.},
    pages = {1--16},
    posted-at = {2010-02-04 22:59:15},
    priority = {2},
    publisher = {Hindawi Publishing Corp.},
    title = {Unsupervised modeling of objects and their hierarchical contextual interactions},
    url = {http://dx.doi.org/10.1155/2009/184618},
    volume = {2009},
    year = {2009}
}



@inproceedings{Parikh09,
    abstract = {The visual world demonstrates organized spatial pat-
terns, among objects or regions in a scene, object-parts
in an object, and low-level features in object-parts. These
classes of spatial structures are inherently hierarchical in
nature. Although seemingly quite different these spatial pat-
terns are simply manifestations of different levels in a hier-
archy. In this work, we present a unified approach to un-
supervised learning of hierarchical spatial structures from
a collection of images. Ours is a hierarchical rule-based
model capturing spatial patterns, where each rule is repre-
sented by a star-graph. We propose an unsupervised EM-
style algorithm to learn our model from a collection of im-
ages. We show that the inference problem of determining
the set of learnt rules instantiated in an image is equiva-
lent to finding the minimum-cost Steiner tree in a directed
acyclic graph. We evaluate our approach on a diverse set
of data sets of object categories, natural outdoor scenes and
images from complex street scenes with multiple objects.},
    author = {Parikh, Devi and Zitnick, C. Lawrence and Chen, Tsuhan},
    booktitle = {IEEE Conference on Computer Vision and Pattern Recognition},
    citeulike-article-id = {5013745},
    citeulike-linkout-0 = {http://amp.ece.cmu.edu/Publication/Devi/ParikhZitnickChen\_CVPR\_2009\_steiner.pdf},
    posted-at = {2010-02-04 22:57:57},
    priority = {2},
    title = {Unsupervised Learning of Hierarchical Spatial Structures In Images},
    url = {http://amp.ece.cmu.edu/Publication/Devi/ParikhZitnickChen\_CVPR\_2009\_steiner.pdf},
    year = {2009}
}



@article{Qi2005Eigenvalues,
    abstract = {In this paper, we define the symmetric hyperdeterminant, eigenvalues and E-eigenvalues of a real supersymmetric tensor. We show that eigenvalues are roots of a one-dimensional polynomial, and when the order of the tensor is even, E-eigenvalues are roots of another one-dimensional polynomial. These two one-dimensional polynomials are associated with the symmetric hyperdeterminant. We call them the characteristic polynomial and the E-characteristic polynomial of that supersymmetric tensor. Real eigenvalues (E-eigenvalues) with real eigenvectors (E-eigenvectors) are called H-eigenvalues (Z-eigenvalues). When the order of the supersymmetric tensor is even, H-eigenvalues (Z-eigenvalues) exist and the supersymmetric tensor is positive definite if and only if all of its H-eigenvalues (Z-eigenvalues) are positive. An  inlMMLBox -order  n -dimensional supersymmetric tensor where  m  is even has exactly  n ( m −1) n −1  eigenvalues, and the number of its E-eigenvalues is strictly less than  n ( m −1) n −1  when  m ≥4 . We show that the product of all the eigenvalues is equal to the value of the symmetric hyperdeterminant, while the sum of all the eigenvalues is equal to the sum of the diagonal elements of that supersymmetric tensor, multiplied by  ( m −1) n −1 . The  n ( m −1) n −1  eigenvalues are distributed in  n  disks in  inlMMLBox . The centers and radii of these  n  disks are the diagonal elements, and the sums of the absolute values of the corresponding off-diagonal elements, of that supersymmetric tensor. On the other hand, E-eigenvalues are invariant under orthogonal transformations.},
    author = {Qi, L.},
    citeulike-article-id = {6628551},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.jsc.2005.05.007},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0747717105000817},
    doi = {10.1016/j.jsc.2005.05.007},
    issn = {07477171},
    journal = {Journal of Symbolic Computation},
    month = {December},
    number = {6},
    pages = {1302--1324},
    posted-at = {2010-02-04 22:56:48},
    priority = {2},
    title = {Eigenvalues of a real supersymmetric tensor},
    url = {http://dx.doi.org/10.1016/j.jsc.2005.05.007},
    volume = {40},
    year = {2005}
}



@article{Lim2006Singular,
    abstract = {We propose a theory of eigenvalues, eigenvectors, singular values, and
singular vectors for tensors based on a constrained variational approach much
like the Rayleigh quotient for symmetric matrix eigenvalues. These notions are
particularly useful in generalizing certain areas where the spectral theory of
matrices has traditionally played an important role. For illustration, we will
discuss a multilinear generalization of the Perron-Frobenius theorem.},
    archivePrefix = {arXiv},
    author = {Lim, Lek-Heng},
    citeulike-article-id = {780719},
    citeulike-linkout-0 = {http://arxiv.org/abs/math.SP/0607648},
    citeulike-linkout-1 = {http://arxiv.org/pdf/math.SP/0607648},
    day = {26},
    eprint = {math.SP/0607648},
    month = {Jul},
    posted-at = {2010-02-04 22:52:58},
    priority = {2},
    title = {Singular Values and Eigenvalues of Tensors: A Variational Approach},
    url = {http://arxiv.org/abs/math.SP/0607648},
    year = {2006}
}



@article{Shi2000Normalized,
    abstract = {We propose a novel approach for solving the perceptual
grouping problem in vision. Rather than focusing
on local features and their consistencies in the
image data, our approach aims at extracting the global
impression of an image. We treat image segmentation
as a graph partitioning problem and propose a
novel global criterion, the normalized cut, for segmenting
the graph. The normalized cut criterion measures
both the total dissimilarity between the different groups
as well as the total...},
    author = {Shi, Jianbo and Malik, Jitendra},
    citeulike-article-id = {801014},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.42.7500},
    journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
    number = {8},
    pages = {888--905},
    posted-at = {2010-02-04 22:52:06},
    priority = {2},
    title = {Normalized Cuts and Image Segmentation},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.42.7500},
    volume = {22},
    year = {2000}
}



@phdthesis{Jin2006Probabilistic,
    author = {Jin, Ya},
    citeulike-article-id = {6628548},
    month = {May},
    posted-at = {2010-02-04 22:51:31},
    priority = {2},
    school = {Brown},
    title = {Probabilistic Hierarchical Image Models},
    year = {2006}
}



@inbook{Wertheimer1938Laws,
    author = {Wertheimer, M.},
    booktitle = {A Sourcebook of Gestalt Psychology},
    citeulike-article-id = {6628541},
    citeulike-linkout-0 = {http://psychclassics.asu.edu/Wertheimer/Forms/forms.htm},
    editor = {Ellis, W. B.},
    pages = {71--88},
    posted-at = {2010-02-04 22:46:30},
    priority = {2},
    publisher = {Harcourt, Brace},
    title = {Laws of Organization in Perceptual Forms (partial translation)},
    url = {http://psychclassics.asu.edu/Wertheimer/Forms/forms.htm},
    year = {1938}
}



@inproceedings{Mcdonald2005Nonprojective,
    abstract = {We formalize weighted dependency parsing as searching for maximum spanning trees (MSTs) in directed graphs. Using this representation, the parsing algorithm of Eisner (1996) is sufficient for searching over all projective trees in O(n 3) time. More surprisingly, the representation is extended naturally to non-projective parsing using Chu-Liu-Edmonds (Chu and Liu, 1965; Edmonds, 1967) MST algorithm, yielding an O(n 2) parsing algorithm. We evaluate these methods on the Prague Dependency Treebank using online large-margin learning techniques (Crammer et al., 2003; McDonald et al., 2005) and show that MST parsing increases efficiency and accuracy for languages with non-projective dependencies. 1},
    author = {Mcdonald, Ryan and Pereira, Fernando and Ribarov, Kiril and Haji\v{c}, Jan},
    booktitle = {In Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing},
    citeulike-article-id = {6628540},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.84.2066},
    pages = {523--530},
    posted-at = {2010-02-04 22:43:05},
    priority = {2},
    title = {Non-projective dependency parsing using spanning tree algorithms},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.84.2066},
    year = {2005}
}



@article{Tarjan1977Finding,
    abstract = {Chu and Liu, Edmonds, and Bock have independently devised an efficient algorithm to find an optimum branching in a directed graph. We give an implementation of the algorithm which runs in 0(m logn) time if the problem graph has n vertices and m edges. A modification for dense graphs gives a running time of 0(n2). We also show that the unmodified algorithm runs in 0(n(log n)2 +m) time on an average graph, assuming a uniform probability distribution.},
    address = {Stanford University Stanford, California},
    author = {Tarjan, R. E.},
    citeulike-article-id = {6628539},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/net.3230070103},
    citeulike-linkout-1 = {http://www3.interscience.wiley.com/cgi-bin/abstract/113393863/ABSTRACT},
    doi = {10.1002/net.3230070103},
    issn = {1097-0037},
    journal = {Networks},
    number = {1},
    pages = {25--35},
    posted-at = {2010-02-04 22:41:45},
    priority = {2},
    title = {Finding optimum branchings},
    url = {http://dx.doi.org/10.1002/net.3230070103},
    volume = {7},
    year = {1977}
}



@inproceedings{Koo2007Structured,
    abstract = {This paper provides an algorithmic framework for learning statistical models involving directed spanning trees, or equivalently non-projective dependency structures. We show how partition functions and marginals for directed spanning trees can be computed by an adaptation of Kirchhoff's Matrix-Tree Theorem. To demonstrate an application of the method, we perform experiments which use the algorithm in training both log-linear and max-margin dependency parsers. The new training methods give improvements in accuracy over perceptron-trained models. 1},
    author = {Koo, Terry and Globerson, Amir and Carreras, Xavier and Collins, Michael},
    booktitle = {In EMNLP-CoNLL},
    citeulike-article-id = {6628533},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.64.2843},
    posted-at = {2010-02-04 22:40:29},
    priority = {2},
    title = {Structured prediction models via the matrix-tree theorem},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.64.2843},
    year = {2007}
}



@inproceedings{Johnson1999Estimators,
    address = {Morristown, NJ, USA},
    author = {Johnson, Mark and Geman, Stuart and Canon, Stephen and Chi, Zhiyi and Riezler, Stefan},
    booktitle = {Proceedings of the 37th annual meeting of the Association for Computational Linguistics on Computational Linguistics},
    citeulike-article-id = {912421},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1034758},
    isbn = {1558606093},
    pages = {535--541},
    posted-at = {2010-02-04 22:39:09},
    priority = {2},
    publisher = {Association for Computational Linguistics},
    title = {Estimators for stochastic "Unification-Based" grammars},
    url = {http://portal.acm.org/citation.cfm?id=1034758},
    year = {1999}
}



@article{KleinMultiplesource,
    author = {Klein, Philip N.},
    citeulike-article-id = {6628526},
    posted-at = {2010-02-04 22:34:52},
    priority = {2},
    title = {Multiple-source shortest paths in planar graphs}
}



@proceedings{Felzenszwalb07,
    abstract = {We describe a new hierarchical representation for two-dimensional objects that captures shape information at multiple levels of resolution. This representation is based on a hierarchical description of an object's boundary and can be used in an elastic matching framework, both for comparing pairs of objects and for detecting objects in cluttered images. In contrast to classical elastic models, our representation explicitly captures global shape information. This leads to richer geometric models and more accurate recognition results. Our experiments demonstrate classification results that are significantly better than the current state-of-the-art in several shape datasets. We also show initial experiments in matching shapes to cluttered images.},
    author = {Felzenszwalb, P. and Schwartz, J.},
    booktitle = {Computer Vision and Pattern Recognition, 2007. CVPR '07. IEEE Conference on},
    citeulike-article-id = {4245508},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/CVPR.2007.383018},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4270043},
    doi = {10.1109/CVPR.2007.383018},
    journal = {Computer Vision and Pattern Recognition, 2007. CVPR '07. IEEE Conference on},
    pages = {1--8},
    posted-at = {2010-02-04 22:29:26},
    priority = {2},
    title = {Hierarchical Matching of Deformable Shapes},
    url = {http://dx.doi.org/10.1109/CVPR.2007.383018},
    year = {2007}
}



@inproceedings{Mcallester1999Complexity,
    address = {London, UK},
    author = {Mcallester, David A.},
    booktitle = {SAS '99: Proceedings of the 6th International Symposium on Static Analysis},
    citeulike-article-id = {1813098},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=647168.718136},
    isbn = {3540664599},
    pages = {312--329},
    posted-at = {2010-02-04 22:27:11},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {On the Complexity Analysis of Static Analyses},
    url = {http://portal.acm.org/citation.cfm?id=647168.718136},
    year = {1999}
}



@misc{FakcharoenpholPlanar,
    abstract = {for finding shortest paths in a planar graph with real
weights.},
    author = {Fakcharoenphol, Jittat and Rao, Satish},
    citeulike-article-id = {504347},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.3.7229},
    posted-at = {2010-02-04 22:25:01},
    priority = {2},
    title = {Planar Graphs, Negative Weight Edges, Shortest Paths, and Near Linear Time},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.3.7229}
}



@inproceedings{Ren2005ScaleInvariant,
    address = {Washington, DC, USA},
    author = {Ren, Xiaofeng and Fowlkes, Charless C. and Malik, Jitendra},
    booktitle = {ICCV '05: Proceedings of the Tenth IEEE International Conference on Computer Vision},
    citeulike-article-id = {1232052},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1097115.1097782},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/ICCV.2005.213},
    doi = {10.1109/ICCV.2005.213},
    pages = {1214--1221},
    posted-at = {2010-02-04 22:24:37},
    priority = {2},
    publisher = {IEEE Computer Society},
    title = {Scale-Invariant Contour Completion Using Conditional Random Fields},
    url = {http://dx.doi.org/10.1109/ICCV.2005.213},
    year = {2005}
}



@article{Olson1997Automatic,
    abstract = {Abstract--- This paper describes techniques to perform efficient and accurate target recognition in difficult domains. In order to accurately model small, irregularly shaped targets, the target objects and images are represented by their edge maps, with a local orientation associated with each edge pixel. Threedimensional objects are modeled by a set of two-dimensional views of the object. Translation, rotation, and scaling of the views are allowed to approximate full three-dimensional motion of the object. A version of the Hausdorff measure that incorporates both location and orientation information is used to determine which positions of each object model are reported as possible target locations. These positions are determined efficiently through the examination of a hierarchical cell decomposition of the transformation space. This allows large volumes of the space to be pruned quickly. Additional techniques are used to decrease the computation time required by the method when matching is performed against a catalog of object models. The probability that this measure will yield a false alarm and efficient methods for estimating this probability at run-time are considered in detail. This information can be used to maintain a low false alarm rate or to rank competing hypotheses based on their likelihood of being a false alarm. Finally, results of the system recognizing objects in infrared and intensity images are given. I.},
    author = {Olson, Clark F. and Huttenlocher, Daniel P.},
    citeulike-article-id = {4123055},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.56.7573},
    journal = {IEEE Transactions on Image Processing},
    pages = {103--113},
    posted-at = {2010-02-04 22:23:48},
    priority = {2},
    title = {Automatic target recognition by matching oriented edge pixels},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.56.7573},
    volume = {6},
    year = {1997}
}



@article{Lafferty1996GibbsMarkov,
    author = {Lafferty, John D.},
    citeulike-article-id = {6628506},
    journal = {Computing Science and Statistics},
    pages = {370--377},
    posted-at = {2010-02-04 22:22:47},
    priority = {2},
    title = {Gibbs-Markov Models},
    volume = {27},
    year = {1996}
}



@book{grune-jacobs-90,
    abstract = {This 320-page book treats parsing in its own right, in greater depth than is found in most computer science and linguistics books. It offers a clear, accessible, and thorough discussion of many different parsing techniques with their interrelations and applicabilities, including error recovery techniques. Unlike most books, it treats (almost) all parsing methods, not just the popular ones. See Preface + Introduction and/or Table of Contents for a quick impression. The book features a 48 page...},
    address = {Chichester, England},
    author = {Grune, D. and Jacobs, C. J. H.},
    citeulike-article-id = {2570368},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.55.6774},
    keywords = {candidacyexam},
    posted-at = {2010-02-04 22:20:24},
    priority = {2},
    publisher = {Ellis Horwood Limited},
    title = {Parsing techniques: a practical guide},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.55.6774},
    year = {1990}
}



@phdthesis{Huang2001Compositional,
    author = {Huang, Shih-Hsiu},
    citeulike-article-id = {6628501},
    keywords = {candidacyexam},
    month = {May},
    posted-at = {2010-02-04 22:19:14},
    priority = {2},
    school = {Brown},
    title = {Compositional Approach to Recognition Using Multi-Scale Computations},
    year = {2001}
}



@book{Hofstadter1996Metamagical,
    abstract = {{A bestselling collection of brilliant and quirky essays, on subjects ranging from biology to grammar to artificial intelligence, that are unified by one primary concern: the way people perceive and think. }},
    author = {Hofstadter, Douglas R.},
    citeulike-article-id = {567103},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0465045669},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0465045669},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0465045669},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0465045669},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0465045669/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0465045669},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0465045669},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0465045669},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0465045669\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0465045669},
    day = {14},
    howpublished = {Paperback},
    isbn = {0465045669},
    keywords = {candidacyexam},
    month = {May},
    posted-at = {2010-02-04 22:06:42},
    priority = {2},
    publisher = {{HarperCollins Publishers}},
    title = {Metamagical Themas: Questing for the Essence of Mind and Pattern},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0465045669},
    year = {1996}
}



@article{Bod2009From,
    author = {Bod, Rens},
    citeulike-article-id = {6628476},
    issn = {0364-0213 / 1551-6709},
    journal = {Cognitive Science},
    keywords = {candidacyexam},
    pages = {752--793},
    posted-at = {2010-02-04 22:05:26},
    priority = {2},
    title = {From Exemplar to Grammar: A Probabilistic Analogy-Based MOdel of Language Learning},
    volume = {33},
    year = {2009}
}



@phdthesis{NevillManning1996Inferring,
    author = {Nevill-Manning, Craig G.},
    citeulike-article-id = {6628470},
    keywords = {candidacyexam},
    month = {May},
    posted-at = {2010-02-04 22:01:51},
    priority = {2},
    title = {Inferring Sequential Structure},
    year = {1996}
}



@article{deMarcken1995Unsupervised,
    author = {de Marcken, Carl},
    citeulike-article-id = {6596595},
    citeulike-linkout-0 = {http://www.demarcken.org/carl/papers/sigdat.pdf},
    keywords = {candidacyexam, grammar},
    posted-at = {2010-01-27 20:07:26},
    priority = {2},
    title = {On the Unsupervised Induction of Phrase Structure Grammars},
    url = {http://www.demarcken.org/carl/papers/sigdat.pdf},
    year = {1995}
}



@article{deMarcken1996Linguistic,
    author = {de Marcken, Carl},
    citeulike-article-id = {6596593},
    citeulike-linkout-0 = {http://www.demarcken.org/carl/papers/acl96.pdf},
    keywords = {candidacyexam, grammar},
    posted-at = {2010-01-27 20:06:13},
    priority = {2},
    title = {Linguistic Structure as Composition and Perturbation},
    url = {http://www.demarcken.org/carl/papers/acl96.pdf},
    year = {1996}
}



@phdthesis{deMarcken1996Unsupervised,
    author = {de Marcken, Carl},
    citeulike-article-id = {6596590},
    citeulike-linkout-0 = {http://www.demarcken.org/carl/papers/PhD.pdf},
    keywords = {candidacyexam, grammar},
    posted-at = {2010-01-27 20:03:06},
    priority = {2},
    title = {Unsupervised Language Acquisition},
    url = {http://www.demarcken.org/carl/papers/PhD.pdf},
    year = {1996}
}



@book{Charniak1996Statistical,
    abstract = {{Eugene Charniak breaks new ground in artificial intelligence research by presenting statistical language processing from an artificial intelligence point of view in a text for researchers and scientists with a traditional computer science background.<br /> <br /> New, exacting empirical methods are needed to break the deadlock in such areas of artificial intelligence as robotics, knowledge representation, machine learning, machine translation, and natural language processing (NLP). It is time, Charniak observes, to switch paradigms. This text introduces statistical language processing techniques -- word tagging, parsing with probabilistic context free grammars, grammar induction, syntactic disambiguation, semantic word classes, word-sense disambiguation -- along with the underlying mathematics and chapter exercises.<br /> <br /> Charniak points out that as a method of attacking NLP problems, the statistical approach has several advantages. It is grounded in real text and therefore promises to produce usable results, and it offers an obvious way to approach learning: "one simply gathers statistics."<br /> <br /> <I>Language, Speech, and Communication</I>}},
    author = {Charniak, Eugene},
    citeulike-article-id = {1718353},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0262531410},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0262531410},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0262531410},
    citeulike-linkout-3 = {http://www.amazon.co.uk/exec/obidos/ASIN/0262531410/citeulike00-21},
    citeulike-linkout-4 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0262531410},
    citeulike-linkout-5 = {http://www.worldcat.org/isbn/0262531410},
    citeulike-linkout-6 = {http://books.google.com/books?vid=ISBN0262531410},
    citeulike-linkout-7 = {http://www.amazon.com/gp/search?keywords=0262531410\&index=books\&linkCode=qs},
    citeulike-linkout-8 = {http://www.librarything.com/isbn/0262531410},
    day = {01},
    howpublished = {Paperback},
    isbn = {0262531410},
    keywords = {candidacyexam, grammar},
    month = {September},
    posted-at = {2010-01-27 19:51:32},
    priority = {2},
    publisher = {{The MIT Press}},
    title = {Statistical Language Learning (Language, Speech, and Communication)},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0262531410},
    year = {1996}
}



@book{Manning1999,
    abstract = {"Statistical natural-language processing is, in my estimation, one of the most fast-moving and exciting areas of computer science these days. Anyone who wants to learn this field would be well advised to get this book. For that matter, the same goes for anyone who is already in the field. I know that it is going to be one of the most well-thumbed books on my bookshelf." -- Eugene Charniak, Department of Computer Science, Brown University <P>Statistical approaches to processing natural language text have become dominant in recent years. This foundational text is the first comprehensive introduction to statistical natural language processing (NLP) to appear. The book contains all the theory and algorithms needed for building NLP tools. It provides broad but rigorous coverage of mathematical and linguistic foundations, as well as detailed discussion of statistical methods, allowing students and researchers to construct their own implementations. The book covers collocation finding, word sense disambiguation, probabilistic parsing, information retrieval, and other applications. <P>More on this book},
    author = {Manning, Christopher D. and Sch\"{u}tze, Hinrich},
    citeulike-article-id = {105906},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0262133601},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0262133601},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0262133601},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0262133601},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0262133601/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0262133601},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0262133601},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0262133601},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0262133601\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0262133601},
    day = {18},
    edition = {1},
    howpublished = {Hardcover},
    isbn = {0262133601},
    keywords = {candidacyexam, grammar},
    month = {June},
    posted-at = {2010-01-27 19:51:04},
    priority = {2},
    publisher = {The MIT Press},
    title = {Foundations of Statistical Natural Language Processing},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0262133601},
    year = {1999}
}



@book{Bod2003Probabilistic,
    abstract = {For the past forty years, linguistics has been dominated by the idea that language is categorical and linguistic competence discrete. It has become increasingly clear, however, that many levels of representation, from phonemes to sentence structure, show probabilistic properties, as does the language faculty. Probabilistic linguistics conceptualizes categories as distributions and views knowledge of language not as a minimal set of categorical constraints but as a set of gradient rules that may be characterized by a statistical distribution. Whereas categorical approaches focus on the endpoints of distributions of linguistic phenomena, probabilistic approaches focus on the gradient middle ground. Probabilistic linguistics integrates all the progress made by linguistics thus far with a probabilistic perspective.<br /> <br /> This book presents a comprehensive introduction to probabilistic approaches to linguistic inquiry. It covers the application of probabilistic techniques to phonology, morphology, semantics, syntax, language acquisition, psycholinguistics, historical linguistics, and sociolinguistics. It also includes a tutorial on elementary probability theory and probabilistic grammars.},
    author = {Bod, Rens},
    citeulike-article-id = {238798},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0262523388},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0262523388},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0262523388},
    citeulike-linkout-3 = {http://www.amazon.co.uk/exec/obidos/ASIN/0262523388/citeulike00-21},
    citeulike-linkout-4 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0262523388},
    citeulike-linkout-5 = {http://www.worldcat.org/isbn/0262523388},
    citeulike-linkout-6 = {http://books.google.com/books?vid=ISBN0262523388},
    citeulike-linkout-7 = {http://www.amazon.com/gp/search?keywords=0262523388\&index=books\&linkCode=qs},
    citeulike-linkout-8 = {http://www.librarything.com/isbn/0262523388},
    day = {01},
    howpublished = {Paperback},
    isbn = {0262523388},
    keywords = {candidacyexam, grammar},
    month = {April},
    posted-at = {2010-01-27 19:50:19},
    priority = {2},
    publisher = {The MIT Press},
    title = {Probabilistic Linguistics},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0262523388},
    year = {2003}
}



@book{Jurafsky2008Speech,
    abstract = {An explosion of Web-based language techniques, merging of distinct fields,
availability of phone-based dialogue systems, and much more make this an
exciting time in speech and language processing. The first of its kind to
thoroughly cover language technology – at all levels and with all modern
technologies – this book takes an empirical approach to the subject, based on
applying statistical and other machine-learning algorithms to large
corporations. Builds each chapter around one or more worked examples
demonstrating the main idea of the chapter, usingthe examples to illustrate
the relative strengths and weaknesses of various approaches. Adds coverage of
statistical sequence labeling, information extraction, question answering and
summarization, advanced topics in speech recognition, speech synthesis.
Revises coverage of language modeling, formal grammars, statistical parsing,
machine translation, and dialog processing. A useful reference for
professionals in any of the areas of speech and language processing.},
    author = {Jurafsky, Daniel and Martin, James H.},
    citeulike-article-id = {3153746},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0131873210},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0131873210},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0131873210},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0131873210},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0131873210/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0131873210},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0131873210},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0131873210},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0131873210\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0131873210},
    day = {26},
    edition = {2},
    howpublished = {Hardcover},
    isbn = {0131873210},
    keywords = {candidacyexam, grammar},
    month = {May},
    posted-at = {2010-01-27 19:49:25},
    priority = {2},
    publisher = {Prentice Hall},
    title = {Speech and Language Processing (2nd Edition) (Prentice Hall Series in Artificial Intelligence)},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0131873210},
    year = {2008}
}



@book{Schutze1997Ambiguity,
    author = {Schutze, Hinrich},
    citeulike-article-id = {6596556},
    citeulike-linkout-0 = {http://standish.stanford.edu/bin/object?00000066},
    isbn = {1575860740},
    keywords = {candidacyexam, grammar},
    posted-at = {2010-01-27 19:47:51},
    priority = {2},
    title = {Ambiguity Resolution in Language Learning},
    url = {http://standish.stanford.edu/bin/object?00000066},
    year = {1997}
}



@article{Liu2009Nonparametric,
    abstract = {In this paper we propose a novel nonparametric approach for object recognition and scene parsing using dense scene alignment. Given an input image, we retrieve its best matches from a large database with annotated images using our modified, coarse-to-fine SIFT flow algorithm that aligns the structures within two images. Based on the dense scene correspondence obtained from the SIFT flow, our system warps the existing annotations, and integrates multiple cues in a Markov random field framework to segment and recognize the query image. Promising experimental results have been achieved by our nonparametric scene parsing system on a challenging database. Compared to existing object recognition approaches that require training for each object category, our system is easy to implement, has few parameters, and embeds contextual information naturally in the retrieval/alignment procedure.},
    address = {Los Alamitos, CA, USA},
    author = {Liu, Ce and Yuen, J. and Torralba, A.},
    citeulike-article-id = {6478953},
    citeulike-linkout-0 = {http://doi.ieeecomputersociety.org/10.1109/CVPRW.2009.5206536},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/CVPRW.2009.5206536},
    doi = {10.1109/CVPRW.2009.5206536},
    isbn = {978-1-4244-3992-8},
    journal = {Computer Vision and Pattern Recognition, IEEE Computer Society Conference on},
    pages = {1972--1979},
    posted-at = {2010-01-04 19:29:29},
    priority = {2},
    publisher = {IEEE Computer Society},
    title = {Nonparametric scene parsing: Label transfer via dense scene alignment},
    url = {http://dx.doi.org/10.1109/CVPRW.2009.5206536},
    volume = {0},
    year = {2009}
}



@article{Kent2004Simulation,
    abstract = {The complex Bingham distribution is relevant for the shape analysis of landmark data in two dimensions. In this paper it is shown that the problem of simulating from this distribution reduces to simulation from a truncated multivariate exponential distribution. Several simulation methods are described and their efficiencies are compared.},
    author = {Kent, John T. and Constable, Patrick D. L. and Er, Fikret},
    citeulike-article-id = {6201864},
    citeulike-linkout-0 = {http://dx.doi.org/10.1023/B:STCO.0000009414.14099.03},
    citeulike-linkout-1 = {http://www.springerlink.com/content/gjj8701924l94t54},
    day = {1},
    doi = {10.1023/B:STCO.0000009414.14099.03},
    journal = {Statistics and Computing},
    keywords = {monte\_carlo, sampling, watson},
    month = {January},
    number = {1},
    pages = {53--57},
    posted-at = {2009-11-24 05:44:22},
    priority = {2},
    title = {Simulation for the complex Bingham distribution},
    url = {http://dx.doi.org/10.1023/B:STCO.0000009414.14099.03},
    volume = {14},
    year = {2004}
}



@article{Mardia1999Complex,
    abstract = {The complex Watson distribution is an important simple distribution on the complex sphere which is used in statistical shape analysis. We describe the density, obtain the integrating constant and provide large sample approximations. Maximum likelihood estimation and hypothesis testing procedures for one and two samples are described. The particular connection with shape analysis is discussed and we consider an application examining shape differences between normal and schizophrenic brains. We make some observations about Bayesian shape inference and finally we describe a more general rotationally symmetric family of distributions.},
    author = {Mardia, K. V. and Dryden, I. L.},
    citeulike-article-id = {6200344},
    citeulike-linkout-0 = {http://dx.doi.org/10.2307/2680713},
    citeulike-linkout-1 = {http://www.jstor.org/stable/2680713},
    doi = {10.2307/2680713},
    issn = {13697412},
    journal = {Journal of the Royal Statistical Society. Series B (Statistical Methodology)},
    keywords = {grammar, watson},
    number = {4},
    pages = {913--926},
    posted-at = {2009-11-23 23:40:52},
    priority = {2},
    publisher = {Blackwell Publishing for the Royal Statistical Society},
    title = {The Complex Watson Distribution and Shape Analysis},
    url = {http://dx.doi.org/10.2307/2680713},
    volume = {61},
    year = {1999}
}



@inproceedings{Bijral2007Mixture,
    abstract = {Machine learning applications often involve data that can be analyzed as unit vectors on a d-dimensional hypersphere, or equivalently are directional in nature. Spectral clustering techniques generate embeddings that constitute an example of directional data and can result in different shapes on a hypersphere (depending on the original structure). Other examples of directional data include text and some sub-domains of bioinformatics. The Watson distribution for directional data presents a tractable form and has more modeling capability than the simple von Mises-Fisher distribution. In this paper, we present a generative model of mixtures of Watson distributions on a hypersphere and derive numerical approximations of the parameters in an Expectation Maximization (EM) setting. This model also allows us to present an explanation for choosing the right embedding dimension for spectral clustering. We analyze the algorithm on a generated example and demonstrate its superiority over the existing algorithms through results on real datasets. 1},
    author = {Bijral, Avleen S. and Breitenbach, Markus and Grudic, Greg},
    booktitle = {In AI and Statistics},
    citeulike-article-id = {6199070},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.62.9059},
    keywords = {grammar, watson},
    posted-at = {2009-11-23 20:16:05},
    priority = {2},
    title = {Mixture of watson distributions: A generative model for hyperspherical embeddings},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.62.9059},
    year = {2007}
}



@article{Green1995Reversible,
    abstract = {Markov chain Monte Carlo methods for Bayesian computation have until recently been restricted to problems where the joint distribution of all variables has a density with respect to some fixed standard underlying measure. They have therefore not been available for application to Bayesian model determination, where the dimensionality of the parameter vector is typically not fixed. This paper proposes a new framework for the construction of reversible Markov chain samplers that jump between parameter subspaces of differing dimensionality, which is flexible and entirely constructive. It should therefore have wide applicability in model determination problems. The methodology is illustrated with applications to multiple change-point analysis in one and two dimensions, and to a Bayesian comparison of binomial experiments. 10.1093/biomet/82.4.711},
    author = {Green, Peter J.},
    citeulike-article-id = {2529750},
    citeulike-linkout-0 = {http://dx.doi.org/10.1093/biomet/82.4.711},
    citeulike-linkout-1 = {http://biomet.oxfordjournals.org/content/82/4/711.abstract},
    citeulike-linkout-2 = {http://biomet.oxfordjournals.org/content/82/4/711.full.pdf},
    citeulike-linkout-3 = {http://biomet.oxfordjournals.org/cgi/content/abstract/82/4/711},
    day = {1},
    doi = {10.1093/biomet/82.4.711},
    journal = {Biometrika},
    keywords = {monte\_carlo},
    month = {December},
    number = {4},
    pages = {711--732},
    posted-at = {2009-10-20 16:16:08},
    priority = {2},
    title = {Reversible jump Markov chain Monte Carlo computation and Bayesian model determination},
    url = {http://dx.doi.org/10.1093/biomet/82.4.711},
    volume = {82},
    year = {1995}
}



@article{Kimia2003Euler,
    abstract = {In this paper we address the curve completion problem, e.g., the geometric continuation of boundaries of objects which are temporarily interrupted by occlusion. Also known as the gap completion or shape completion problem, this problem is a significant element of perceptual grouping of edge elements and has been approached by using cubic splines or biarcs which minimize total curvature squared (elastica), as motivated by a physical analogy. Our approach is motivated by railroad design methods of the early 1900's which connect two rail segments by  ” transition curves”, and by the work of Knuth on mathematical typography. We propose that in using an energy minimizing solution completion curves should not penalize curvature as in elastica but curvature variation. The minimization of total curvature variation leads to an Euler Spiral solution, a curve whose curvature varies linearly with arclength. We reduce the construction of this curve from a pair of points and tangents at these points to solving a nonlinear system of equations involving Fresnel Integrals, whose solution relies on optimization from a suitable initial condition constrained to satisfy given boundary conditions. Since the choice of an appropriate initial curve is critical in this optimization, we analytically derive an optimal solution in the class of biarc curves, which is then used as the initial curve. The resulting interpolations yield intuitive interpolation across gaps and occlusions, and are extensible, in contrast to the scale-invariant version of elastica. In addition, Euler Spiral segments can be used in other applications of curve completions, e.g., modeling boundary segments between curvature extrema or modeling skeletal branch geometry.},
    author = {Kimia, Benjamin and Frankel, Ilana and Popescu, Ana-Maria},
    citeulike-article-id = {5941554},
    citeulike-linkout-0 = {http://dx.doi.org/10.1023/A:1023713602895},
    citeulike-linkout-1 = {http://www.springerlink.com/content/m05l328421n82428},
    day = {21},
    doi = {10.1023/A:1023713602895},
    journal = {International Journal of Computer Vision},
    month = {August},
    number = {1},
    pages = {159--182},
    posted-at = {2009-10-14 23:04:35},
    priority = {2},
    title = {Euler Spiral for Shape Completion},
    url = {http://dx.doi.org/10.1023/A:1023713602895},
    volume = {54},
    year = {2003}
}



@misc{Klein2002Natural,
    abstract = {This paper presents a novel approach to the unsupervised learning of syntactic

analyses of natural language text. Most previous work has focused

on maximizing likelihood according to generative PCFG models. In contrast,

we employ a simpler probabilistic model over trees based directly

on constituent identity and linear context, and use an EM-like iterative

procedure to induce structure. This method produces much higher quality

analyses, giving the best published results on the ATIS...},
    author = {Klein, D. and Manning, C.},
    citeulike-article-id = {2924347},
    citeulike-linkout-0 = {http://citeseer.ist.psu.edu/klein01natural.html},
    citeulike-linkout-1 = {http://citeseer.lcs.mit.edu/klein01natural.html},
    citeulike-linkout-2 = {http://citeseer.ifi.unizh.ch/klein01natural.html},
    citeulike-linkout-3 = {http://citeseer.comp.nus.edu.sg/klein01natural.html},
    posted-at = {2009-08-31 18:52:58},
    priority = {2},
    title = {Natural language grammar induction using a constituent-context model},
    url = {http://citeseer.ist.psu.edu/klein01natural.html},
    year = {2002}
}



@article{Zhu2009Unsupervised,
    abstract = {We introduce a Probabilistic Grammar-Markov Model (PGMM) which couples probabilistic context free grammars and Markov Random Fields. These PGMMs are generative models defined over attributed features and are used to detect and classify objects in natural images. PGMMs are designed so that they can perform rapid inference, parameter learning, and the more difficult task of structure induction. PGMMs can deal with unknown 2D pose (position, orientation, and scale) in both inference and learning, different appearances, or aspects, of the model. The PGMMs can be learnt in an unsupervised manner where the image can contain one of an unknown number of objects of different categories or even be pure background. We first study the weakly supervised case, where each image contains an example of the (single) object of interest, and then generalize to less supervised cases. The goal of this paper is theoretical but, to provide proof of concept, we demonstrate results from this approach on a subset of the Caltech dataset (learning on a training set and evaluating on a testing set). Our results are generally comparable with the current state of the art, and our inference is performed in less than five seconds.},
    address = {Washington, DC, USA},
    author = {Zhu, Long and Chen, Yuanhao and Yuille, Alan},
    citeulike-article-id = {5666971},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1477526},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/TPAMI.2008.67},
    doi = {10.1109/TPAMI.2008.67},
    issn = {0162-8828},
    journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
    keywords = {grammar},
    number = {1},
    pages = {114--128},
    posted-at = {2009-08-29 19:04:34},
    priority = {2},
    publisher = {IEEE Computer Society},
    title = {Unsupervised Learning of Probabilistic Grammar-Markov Models for Object Categories},
    url = {http://dx.doi.org/10.1109/TPAMI.2008.67},
    volume = {31},
    year = {2009}
}



@article{Caraballo1997New,
    abstract = {Best-first parsing methods for natural language try to parse efficiently by considering the most likely constituents first. Some figure of merit is needed by which to compare the likelihood of constituents, and the choice of this figure has a substantial impact on the efficiency of the parser. While several parsers described in the literature have used such techniques, there is little published data on their efficacy, much less attempts to judge their relative merits. We propose and evaluate several figures of merit for best-first parsing, and we identify an easily-computable figure of merit which provides excellent performance on various measures and two different grammars. 1 Introduction  Chart parsing is a commonly-used algorithm for parsing natural language texts. The chart is a data structure which contains all of the constituents for which subtrees have been found, that is, constituents for which a derivation has been found and which may therefore appear in some complete parse of...},
    author = {Caraballo, Sharon A. and Charniak, Eugene},
    citeulike-article-id = {5651192},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.52.6651},
    journal = {Computational Linguistics},
    keywords = {grammar},
    pages = {275--298},
    posted-at = {2009-08-26 18:53:06},
    priority = {2},
    title = {New Figures of Merit for Best-First Probabilistic Chart Parsing},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.52.6651},
    volume = {24},
    year = {1997}
}



@article{Han2009BottomUpTopDown,
    abstract = {This paper presents a simple attribute graph grammar as a generative representation for made-made scenes, such as buildings, hallways, kitchens, and living rooms, and studies an effective top-down/bottom-up inference algorithm for parsing images in the process of maximizing a Bayesian posterior probability or equivalently minimizing a description length (MDL). Given an input image, the inference algorithm computes (or constructs) a parse graph, which includes a parse tree for the hierarchical decomposition and a number of spatial constraints. In the inference algorithm, the bottom-up step detects an excessive number of rectangles as weighted candidates, which are sorted in certain order and activate top-down predictions of occluded or missing components through the grammar rules. In the experiment, we show that the grammar and top-down inference can largely improve the performance of bottom-up detection.},
    author = {Han, Feng and Zhu, Song-Chun},
    booktitle = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
    citeulike-article-id = {4719290},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/TPAMI.2008.65},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4479470},
    doi = {10.1109/TPAMI.2008.65},
    journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
    keywords = {grammar},
    number = {1},
    pages = {59--73},
    posted-at = {2009-08-26 18:30:27},
    priority = {2},
    title = {Bottom-Up/Top-Down Image Parsing with Attribute Grammar},
    url = {http://dx.doi.org/10.1109/TPAMI.2008.65},
    volume = {31},
    year = {2009}
}



@article{Tu2005Image,
    author = {Tu, Zhuowen and Chen, Xiangrong and Yuille, Alan and Zhu, Song-Chun},
    citeulike-article-id = {156940},
    citeulike-linkout-0 = {http://dblp.uni-trier.de/rec/bibtex/journals/ijcv/TuCYZ05},
    citeulike-linkout-1 = {http://dx.doi.org/10.1007/s11263-005-6642-x},
    citeulike-linkout-2 = {http://www.ingentaconnect.com/content/klu/visi/2005/00000063/00000002/00006642},
    citeulike-linkout-3 = {http://www.springerlink.com/content/g1886t6163340314},
    doi = {10.1007/s11263-005-6642-x},
    issn = {0920-5691},
    journal = {International Journal of Computer Vision},
    keywords = {grammar},
    month = {July},
    number = {2},
    pages = {113--140},
    posted-at = {2009-08-26 18:29:07},
    priority = {2},
    publisher = {Kluwer Academic Publishers},
    title = {Image Parsing: Unifying Segmentation, Detection, and Recognition},
    url = {http://dx.doi.org/10.1007/s11263-005-6642-x},
    volume = {63},
    year = {2005}
}



@article{Zhu2006Stochastic,
    abstract = {This exploratory paper quests for a stochastic and context sensitive grammar of images. The grammar should achieve the following four objectives and thus serves as a unified framework of representation, learning, and recognition for a large number of object categories. (i) The grammar represents both the hierarchical decompositions from scenes, to objects, parts, primitives and pixels by terminal and nonterminal nodes and the contexts for spatial and functional relations by horizontal links between the nodes. It formulates each object category as the set of all possible valid configurations produced by the grammar. (ii) The grammar is embodied in a simple And-Or graph representation where each Or-node points to alternative sub-configurations and an And-node is decomposed into a number of components. This representation supports recursive top-down/bottom-up procedures for image parsing under the Bayesian framework and make it convenient to scale up in complexity. Given an input image, the image parsing task constructs a most probable parse graph on-the-fly as the output interpretation and this parse graph is a subgraph of the And-Or graph after making choice on the Or-nodes. (iii) A probabilistic model is defined on this And-Or graph representation to account for the natural occurrence frequency of objects and parts as well as their relations. This model is learned from a relatively small training set per category and then sampled to synthesize a large number of configurations to cover novel object instances in the test set. This generalization capability is mostly missing in discriminative machine learning methods and can largely improve recognition performance in experiments. (iv) To fill the well-known semantic gap between symbols and raw signals, the grammar includes a series of visual dictionaries and organizes them through graph composition. At the bottom-level the dictionary is a set of image primitives each having a number of anchor points with open bonds to link with other primitives. These primitives can be combined to form larger and larger graph structures for parts and objects. The ambiguities in inferring local primitives shall be resolved through top-down computation using larger structures. Finally these primitives forms a primal sketch representation which will generate the input image with every pixels explained. The proposal grammar integrates three prominent representations in the literature: stochastic grammars for composition, Markov (or graphical) models for contexts, and sparse coding with primitives (wavelets). It also combines the structure-based and appearance based methods in the vision literature. Finally the paper presents three case studies to illustrate the proposed grammar.},
    address = {Hanover, MA, USA},
    author = {Zhu, Song C. and Mumford, David},
    citeulike-article-id = {3874677},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1315337},
    citeulike-linkout-1 = {http://dx.doi.org/10.1561/0600000018},
    doi = {10.1561/0600000018},
    issn = {1572-2740},
    journal = {Found. Trends. Comput. Graph. Vis.},
    number = {4},
    pages = {259--362},
    posted-at = {2009-08-26 18:27:56},
    priority = {2},
    publisher = {Now Publishers Inc.},
    title = {A stochastic grammar of images},
    url = {http://dx.doi.org/10.1561/0600000018},
    volume = {2},
    year = {2006}
}



@proceedings{Jin2006Context,
    abstract = {It is widely conjectured that the excellent ROC performance of biological vision systems is due in large part to the exploitation of context at each of many levels in a part/whole hierarchy. We propose a mathematical framework (a "composition machine") for constructing probabilistic hierarchical image models, designed to accommodate arbitrary contextual relationships, and we build a demonstration system for reading Massachusetts license plates in an image set collected at Logan Airport. The demonstration system detects and correctly reads more than 98\% of the plates, with a negligible rate of false detection. Unlike a formal grammar, the architecture of a composition machine does not exclude the sharing of sub-parts among multiple entities, and does not limit interpretations to single trees (e.g. a scene can have multiple license plates, or no plates at all). In this sense, the architecture is more like a general Bayesian network than a formal grammar. On the other hand, unlike a Bayesian network, the distribution is non-Markovian, and therefore more like a probabilistic context-sensitive grammar. The conceptualization and construction of a composition machine is facilitated by its formulation as the result of a series of non-Markovian perturbations of a "Markov backbone."},
    author = {Jin, Ya and Geman, S.},
    booktitle = {Computer Vision and Pattern Recognition, 2006 IEEE Computer Society Conference on},
    citeulike-article-id = {2404441},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/CVPR.2006.86},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1641016},
    doi = {10.1109/CVPR.2006.86},
    journal = {Computer Vision and Pattern Recognition, 2006 IEEE Computer Society Conference on},
    keywords = {grammar},
    pages = {2145--2152},
    posted-at = {2009-08-26 18:26:49},
    priority = {2},
    title = {Context and Hierarchy in a Probabilistic Image Model},
    url = {http://dx.doi.org/10.1109/CVPR.2006.86},
    volume = {2},
    year = {2006}
}



@article{BienenstockCompositionality,
    author = {Bienenstock, Elie and Geman, Stuart and Potter, Daniel},
    citeulike-article-id = {5651122},
    citeulike-linkout-0 = {http://citeseer.ist.psu.edu/old/bienenstock97compositionality.html},
    keywords = {grammar},
    posted-at = {2009-08-26 18:26:16},
    priority = {2},
    title = {Compositionality, MDL Priors, and Object Recognition},
    url = {http://citeseer.ist.psu.edu/old/bienenstock97compositionality.html}
}



@techreport{GemanComposition,
    author = {Geman, Stuart and Potter, Daniel F. and Chi, Zhiyi},
    citeulike-article-id = {5651119},
    citeulike-linkout-0 = {http://www.cs.umd.edu/\~{}djacobs/CMSC828/Composition\%2520Systems.pdf},
    institution = {Brown University},
    keywords = {grammar},
    posted-at = {2009-08-26 18:24:20},
    priority = {2},
    title = {Composition Systems},
    url = {http://www.cs.umd.edu/\~{}djacobs/CMSC828/Composition\%2520Systems.pdf}
}



@inproceedings{Liu2008SIFT,
    abstract = {While image registration has been studied in different areas of computer vision, aligning images depicting different scenes remains a challenging problem, closer to recognition than to image matching. Analogous to optical flow, where an image is aligned to its temporally adjacent frame, we propose  SIFT flow , a method to align an image to its neighbors in a large image collection consisting of a variety of scenes. For a query image, histogram intersection on a bag-of-visual-words representation is used to find the set of nearest neighbors in the database. The SIFT flow algorithm then consists of matching densely sampled SIFT features between the two images, while preserving spatial discontinuities. The use of SIFT features allows robust matching across different scene/object appearances and the discontinuity-preserving spatial model allows matching of objects located at different parts of the scene. Experiments show that the proposed approach is able to robustly align complicated scenes with large spatial distortions. We collect a large database of videos and apply the SIFT flow algorithm to two applications: (i) motion field prediction from a single static image and (ii) motion synthesis via transfer of moving objects.},
    address = {Berlin, Heidelberg},
    author = {Liu, Ce and Yuen, Jenny and Torralba, Antonio and Sivic, Josef and Freeman, William T.},
    booktitle = {ECCV '08: Proceedings of the 10th European Conference on Computer Vision},
    citeulike-article-id = {4143297},
    citeulike-linkout-0 = {http://web.missouri.edu/\~{}hantx/ECE8001/notes/StudentPresentation/SIFT\_flow.pdf},
    citeulike-linkout-1 = {http://portal.acm.org/citation.cfm?id=1478176},
    citeulike-linkout-2 = {http://dx.doi.org/10.1007/978-3-540-88690-7\_3},
    doi = {10.1007/978-3-540-88690-7\_3},
    isbn = {978-3-540-88689-1},
    keywords = {keypoint},
    location = {Marseille, France},
    pages = {28--42},
    posted-at = {2009-08-25 19:57:43},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {SIFT Flow: Dense Correspondence across Different Scenes},
    url = {http://web.missouri.edu/\~{}hantx/ECE8001/notes/StudentPresentation/SIFT\_flow.pdf},
    year = {2008}
}



@phdthesis{Stolcke1994Bayesian,
    address = {Berkeley, CA, USA},
    author = {Stolcke, Andreas},
    citeulike-article-id = {165434},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=221997},
    keywords = {grammar},
    posted-at = {2009-08-25 19:56:19},
    priority = {2},
    publisher = {University of California at Berkeley},
    title = {Bayesian learning of probabilistic language models},
    url = {http://portal.acm.org/citation.cfm?id=221997},
    year = {1994}
}



@article{Cook1976Grammatical,
    abstract = {A cost function is developed, based on information-theoretic concepts, that measures the complexity of a stochastic context-free grammar, as well as the discrepancy between its language and a given stochastic language sample. This function is used to guide a search procedure that finds simple grammars whose languages are good fits to a sample. Reasonable results have been obtained in a variety of cases, including parenthesis and addition strings, Basic English (the first 25 sentences in  English Through Pictures ) and chain-encoded chromosome boundaries.},
    author = {Cook, C.},
    citeulike-article-id = {5645610},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/0020-0255(76)90061-X},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/0020-0255(76)90061-X},
    doi = {10.1016/0020-0255(76)90061-X},
    issn = {00200255},
    journal = {Information Sciences},
    keywords = {grammar},
    number = {1},
    pages = {59--80},
    posted-at = {2009-08-25 19:55:28},
    priority = {2},
    title = {Grammatical inference by hill climbing},
    url = {http://dx.doi.org/10.1016/0020-0255(76)90061-X},
    volume = {10},
    year = {1976}
}



@article{Mikolajczyk2005Performance,
    abstract = {In this paper, we compare the performance of descriptors computed for local interest regions, as, for example, extracted by the Harris-Affine detector [Mikolajczyk, K and Schmid, C, 2004]. Many different descriptors have been proposed in the literature. It is unclear which descriptors are more appropriate and how their performance depends on the interest region detector. The descriptors should be distinctive and at the same time robust to changes in viewing conditions as well as to errors of the detector. Our evaluation uses as criterion recall with respect to precision and is carried out for different image transformations. We compare shape context [Belongie, S, et al., April 2002], steerable filters [Freeman, W and Adelson, E, Setp. 1991], PCA-SIFT [Ke, Y and Sukthankar, R, 2004], differential invariants [Koenderink, J and van Doorn, A, 1987], spin images [Lazebnik, S, et al., 2003], SIFT [Lowe, D. G., 1999], complex filters [Schaffalitzky, F and Zisserman, A, 2002], moment invariants [Van Gool, L, et al., 1996], and cross-correlation for different types of interest regions. We also propose an extension of the SIFT descriptor and show that it outperforms the original method. Furthermore, we observe that the ranking of the descriptors is mostly independent of the interest region detector and that the SIFT-based descriptors perform best. Moments and steerable filters show the best performance among the low dimensional descriptors.},
    author = {Mikolajczyk, K. and Schmid, C.},
    citeulike-article-id = {828985},
    citeulike-linkout-0 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1498756},
    journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
    keywords = {keypoint},
    number = {10},
    pages = {1615--1630},
    posted-at = {2009-08-13 23:29:41},
    priority = {2},
    title = {A performance evaluation of local descriptors},
    url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1498756},
    volume = {27},
    year = {2005}
}



@article{Kofidis2002Best,
    abstract = {Abstract. Recently the problem of determining the best, in the least-squares sense, rank-1 approximation to a higher-order tensor was studied and an iterative method that extends the wellknown power method for matriceswasproposed for itssolution. Thishigher-order power method is also proposed for the special but important class of supersymmetric tensors, with no change. A simplified version, adapted to the special structure of the supersymmetric problem, is deemed unreliable, asitsconvergence isnot guaranteed. The aim of thispaper isto show that a symmetric version of the above method converges under assumptions of convexity (or concavity) for the functional induced by the tensor in question, assumptions that are very often satisfied in practical applications. The use of this version entails significant savings in computational complexity as compared to the unconstrained higher-order power method. Furthermore, a novel method for initializing the iterative processisdeveloped which hasbeen observed to yield an estimate that liescloser to the global optimum than the initialization suggested before. Moreover, its proximity to the global optimum is a priori quantifiable. In the course of the analysis, some important properties that the supersymmetry of a tensor implies for its square matrix unfolding are also studied.},
    author = {Kofidis, Eleftherios and Phillip and Regalia, A.},
    citeulike-article-id = {5430690},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.101.6035},
    journal = {SIAM J. Matrix Anal. Appl},
    keywords = {tensor},
    pages = {863--884},
    posted-at = {2009-08-13 07:06:00},
    priority = {2},
    title = {On the best rank-1 approximation of higher-order supersymmetric tensors},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.101.6035},
    volume = {23},
    year = {2002}
}



@proceedings{Parikh2007Hierarchical,
    abstract = {We introduce hSOs: hierarchical semantics of objects. An hSO is learnt from a collection of images taken from a particular scene category. The hSO captures the interactions between the objects that tend to co-occur in the scene, and hence are potentially semantically related. Such relationships are typically hierarchical. For example, in a collection of images taken in a living room scene, the TV, DVD player and coffee-table co-occur frequently. The TV and the DVD player are more closely related to each other than the coffee table, and this can be learnt from the fact that the two are located at similar relative locations across images, while the coffee table is somewhat arbitrarily placed. The goal of this paper is to learn this hierarchy that characterizes the scene. The proposed approach, being entirely unsupervised, can detect the parts of the images that belong to the foreground objects, cluster these parts to represent objects, and provide an understanding of the scene by hierarchically clustering these objects in a semantically meaningful way - all from a collection of unlabeled images of a particular scene category. In addition to providing the semantic layout of the scene, learnt hSOs can have several useful applications such as compact scene representation for scene category classification and providing context for enhanced object detection.},
    author = {Parikh, D. and Chen, Tsuhan},
    booktitle = {Computer Vision, 2007. ICCV 2007. IEEE 11th International Conference on},
    citeulike-article-id = {4446213},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/ICCV.2007.4408960},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4408960},
    doi = {10.1109/ICCV.2007.4408960},
    journal = {Computer Vision, 2007. ICCV 2007. IEEE 11th International Conference on},
    keywords = {grammar},
    pages = {1--8},
    posted-at = {2009-08-10 16:28:25},
    priority = {2},
    title = {Hierarchical Semantics of Objects (hSOs)},
    url = {http://dx.doi.org/10.1109/ICCV.2007.4408960},
    year = {2007}
}



@inproceedings{Finley2008Training,
    abstract = {While discriminative training (e.g., CRF, structural SVM) holds much promise for machine translation, image segmentation, and clustering, the complex inference these applications require make exact training intractable. This leads to a need for approximate training methods. Unfortunately, knowledge about how to perform efficient and effective approximate training is limited. Focusing on structural SVMs, we provide and explore algorithms for two different classes of approximate training algorithms, which we call undergenerating (e.g., greedy) and overgenerating (e.g., relaxations) algorithms. We provide a theoretical and empirical analysis of both types of approximate trained structural SVMs, focusing on fully connected pairwise Markov random fields. We find that models trained with overgenerating methods have theoretic advantages over undergenerating methods, are empirically robust relative to their undergenerating brethren, and relaxed trained models favor non-fractional predictions from relaxed predictors.},
    address = {New York, NY, USA},
    author = {Finley, Thomas and Joachims, Thorsten},
    booktitle = {ICML '08: Proceedings of the 25th international conference on Machine learning},
    citeulike-article-id = {5375475},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1390195},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1390156.1390195},
    doi = {10.1145/1390156.1390195},
    isbn = {978-1-60558-205-4},
    keywords = {structured},
    location = {Helsinki, Finland},
    pages = {304--311},
    posted-at = {2009-08-06 00:00:39},
    priority = {2},
    publisher = {ACM},
    title = {Training structural SVMs when exact inference is intractable},
    url = {http://dx.doi.org/10.1145/1390156.1390195},
    year = {2008}
}



@proceedings{Leordeanu2007Beyond,
    abstract = {We present a discriminative shape-based algorithm for object category localization and recognition. Our method learns object models in a weakly-supervised fashion, without requiring the specification of object locations nor pixel masks in the training data. We represent object models as cliques of fully-interconnected parts, exploiting only the pairwise geometric relationships between them. The use of pairwise relationships enables our algorithm to successfully overcome several problems that are common to previously-published methods. Even though our algorithm can easily incorporate local appearance information from richer features, we purposefully do not use them in order to demonstrate that simple geometric relationships can match (or exceed) the performance of state-of-the-art object recognition algorithms.},
    author = {Leordeanu, M. and Hebert, M. and Sukthankar, R.},
    booktitle = {Computer Vision and Pattern Recognition, 2007. CVPR '07. IEEE Conference on},
    citeulike-article-id = {3496533},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/CVPR.2007.383091},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4270116},
    day = {22},
    doi = {10.1109/CVPR.2007.383091},
    journal = {Computer Vision and Pattern Recognition, 2007. CVPR '07. IEEE Conference on},
    keywords = {tensor},
    month = {June},
    pages = {1--8},
    posted-at = {2009-08-05 23:56:44},
    priority = {2},
    title = {Beyond Local Appearance: Category Recognition from Pairwise Interactions of Simple Features},
    url = {http://dx.doi.org/10.1109/CVPR.2007.383091},
    year = {2007}
}



@article{Hinton2006Fast,
    abstract = {We show how to use "complementary priors" to eliminate the explaining-away effects that make inference difficult in densely connected belief nets that have many hidden layers. Using complementary priors, we derive a fast, greedy algorithm that can learn deep, directed belief networks one layer at a time, provided the top two layers form an undirected associative memory. The fast, greedy algorithm is used to initialize a slower learning procedure that fine-tunes the weights using a contrastive version of the wake-sleep algorithm. After fine-tuning, a network with three hidden layers forms a very good generative model of the joint distribution of handwritten digit images and their labels. This generative model gives better digit classification than the best discriminative learning algorithms. The low-dimensional manifolds on which the digits lie are modeled by long ravines in the free-energy landscape of the top-level associative memory, and it is easy to explore these ravines by using the directed connections to display what the associative memory has in mind.},
    author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee-Whye},
    citeulike-article-id = {921697},
    citeulike-linkout-0 = {http://www.informatics.sussex.ac.uk/users/chrisla/papers/hinton06.pdf},
    citeulike-linkout-1 = {http://neco.mitpress.org/cgi/content/abstract/18/7/1527},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/16764513},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=16764513},
    day = {1},
    journal = {Neural Comp.},
    month = {July},
    number = {7},
    pages = {1527--1554},
    posted-at = {2009-08-05 23:53:59},
    priority = {2},
    title = {A Fast Learning Algorithm for Deep Belief Nets},
    url = {http://www.informatics.sussex.ac.uk/users/chrisla/papers/hinton06.pdf},
    volume = {18},
    year = {2006}
}



@article{Lazebnik2005Sparse,
    abstract = {This paper introduces a texture representation suitable for recognizing images of textured surfaces under a wide range of transformations, including viewpoint changes and nonrigid deformations. At the feature extraction stage, a sparse set of affine Harris and Laplacian regions is found in the image. Each of these regions can be thought of as a texture element having a characteristic elliptic shape and a distinctive appearance pattern. This pattern is captured in an affine-invariant fashion via a process of shape normalization followed by the computation of two novel descriptors, the spin image and the RIFT descriptor. When affine invariance is not required, the original elliptical shape serves as an additional discriminative feature for texture recognition. The proposed approach is evaluated in retrieval and classification tasks using the entire Brodatz database and a publicly available collection of 1,000 photographs of textured surfaces taken from different viewpoints.},
    author = {Lazebnik, S. and Schmid, C. and Ponce, J.},
    booktitle = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
    citeulike-article-id = {1647377},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/TPAMI.2005.151},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1453514},
    doi = {10.1109/TPAMI.2005.151},
    journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
    number = {8},
    pages = {1265--1278},
    posted-at = {2009-07-21 01:24:55},
    priority = {2},
    title = {A sparse texture representation using local affine regions},
    url = {http://dx.doi.org/10.1109/TPAMI.2005.151},
    volume = {27},
    year = {2005}
}



@proceedings{Lazebnik2006Beyond,
    abstract = {This paper presents a method for recognizing scene categories based on approximate global geometric correspondence. This technique works by partitioning the image into increasingly fine sub-regions and computing histograms of local features found inside each sub-region. The resulting "spatial pyramid" is a simple and computationally efficient extension of an orderless bag-of-features image representation, and it shows significantly improved performance on challenging scene categorization tasks. Specifically, our proposed method exceeds the state of the art on the Caltech-101 database and achieves high accuracy on a large database of fifteen natural scene categories. The spatial pyramid framework also offers insights into the success of several recently proposed image descriptions, including Torralba\&\#146;s "gist" and Lowe\&\#146;s SIFT descriptors.},
    address = {Los Alamitos, CA, USA},
    author = {Lazebnik, S. and Schmid, C. and Ponce, J.},
    booktitle = {CVPR '06: Proceedings of the 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
    citeulike-article-id = {1720832},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1153549},
    citeulike-linkout-1 = {http://doi.ieeecomputersociety.org/10.1109/CVPR.2006.68},
    citeulike-linkout-2 = {http://dblp.uni-trier.de/rec/bibtex/conf/cvpr/LazebnikSP06},
    citeulike-linkout-3 = {http://dx.doi.org/10.1109/CVPR.2006.68},
    citeulike-linkout-4 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1641019},
    day = {09},
    doi = {10.1109/CVPR.2006.68},
    issn = {1063-6919},
    journal = {Computer Vision and Pattern Recognition, 2006 IEEE Computer Society Conference on},
    keywords = {bagofwords},
    month = {October},
    pages = {2169--2178},
    posted-at = {2009-07-21 01:24:51},
    priority = {2},
    publisher = {IEEE Computer Society},
    title = {Beyond Bags of Features: Spatial Pyramid Matching for Recognizing Natural Scene Categories},
    url = {http://dx.doi.org/10.1109/CVPR.2006.68},
    volume = {2},
    year = {2006}
}



@inproceedings{Csurka2004Visual,
    abstract = {Abstract. We present a novel method for generic visual categorization: the problem of identifying the object content of natural images while generalizing across variations inherent to the object class. This bag of keypoints method is based on vector quantization of affine invariant descriptors of image patches. We propose and compare two alternative implementations using different classifiers: Na\"{i}ve Bayes and SVM. The main advantages of the method are that it is simple, computationally efficient and intrinsically invariant. We present results for simultaneously classifying seven semantic visual categories. These results clearly demonstrate that the method is robust to background clutter and produces good categorization accuracy even without exploiting geometric information. 1.},
    author = {Csurka, Gabriella and Dance, Christopher R. and Fan, Lixin and Willamowski, Jutta and Bray, C\'{e}dric},
    booktitle = {In Workshop on Statistical Learning in Computer Vision, ECCV},
    citeulike-article-id = {4007958},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.72.604},
    keywords = {bagofwords},
    pages = {1--22},
    posted-at = {2009-07-21 01:23:32},
    priority = {2},
    title = {Visual categorization with bags of keypoints},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.72.604},
    year = {2004}
}



@inproceedings{Sun2008Least,
    abstract = {Canonical Correlation Analysis (CCA) is a well-known technique for finding the correlations between two sets of multi-dimensional variables. It projects both sets of variables into a lower-dimensional space in which they are maximally correlated. CCA is commonly applied for supervised dimensionality reduction, in which one of the multi-dimensional variables is derived from the class label. It has been shown that CCA can be formulated as a least squares problem in the binaryclass case. However, their relationship in the more general setting remains unclear. In this paper, we show that, under a mild condition which tends to hold for high-dimensional data, CCA in multi-label classifications can be formulated as a least squares problem. Based on this equivalence relationship, we propose several CCA extensions including sparse CCA using 1-norm regularization. Experiments on multi-label data sets confirm the established equivalence relationship. Results also demonstrate the effectiveness of the proposed CCA extensions.},
    address = {New York, NY, USA},
    author = {Sun, Liang and Ji, Shuiwang and Ye, Jieping},
    booktitle = {ICML '08: Proceedings of the 25th international conference on Machine learning},
    citeulike-article-id = {3781597},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1390156.1390285},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1390156.1390285},
    doi = {10.1145/1390156.1390285},
    isbn = {978-1-60558-205-4},
    location = {Helsinki, Finland},
    pages = {1024--1031},
    posted-at = {2009-07-21 01:16:50},
    priority = {2},
    publisher = {ACM},
    title = {A least squares formulation for canonical correlation analysis},
    url = {http://dx.doi.org/10.1145/1390156.1390285},
    year = {2008}
}



@inproceedings{Mikolajczyk2002Affine,
    abstract = {  This paper presents a novel approach for detecting affine invariant interest points. Our method can deal with significant affine transformations including large scale changes. Such transformations introduce significant changes in the point location as well as in the scale and the shape of the neighbourhood of an interest point. Our approach allows to solve for these problems simultaneously. It is based on three key ideas: 1) The second moment matrix computed in a point can be used to normalize a region in an affine invariant way (skew and stretch). 2) The scale of the local structure is indicated by local extrema of normalized derivatives over scale. 3) An affine-adapted Harris detector determines the location of interest points. Amulti-scale version of this detector is used for initialization. An iterative algorithm then modifies location, scale and neighbourhood of each point and converges to affine invariant points. For matching and recognition, the image is characterized by a set of affine invariant points; the affine transformation associated with each point allows the computation of an affine invariant descriptor which is also invariant to affine illumination changes. A quantitative comparison of our detector with existing ones shows a significant improvement in the presence of large affine deformations. Experimental results for wide baseline matching show an excellent performance in the presence of large perspective transformations including significant scale changes. Results for recognition are very good for a database with more than 5000 images.},
    author = {Mikolajczyk, Krystian and Schmid, Cordelia},
    booktitle = { Proc. European Conf. Computer Vision},
    citeulike-article-id = {4889589},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.19.4779},
    keywords = {keypoint},
    pages = {128--142},
    posted-at = {2009-07-21 01:14:16},
    priority = {2},
    title = {An affine invariant interest point detector},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.19.4779},
    volume = {2350},
    year = {2002}
}




